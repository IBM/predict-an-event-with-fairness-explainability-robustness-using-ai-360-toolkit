{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This Notebook demonstrates how to reduce the bias during \"Pre-processing\" & \"In-processing\" stage using AI 360 Fairness toolkit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing algorithm\n",
    "A bias mitigation algorithm that is applied to training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In-processing algorithm\n",
    "A bias mitigation algorithm that is applied to a model during its training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insert your credentials as credentials in the below cell\n",
    "Click on dropdown from Pipeline_LabelEncoder-0.1.zip under Data tab and select 'Credentials'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# @hidden_cell\n",
    "# The following code contains the credentials for a file in your IBM Cloud Object Storage.\n",
    "# You might want to remove those credentials before you share your notebook.\n",
    "credentials = {\n",
    "    \n",
    "    \n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ibm_botocore.client import Config\n",
    "import ibm_boto3\n",
    "\n",
    "cos = ibm_boto3.client(service_name='s3',\n",
    "    ibm_api_key_id=credentials['IBM_API_KEY_ID'],\n",
    "    ibm_service_instance_id=credentials['IAM_SERVICE_ID'],\n",
    "    ibm_auth_endpoint=credentials['IBM_AUTH_ENDPOINT'],\n",
    "    config=Config(signature_version='oauth'),\n",
    "    endpoint_url=credentials['ENDPOINT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/wsuser/work'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cos.download_file(Bucket=credentials['BUCKET'],Key='Pipeline_LabelEncoder-0.1.zip',Filename='/home/wsuser/work/Pipeline_LabelEncoder-0.1.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline_LabelEncoder-0.1.zip\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ./Pipeline_LabelEncoder-0.1.zip\n",
      "Building wheels for collected packages: Pipeline-LabelEncoder\n",
      "  Building wheel for Pipeline-LabelEncoder (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for Pipeline-LabelEncoder: filename=Pipeline_LabelEncoder-0.1-py3-none-any.whl size=2060 sha256=7346c21ec588a2e781a6387ad7798665630aa065f85a0905a58ac80b016354b2\n",
      "  Stored in directory: /tmp/wsuser/.cache/pip/wheels/a1/1a/b1/66d8f1917ec5b09eb70adf911c60dec54820888fd7cb9941ad\n",
      "Successfully built Pipeline-LabelEncoder\n",
      "Installing collected packages: Pipeline-LabelEncoder\n",
      "  Attempting uninstall: Pipeline-LabelEncoder\n",
      "    Found existing installation: Pipeline-LabelEncoder 0.1\n",
      "    Uninstalling Pipeline-LabelEncoder-0.1:\n",
      "      Successfully uninstalled Pipeline-LabelEncoder-0.1\n",
      "Successfully installed Pipeline-LabelEncoder-0.1\n",
      "Requirement already satisfied: aif360 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (0.3.0)\n",
      "Requirement already satisfied: scikit-learn>=0.21 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from aif360) (0.23.1)\n",
      "Requirement already satisfied: numpy>=1.16 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from aif360) (1.18.5)\n",
      "Requirement already satisfied: pandas>=0.24.0 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from aif360) (1.0.5)\n",
      "Requirement already satisfied: scipy>=1.2.0 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from aif360) (1.5.0)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from aif360) (3.2.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from scikit-learn>=0.21->aif360) (2.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from scikit-learn>=0.21->aif360) (0.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from pandas>=0.24.0->aif360) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from pandas>=0.24.0->aif360) (2020.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from matplotlib->aif360) (1.2.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from matplotlib->aif360) (2.4.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from matplotlib->aif360) (0.10.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from python-dateutil>=2.6.1->pandas>=0.24.0->aif360) (1.15.0)\n",
      "Collecting tensorflow<2,>=1.13.1\n",
      "  Using cached tensorflow-1.15.5-cp37-cp37m-manylinux2010_x86_64.whl (110.5 MB)\n",
      "Collecting protobuf>=3.6.1\n",
      "  Using cached protobuf-3.14.0-cp37-cp37m-manylinux1_x86_64.whl (1.0 MB)\n",
      "Collecting h5py<=2.10.0\n",
      "  Using cached h5py-2.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n",
      "Processing /tmp/wsuser/.cache/pip/wheels/62/76/4c/aa25851149f3f6d9785f6c869387ad82b3fd37582fa8147ac6/wrapt-1.12.1-cp37-cp37m-linux_x86_64.whl\n",
      "Processing /tmp/wsuser/.cache/pip/wheels/3f/e3/ec/8a8336ff196023622fbcb36de0c5a5c218cbb24111d1d4c7f2/termcolor-1.1.0-py3-none-any.whl\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Using cached opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Collecting six>=1.10.0\n",
      "  Using cached six-1.15.0-py2.py3-none-any.whl (10 kB)\n",
      "Collecting numpy<1.19.0,>=1.16.0\n",
      "  Using cached numpy-1.18.5-cp37-cp37m-manylinux1_x86_64.whl (20.1 MB)\n",
      "Collecting astor>=0.6.0\n",
      "  Using cached astor-0.8.1-py2.py3-none-any.whl (27 kB)\n",
      "Collecting absl-py>=0.7.0\n",
      "  Using cached absl_py-0.11.0-py3-none-any.whl (127 kB)\n",
      "Collecting tensorflow-estimator==1.15.1\n",
      "  Using cached tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503 kB)\n",
      "Collecting google-pasta>=0.1.6\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Collecting grpcio>=1.8.6\n",
      "  Using cached grpcio-1.34.0-cp37-cp37m-manylinux2014_x86_64.whl (3.9 MB)\n",
      "Collecting keras-preprocessing>=1.0.5\n",
      "  Using cached Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "Processing /tmp/wsuser/.cache/pip/wheels/21/7f/02/420f32a803f7d0967b48dd823da3f558c5166991bfd204eef3/gast-0.2.2-py3-none-any.whl\n",
      "Collecting wheel>=0.26; python_version >= \"3\"\n",
      "  Using cached wheel-0.36.2-py2.py3-none-any.whl (35 kB)\n",
      "Collecting tensorboard<1.16.0,>=1.15.0\n",
      "  Using cached tensorboard-1.15.0-py3-none-any.whl (3.8 MB)\n",
      "Collecting keras-applications>=1.0.8\n",
      "  Using cached Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
      "Collecting markdown>=2.6.8\n",
      "  Using cached Markdown-3.3.3-py3-none-any.whl (96 kB)\n",
      "Collecting werkzeug>=0.11.15\n",
      "  Using cached Werkzeug-1.0.1-py2.py3-none-any.whl (298 kB)\n",
      "Collecting setuptools>=41.0.0\n",
      "  Using cached setuptools-51.1.1-py3-none-any.whl (2.0 MB)\n",
      "Collecting importlib-metadata; python_version < \"3.8\"\n",
      "  Using cached importlib_metadata-3.3.0-py3-none-any.whl (10 kB)\n",
      "Collecting typing-extensions>=3.6.4; python_version < \"3.8\"\n",
      "  Using cached typing_extensions-3.7.4.3-py3-none-any.whl (22 kB)\n",
      "Collecting zipp>=0.5\n",
      "  Using cached zipp-3.4.0-py3-none-any.whl (5.2 kB)\n",
      "\u001b[31mERROR: jupyterlab 2.2.6 has requirement jupyterlab_server<2.0,>=1.1.5, but you'll have jupyterlab-server 1.1.0 which is incompatible.\u001b[0m\n",
      "Installing collected packages: six, protobuf, numpy, h5py, wrapt, termcolor, opt-einsum, astor, absl-py, tensorflow-estimator, google-pasta, grpcio, keras-preprocessing, gast, wheel, typing-extensions, zipp, importlib-metadata, markdown, werkzeug, setuptools, tensorboard, keras-applications, tensorflow\n",
      "  Attempting uninstall: six\n",
      "    Found existing installation: six 1.15.0\n",
      "    Uninstalling six-1.15.0:\n",
      "      Successfully uninstalled six-1.15.0\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 3.14.0\n",
      "    Uninstalling protobuf-3.14.0:\n",
      "      Successfully uninstalled protobuf-3.14.0\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.18.5\n",
      "    Uninstalling numpy-1.18.5:\n",
      "      Successfully uninstalled numpy-1.18.5\n",
      "  Attempting uninstall: h5py\n",
      "    Found existing installation: h5py 2.10.0\n",
      "    Uninstalling h5py-2.10.0:\n",
      "      Successfully uninstalled h5py-2.10.0\n",
      "  Attempting uninstall: wrapt\n",
      "    Found existing installation: wrapt 1.12.1\n",
      "    Uninstalling wrapt-1.12.1:\n",
      "      Successfully uninstalled wrapt-1.12.1\n",
      "  Attempting uninstall: termcolor\n",
      "    Found existing installation: termcolor 1.1.0\n",
      "\u001b[31mERROR: Cannot uninstall 'termcolor'. It is a distutils installed project and thus we cannot accurately determine which files belong to it which would lead to only a partial uninstall.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install Pipeline_LabelEncoder-0.1.zip\n",
    "!pip install aif360\n",
    "!pip install 'tensorflow>=1.13.1,< 2' --force-reinstall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.15.5'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# Load all necessary packages\n",
    "import pandas as pd\n",
    "from aif360.datasets import BinaryLabelDataset\n",
    "from aif360.metrics import BinaryLabelDatasetMetric\n",
    "from aif360.metrics import ClassificationMetric\n",
    "from aif360.metrics.utils import compute_boolean_conditioning_vector\n",
    "\n",
    "from aif360.algorithms.inprocessing.adversarial_debiasing import AdversarialDebiasing\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler, MaxAbsScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from IPython.display import Markdown, display\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>Old</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>Young</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>Young</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>Young</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>Young</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction    Age  Outcome  \n",
       "0                     0.627    Old        1  \n",
       "1                     0.351  Young        0  \n",
       "2                     0.672  Young        1  \n",
       "3                     0.167  Young        0  \n",
       "4                     2.288  Young        1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "df = pd.read_csv(body)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768</td>\n",
       "      <td>768.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Young</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>679</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.845052</td>\n",
       "      <td>120.894531</td>\n",
       "      <td>69.105469</td>\n",
       "      <td>20.536458</td>\n",
       "      <td>79.799479</td>\n",
       "      <td>31.992578</td>\n",
       "      <td>0.471876</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.348958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.369578</td>\n",
       "      <td>31.972618</td>\n",
       "      <td>19.355807</td>\n",
       "      <td>15.952218</td>\n",
       "      <td>115.244002</td>\n",
       "      <td>7.884160</td>\n",
       "      <td>0.331329</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.476951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.078000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27.300000</td>\n",
       "      <td>0.243750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>30.500000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.372500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>140.250000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>127.250000</td>\n",
       "      <td>36.600000</td>\n",
       "      <td>0.626250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>199.000000</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>846.000000</td>\n",
       "      <td>67.100000</td>\n",
       "      <td>2.420000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Pregnancies     Glucose  BloodPressure  SkinThickness     Insulin  \\\n",
       "count    768.000000  768.000000     768.000000     768.000000  768.000000   \n",
       "unique          NaN         NaN            NaN            NaN         NaN   \n",
       "top             NaN         NaN            NaN            NaN         NaN   \n",
       "freq            NaN         NaN            NaN            NaN         NaN   \n",
       "mean       3.845052  120.894531      69.105469      20.536458   79.799479   \n",
       "std        3.369578   31.972618      19.355807      15.952218  115.244002   \n",
       "min        0.000000    0.000000       0.000000       0.000000    0.000000   \n",
       "25%        1.000000   99.000000      62.000000       0.000000    0.000000   \n",
       "50%        3.000000  117.000000      72.000000      23.000000   30.500000   \n",
       "75%        6.000000  140.250000      80.000000      32.000000  127.250000   \n",
       "max       17.000000  199.000000     122.000000      99.000000  846.000000   \n",
       "\n",
       "               BMI  DiabetesPedigreeFunction    Age     Outcome  \n",
       "count   768.000000                768.000000    768  768.000000  \n",
       "unique         NaN                       NaN      2         NaN  \n",
       "top            NaN                       NaN  Young         NaN  \n",
       "freq           NaN                       NaN    679         NaN  \n",
       "mean     31.992578                  0.471876    NaN    0.348958  \n",
       "std       7.884160                  0.331329    NaN    0.476951  \n",
       "min       0.000000                  0.078000    NaN    0.000000  \n",
       "25%      27.300000                  0.243750    NaN    0.000000  \n",
       "50%      32.000000                  0.372500    NaN    0.000000  \n",
       "75%      36.600000                  0.626250    NaN    1.000000  \n",
       "max      67.100000                  2.420000    NaN    1.000000  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe(include = 'all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "privileged_groups = [{'Age': 1}]\n",
    "unprivileged_groups = [{'Age': 0}]\n",
    "favorable_label = 0 \n",
    "unfavorable_label = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Age\n",
      "mapping {'Old': 0, 'Young': 1}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627    0        1  \n",
       "1                     0.351    1        0  \n",
       "2                     0.672    1        1  \n",
       "3                     0.167    1        0  \n",
       "4                     2.288    1        1  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "categorical_column = ['Age']\n",
    "\n",
    "data_encoded = df.copy(deep=True)\n",
    "#Use Scikit-learn label encoding to encode character data\n",
    "lab_enc = preprocessing.LabelEncoder()\n",
    "for col in categorical_column:\n",
    "        data_encoded[col] = lab_enc.fit_transform(df[col])\n",
    "        le_name_mapping = dict(zip(lab_enc.classes_, lab_enc.transform(lab_enc.classes_)))\n",
    "        print('Feature', col)\n",
    "        print('mapping', le_name_mapping)\n",
    "        \n",
    "\n",
    "data_encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inside fit transform\n",
      "Feature Age\n",
      "mapping {0: 0, 1: 1}\n",
      "-------------------------\n"
     ]
    }
   ],
   "source": [
    "from Pipeline_LabelEncoder.sklearn_label_encoder import PipelineLabelEncoder\n",
    "preprocessed_data = PipelineLabelEncoder(columns = ['Age']).fit_transform(data_encoded)\n",
    "print('-------------------------')\n",
    "#print('validation data encoding')\n",
    "#validation_enc_data = PipelineLabelEncoder(columns = ['Gender','Married', 'Fraud_risk']).transform(validation_input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create binary label dataset that can be used by bias mitigation algorithms\n",
    "diabetes_dataset = BinaryLabelDataset(favorable_label=favorable_label,\n",
    "                                unfavorable_label=unfavorable_label,\n",
    "                                df=preprocessed_data,\n",
    "                                label_names=['Outcome'],\n",
    "                                protected_attribute_names=['Age'],\n",
    "                                unprivileged_protected_attributes=unprivileged_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Training Data Details"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of the training dataset (768, 8)\n",
      "Training data favorable label 0.0\n",
      "Training data unfavorable label 1.0\n",
      "Training data protected attribute ['Age']\n",
      "Training data privileged protected attribute (1:Young and 0:Old) [array([1.])]\n",
      "Training data unprivileged protected attribute (1:Young and 0:Old) [array([0.])]\n"
     ]
    }
   ],
   "source": [
    "display(Markdown(\"#### Training Data Details\"))\n",
    "print(\"shape of the training dataset\", diabetes_dataset.features.shape)\n",
    "print(\"Training data favorable label\", diabetes_dataset.favorable_label)\n",
    "print(\"Training data unfavorable label\", diabetes_dataset.unfavorable_label)\n",
    "print(\"Training data protected attribute\", diabetes_dataset.protected_attribute_names)\n",
    "print(\"Training data privileged protected attribute (1:Young and 0:Old)\", \n",
    "      diabetes_dataset.privileged_protected_attributes)\n",
    "print(\"Training data unprivileged protected attribute (1:Young and 0:Old)\",\n",
    "      diabetes_dataset.unprivileged_protected_attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes_dataset_train, diabetes_dataset_test = diabetes_dataset.split([0.6], shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Original training dataset"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: Difference in mean outcomes between unprivileged and privileged groups = -0.099364\n",
      "Test set: Difference in mean outcomes between unprivileged and privileged groups = -0.241212\n"
     ]
    }
   ],
   "source": [
    "# Metric for the original dataset\n",
    "metric_orig_train = BinaryLabelDatasetMetric(diabetes_dataset_train, \n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)\n",
    "display(Markdown(\"#### Original training dataset\"))\n",
    "print(\"Train set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_orig_train.mean_difference())\n",
    "metric_orig_test = BinaryLabelDatasetMetric(diabetes_dataset_test, \n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)\n",
    "print(\"Test set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_orig_test.mean_difference())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Scaled dataset - Verify that the scaling does not affect the group label statistics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: Difference in mean outcomes between unprivileged and privileged groups = -0.099364\n",
      "Test set: Difference in mean outcomes between unprivileged and privileged groups = -0.241212\n"
     ]
    }
   ],
   "source": [
    "min_max_scaler = MaxAbsScaler()\n",
    "diabetes_dataset_train.features = min_max_scaler.fit_transform(diabetes_dataset_train.features)\n",
    "diabetes_dataset_test.features = min_max_scaler.transform(diabetes_dataset_test.features)\n",
    "metric_scaled_train = BinaryLabelDatasetMetric(diabetes_dataset_train, \n",
    "                             unprivileged_groups=unprivileged_groups,\n",
    "                             privileged_groups=privileged_groups)\n",
    "display(Markdown(\"#### Scaled dataset - Verify that the scaling does not affect the group label statistics\"))\n",
    "print(\"Train set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_scaled_train.mean_difference())\n",
    "metric_scaled_test = BinaryLabelDatasetMetric(diabetes_dataset_test, \n",
    "                             unprivileged_groups=unprivileged_groups,\n",
    "                             privileged_groups=privileged_groups)\n",
    "print(\"Test set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_scaled_test.mean_difference())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build plan classifier without debiasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load post-processing algorithm that equalizes the odds\n",
    "# Learn parameters with debias set to False\n",
    "sess = tf.Session()\n",
    "#sess = tf.compat.v1.Session()\n",
    "plain_model = AdversarialDebiasing(privileged_groups = privileged_groups,\n",
    "                          unprivileged_groups = unprivileged_groups,\n",
    "                          scope_name='plain_classifier',\n",
    "                          debias=False,\n",
    "                          sess=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages/aif360/algorithms/inprocessing/adversarial_debiasing.py:137: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages/aif360/algorithms/inprocessing/adversarial_debiasing.py:141: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages/aif360/algorithms/inprocessing/adversarial_debiasing.py:84: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages/aif360/algorithms/inprocessing/adversarial_debiasing.py:89: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages/aif360/algorithms/inprocessing/adversarial_debiasing.py:159: The name tf.train.exponential_decay is deprecated. Please use tf.compat.v1.train.exponential_decay instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages/aif360/algorithms/inprocessing/adversarial_debiasing.py:161: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages/aif360/algorithms/inprocessing/adversarial_debiasing.py:165: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages/aif360/algorithms/inprocessing/adversarial_debiasing.py:187: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages/aif360/algorithms/inprocessing/adversarial_debiasing.py:188: The name tf.local_variables_initializer is deprecated. Please use tf.compat.v1.local_variables_initializer instead.\n",
      "\n",
      "epoch 0; iter: 0; batch classifier loss: 0.733848\n",
      "epoch 1; iter: 0; batch classifier loss: 0.705918\n",
      "epoch 2; iter: 0; batch classifier loss: 0.697707\n",
      "epoch 3; iter: 0; batch classifier loss: 0.668858\n",
      "epoch 4; iter: 0; batch classifier loss: 0.683273\n",
      "epoch 5; iter: 0; batch classifier loss: 0.661506\n",
      "epoch 6; iter: 0; batch classifier loss: 0.672708\n",
      "epoch 7; iter: 0; batch classifier loss: 0.666617\n",
      "epoch 8; iter: 0; batch classifier loss: 0.622283\n",
      "epoch 9; iter: 0; batch classifier loss: 0.604357\n",
      "epoch 10; iter: 0; batch classifier loss: 0.627079\n",
      "epoch 11; iter: 0; batch classifier loss: 0.617319\n",
      "epoch 12; iter: 0; batch classifier loss: 0.667670\n",
      "epoch 13; iter: 0; batch classifier loss: 0.590425\n",
      "epoch 14; iter: 0; batch classifier loss: 0.614204\n",
      "epoch 15; iter: 0; batch classifier loss: 0.631940\n",
      "epoch 16; iter: 0; batch classifier loss: 0.654006\n",
      "epoch 17; iter: 0; batch classifier loss: 0.656718\n",
      "epoch 18; iter: 0; batch classifier loss: 0.629965\n",
      "epoch 19; iter: 0; batch classifier loss: 0.668929\n",
      "epoch 20; iter: 0; batch classifier loss: 0.597523\n",
      "epoch 21; iter: 0; batch classifier loss: 0.609832\n",
      "epoch 22; iter: 0; batch classifier loss: 0.626864\n",
      "epoch 23; iter: 0; batch classifier loss: 0.600600\n",
      "epoch 24; iter: 0; batch classifier loss: 0.624841\n",
      "epoch 25; iter: 0; batch classifier loss: 0.566231\n",
      "epoch 26; iter: 0; batch classifier loss: 0.599646\n",
      "epoch 27; iter: 0; batch classifier loss: 0.606180\n",
      "epoch 28; iter: 0; batch classifier loss: 0.647363\n",
      "epoch 29; iter: 0; batch classifier loss: 0.615267\n",
      "epoch 30; iter: 0; batch classifier loss: 0.601861\n",
      "epoch 31; iter: 0; batch classifier loss: 0.613478\n",
      "epoch 32; iter: 0; batch classifier loss: 0.627534\n",
      "epoch 33; iter: 0; batch classifier loss: 0.556390\n",
      "epoch 34; iter: 0; batch classifier loss: 0.635433\n",
      "epoch 35; iter: 0; batch classifier loss: 0.601133\n",
      "epoch 36; iter: 0; batch classifier loss: 0.643158\n",
      "epoch 37; iter: 0; batch classifier loss: 0.595400\n",
      "epoch 38; iter: 0; batch classifier loss: 0.607469\n",
      "epoch 39; iter: 0; batch classifier loss: 0.634301\n",
      "epoch 40; iter: 0; batch classifier loss: 0.577843\n",
      "epoch 41; iter: 0; batch classifier loss: 0.606166\n",
      "epoch 42; iter: 0; batch classifier loss: 0.567611\n",
      "epoch 43; iter: 0; batch classifier loss: 0.600869\n",
      "epoch 44; iter: 0; batch classifier loss: 0.590184\n",
      "epoch 45; iter: 0; batch classifier loss: 0.618053\n",
      "epoch 46; iter: 0; batch classifier loss: 0.592697\n",
      "epoch 47; iter: 0; batch classifier loss: 0.563050\n",
      "epoch 48; iter: 0; batch classifier loss: 0.571746\n",
      "epoch 49; iter: 0; batch classifier loss: 0.555651\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<aif360.algorithms.inprocessing.adversarial_debiasing.AdversarialDebiasing at 0x7f4a47968610>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plain_model.fit(diabetes_dataset_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply the plain model to test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_nodebiasing_train = plain_model.predict(diabetes_dataset_train)\n",
    "dataset_nodebiasing_test = plain_model.predict(diabetes_dataset_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics for the dataset from plain model (without debiasing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Model - without debiasing - dataset metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: Difference in mean outcomes between unprivileged and privileged groups = -0.598303\n",
      "Test set: Difference in mean outcomes between unprivileged and privileged groups = -0.589091\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Model - without debiasing - classification metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Classification accuracy = 0.711039\n",
      "Test set: Balanced classification accuracy = 0.610898\n",
      "Test set: Disparate impact = 0.381679\n",
      "Test set: Equal opportunity difference = -0.428571\n",
      "Test set: Average odds difference = -0.538370\n",
      "Test set: Theil_index = 0.075720\n"
     ]
    }
   ],
   "source": [
    "display(Markdown(\"#### Model - without debiasing - dataset metrics\"))\n",
    "metric_dataset_nodebiasing_train = BinaryLabelDatasetMetric(dataset_nodebiasing_train, \n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)\n",
    "\n",
    "print(\"Train set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_dataset_nodebiasing_train.mean_difference())\n",
    "\n",
    "metric_dataset_nodebiasing_test = BinaryLabelDatasetMetric(dataset_nodebiasing_test, \n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)\n",
    "\n",
    "print(\"Test set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_dataset_nodebiasing_test.mean_difference())\n",
    "\n",
    "display(Markdown(\"#### Model - without debiasing - classification metrics\"))\n",
    "classified_metric_nodebiasing_test = ClassificationMetric(diabetes_dataset_test, \n",
    "                                                 dataset_nodebiasing_test,\n",
    "                                                 unprivileged_groups=unprivileged_groups,\n",
    "                                                 privileged_groups=privileged_groups)\n",
    "print(\"Test set: Classification accuracy = %f\" % classified_metric_nodebiasing_test.accuracy())\n",
    "TPR = classified_metric_nodebiasing_test.true_positive_rate()\n",
    "TNR = classified_metric_nodebiasing_test.true_negative_rate()\n",
    "bal_acc_nodebiasing_test = 0.5*(TPR+TNR)\n",
    "print(\"Test set: Balanced classification accuracy = %f\" % bal_acc_nodebiasing_test)\n",
    "print(\"Test set: Disparate impact = %f\" % classified_metric_nodebiasing_test.disparate_impact())\n",
    "print(\"Test set: Equal opportunity difference = %f\" % classified_metric_nodebiasing_test.equal_opportunity_difference())\n",
    "print(\"Test set: Average odds difference = %f\" % classified_metric_nodebiasing_test.average_odds_difference())\n",
    "print(\"Test set: Theil_index = %f\" % classified_metric_nodebiasing_test.theil_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply in-processing algorithm based on adversarial learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.close()\n",
    "tf.reset_default_graph()\n",
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learn parameters with debias set to True\n",
    "debiased_model = AdversarialDebiasing(privileged_groups = privileged_groups,\n",
    "                          unprivileged_groups = unprivileged_groups,\n",
    "                          scope_name='debiased_classifier',\n",
    "                          debias=True,\n",
    "                          sess=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 0.719709; batch adversarial loss: 0.707410\n",
      "epoch 1; iter: 0; batch classifier loss: 0.734156; batch adversarial loss: 0.704542\n",
      "epoch 2; iter: 0; batch classifier loss: 0.726808; batch adversarial loss: 0.702275\n",
      "epoch 3; iter: 0; batch classifier loss: 0.745609; batch adversarial loss: 0.701177\n",
      "epoch 4; iter: 0; batch classifier loss: 0.731937; batch adversarial loss: 0.700088\n",
      "epoch 5; iter: 0; batch classifier loss: 0.724922; batch adversarial loss: 0.698732\n",
      "epoch 6; iter: 0; batch classifier loss: 0.713914; batch adversarial loss: 0.695718\n",
      "epoch 7; iter: 0; batch classifier loss: 0.721002; batch adversarial loss: 0.695420\n",
      "epoch 8; iter: 0; batch classifier loss: 0.706691; batch adversarial loss: 0.692693\n",
      "epoch 9; iter: 0; batch classifier loss: 0.704806; batch adversarial loss: 0.690888\n",
      "epoch 10; iter: 0; batch classifier loss: 0.713283; batch adversarial loss: 0.687029\n",
      "epoch 11; iter: 0; batch classifier loss: 0.709272; batch adversarial loss: 0.684010\n",
      "epoch 12; iter: 0; batch classifier loss: 0.695250; batch adversarial loss: 0.684294\n",
      "epoch 13; iter: 0; batch classifier loss: 0.689950; batch adversarial loss: 0.682139\n",
      "epoch 14; iter: 0; batch classifier loss: 0.680935; batch adversarial loss: 0.680896\n",
      "epoch 15; iter: 0; batch classifier loss: 0.678971; batch adversarial loss: 0.676125\n",
      "epoch 16; iter: 0; batch classifier loss: 0.675492; batch adversarial loss: 0.679915\n",
      "epoch 17; iter: 0; batch classifier loss: 0.662445; batch adversarial loss: 0.673574\n",
      "epoch 18; iter: 0; batch classifier loss: 0.639764; batch adversarial loss: 0.669879\n",
      "epoch 19; iter: 0; batch classifier loss: 0.617830; batch adversarial loss: 0.665276\n",
      "epoch 20; iter: 0; batch classifier loss: 0.616387; batch adversarial loss: 0.666273\n",
      "epoch 21; iter: 0; batch classifier loss: 0.614119; batch adversarial loss: 0.661479\n",
      "epoch 22; iter: 0; batch classifier loss: 0.639519; batch adversarial loss: 0.662677\n",
      "epoch 23; iter: 0; batch classifier loss: 0.634923; batch adversarial loss: 0.655987\n",
      "epoch 24; iter: 0; batch classifier loss: 0.618898; batch adversarial loss: 0.649650\n",
      "epoch 25; iter: 0; batch classifier loss: 0.602790; batch adversarial loss: 0.648423\n",
      "epoch 26; iter: 0; batch classifier loss: 0.636295; batch adversarial loss: 0.647120\n",
      "epoch 27; iter: 0; batch classifier loss: 0.593816; batch adversarial loss: 0.638820\n",
      "epoch 28; iter: 0; batch classifier loss: 0.607627; batch adversarial loss: 0.641455\n",
      "epoch 29; iter: 0; batch classifier loss: 0.597371; batch adversarial loss: 0.631617\n",
      "epoch 30; iter: 0; batch classifier loss: 0.625358; batch adversarial loss: 0.637608\n",
      "epoch 31; iter: 0; batch classifier loss: 0.587366; batch adversarial loss: 0.627778\n",
      "epoch 32; iter: 0; batch classifier loss: 0.595702; batch adversarial loss: 0.636348\n",
      "epoch 33; iter: 0; batch classifier loss: 0.603606; batch adversarial loss: 0.628887\n",
      "epoch 34; iter: 0; batch classifier loss: 0.608324; batch adversarial loss: 0.620453\n",
      "epoch 35; iter: 0; batch classifier loss: 0.609205; batch adversarial loss: 0.625607\n",
      "epoch 36; iter: 0; batch classifier loss: 0.595749; batch adversarial loss: 0.617146\n",
      "epoch 37; iter: 0; batch classifier loss: 0.585345; batch adversarial loss: 0.614890\n",
      "epoch 38; iter: 0; batch classifier loss: 0.597665; batch adversarial loss: 0.614633\n",
      "epoch 39; iter: 0; batch classifier loss: 0.607348; batch adversarial loss: 0.619236\n",
      "epoch 40; iter: 0; batch classifier loss: 0.625501; batch adversarial loss: 0.620120\n",
      "epoch 41; iter: 0; batch classifier loss: 0.605575; batch adversarial loss: 0.611086\n",
      "epoch 42; iter: 0; batch classifier loss: 0.631326; batch adversarial loss: 0.614076\n",
      "epoch 43; iter: 0; batch classifier loss: 0.593519; batch adversarial loss: 0.601517\n",
      "epoch 44; iter: 0; batch classifier loss: 0.635104; batch adversarial loss: 0.609804\n",
      "epoch 45; iter: 0; batch classifier loss: 0.615679; batch adversarial loss: 0.610952\n",
      "epoch 46; iter: 0; batch classifier loss: 0.610811; batch adversarial loss: 0.600899\n",
      "epoch 47; iter: 0; batch classifier loss: 0.591105; batch adversarial loss: 0.595707\n",
      "epoch 48; iter: 0; batch classifier loss: 0.622528; batch adversarial loss: 0.591576\n",
      "epoch 49; iter: 0; batch classifier loss: 0.601092; batch adversarial loss: 0.598573\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<aif360.algorithms.inprocessing.adversarial_debiasing.AdversarialDebiasing at 0x7f4a4823b950>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "debiased_model.fit(diabetes_dataset_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply the plain model to test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_debiasing_train = debiased_model.predict(diabetes_dataset_train)\n",
    "dataset_debiasing_test = debiased_model.predict(diabetes_dataset_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Model - without debiasing - dataset metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: Difference in mean outcomes between unprivileged and privileged groups = -0.598303\n",
      "Test set: Difference in mean outcomes between unprivileged and privileged groups = -0.589091\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Model - with debiasing - dataset metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: Difference in mean outcomes between unprivileged and privileged groups = 0.164958\n",
      "Test set: Difference in mean outcomes between unprivileged and privileged groups = 0.019394\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Model - without debiasing - classification metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Classification accuracy = 0.711039\n",
      "Test set: Balanced classification accuracy = 0.610898\n",
      "Test set: Disparate impact = 0.381679\n",
      "Test set: Equal opportunity difference = -0.428571\n",
      "Test set: Average odds difference = -0.538370\n",
      "Test set: Theil_index = 0.075720\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Model - with debiasing - classification metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Classification accuracy = 0.724026\n",
      "Test set: Balanced classification accuracy = 0.697741\n",
      "Test set: Disparate impact = 1.029963\n",
      "Test set: Equal opportunity difference = 0.147151\n",
      "Test set: Average odds difference = 0.120200\n",
      "Test set: Theil_index = 0.186439\n"
     ]
    }
   ],
   "source": [
    "# Metrics for the dataset from plain model (without debiasing)\n",
    "display(Markdown(\"#### Model - without debiasing - dataset metrics\"))\n",
    "print(\"Train set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_dataset_nodebiasing_train.mean_difference())\n",
    "print(\"Test set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_dataset_nodebiasing_test.mean_difference())\n",
    "\n",
    "# Metrics for the dataset from model with debiasing\n",
    "display(Markdown(\"#### Model - with debiasing - dataset metrics\"))\n",
    "metric_dataset_debiasing_train = BinaryLabelDatasetMetric(dataset_debiasing_train, \n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)\n",
    "\n",
    "print(\"Train set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_dataset_debiasing_train.mean_difference())\n",
    "\n",
    "metric_dataset_debiasing_test = BinaryLabelDatasetMetric(dataset_debiasing_test, \n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)\n",
    "\n",
    "print(\"Test set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_dataset_debiasing_test.mean_difference())\n",
    "\n",
    "\n",
    "\n",
    "display(Markdown(\"#### Model - without debiasing - classification metrics\"))\n",
    "print(\"Test set: Classification accuracy = %f\" % classified_metric_nodebiasing_test.accuracy())\n",
    "TPR = classified_metric_nodebiasing_test.true_positive_rate()\n",
    "TNR = classified_metric_nodebiasing_test.true_negative_rate()\n",
    "bal_acc_nodebiasing_test = 0.5*(TPR+TNR)\n",
    "print(\"Test set: Balanced classification accuracy = %f\" % bal_acc_nodebiasing_test)\n",
    "print(\"Test set: Disparate impact = %f\" % classified_metric_nodebiasing_test.disparate_impact())\n",
    "print(\"Test set: Equal opportunity difference = %f\" % classified_metric_nodebiasing_test.equal_opportunity_difference())\n",
    "print(\"Test set: Average odds difference = %f\" % classified_metric_nodebiasing_test.average_odds_difference())\n",
    "print(\"Test set: Theil_index = %f\" % classified_metric_nodebiasing_test.theil_index())\n",
    "\n",
    "\n",
    "\n",
    "display(Markdown(\"#### Model - with debiasing - classification metrics\"))\n",
    "classified_metric_debiasing_test = ClassificationMetric(diabetes_dataset_test, \n",
    "                                                 dataset_debiasing_test,\n",
    "                                                 unprivileged_groups=unprivileged_groups,\n",
    "                                                 privileged_groups=privileged_groups)\n",
    "print(\"Test set: Classification accuracy = %f\" % classified_metric_debiasing_test.accuracy())\n",
    "TPR = classified_metric_debiasing_test.true_positive_rate()\n",
    "TNR = classified_metric_debiasing_test.true_negative_rate()\n",
    "bal_acc_debiasing_test = 0.5*(TPR+TNR)\n",
    "print(\"Test set: Balanced classification accuracy = %f\" % bal_acc_debiasing_test)\n",
    "print(\"Test set: Disparate impact = %f\" % classified_metric_debiasing_test.disparate_impact())\n",
    "print(\"Test set: Equal opportunity difference = %f\" % classified_metric_debiasing_test.equal_opportunity_difference())\n",
    "print(\"Test set: Average odds difference = %f\" % classified_metric_debiasing_test.average_odds_difference())\n",
    "print(\"Test set: Theil_index = %f\" % classified_metric_debiasing_test.theil_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We have observed how to use AI 360 fairness toolkit to eliminate the bias during preprocessing & inprocessing stages of model building & development. There's reduction from 42% to 14% with Equal opportunity difference & Average odds difference saw a reduction from 53% to 12% thereby eliminating the bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
