{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unveiling a classification model- Whether the patient is at diabetes risk or not.\n",
    "1. for Data Scientist[to understand underlying patterns discovered by the model] using `Boolean Rule Column Generation` explained provided by AI 360 Explainability Toolkit.\n",
    "2. For doctors- to compare similar profile using `Protodash Explainer.`\n",
    "3. For patient- what do they need to be not at risk using `Contrastive Explanations Method` (CEM) algorithm using AI Explainability 360 on Diabetes Data.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install the required Libraries.\n",
    "Uncomment them and Run the Cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install aix360"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pandas_profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part-1 Boolean Rule Column Generation explainer\n",
    "Using the `Diabetes Data`, we will do\n",
    "\n",
    "- Exploratory Data Analysis\n",
    "- Build Lightgbm model.\n",
    "- Feature importance.\n",
    "- Unveiling Fraud Detection AI Model for Data Scientist using `Boolean Rule Column Generation explainer` provided by AI 360 Explainability Toolkit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the Libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import ipaddress\n",
    "import pandas_profiling as pp\n",
    "%matplotlib inline\n",
    "from sklearn import preprocessing\n",
    "plt.rc(\"font\", size=14)\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import time\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMClassifier\n",
    "import seaborn as sns\n",
    "sns.set(style=\"white\")\n",
    "sns.set(style=\"whitegrid\", color_codes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the `Diabetes-Data` as csv in the notebook. \n",
    "\n",
    "* Click on the `0100` on the top right corner. \n",
    "* Drag and Drop `diabetes-data.csv` \n",
    "* Select the Cell below. \n",
    "* Click on `Insert to Code` and then `Pandas Dataframe.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>Old</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>Young</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>Young</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>Young</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>Young</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction    Age  Outcome  \n",
       "0                     0.627    Old        1  \n",
       "1                     0.351  Young        0  \n",
       "2                     0.672  Young        1  \n",
       "3                     0.167  Young        0  \n",
       "4                     2.288  Young        1  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load the data here \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, some of the columns have zero values to it. Insulin have zeros, Skin thickness is zero which is not possible. Let's check all the columns having zeros and treat them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x1080 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.hist(color='green', figsize=(20,15));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- SkinThickness, Insulin is right skewed.\n",
    "- BMI, and BloodPressure is normally distributed.\n",
    "- Glucose is left skewed.\n",
    "- is normally distributed like BMI, and BloodPressure. If we fill zeros with median of that columns, we wouldn't disrupt the data. For left, and right skewed data, we can fill zeros with median of that columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_treated = df.copy()\n",
    "df_treated['Insulin'].replace(0, df_treated['Insulin'].median(), inplace=True)\n",
    "df_treated['SkinThickness'].replace(0, df_treated['SkinThickness'].median(), inplace=True)\n",
    "df_treated['BMI'].replace(0, df_treated['BMI'].mean(), inplace=True)\n",
    "df_treated['Glucose'].replace(0, df_treated['Glucose'].median(), inplace=True)\n",
    "df_treated['BloodPressure'].replace(0,df_treated['BloodPressure'].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pp.ProfileReport(df_treated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percentage of non_Diabet_risk is 34.9\n",
      "percentage of Fraud Risk 65.1\n"
     ]
    }
   ],
   "source": [
    "count_Diabet_risk = len(df[df['Outcome']==0])\n",
    "count_non_Diabet_risk = len(df[df['Outcome']==1])\n",
    "pct_of_non_Diabet_risk =count_non_Diabet_risk/(count_non_Diabet_risk +count_Diabet_risk )\n",
    "print(\"percentage of non_Diabet_risk is\", round(pct_of_non_Diabet_risk*100,2))\n",
    "pct_of_Diabet_risk= count_Diabet_risk/(count_non_Diabet_risk +count_Diabet_risk)\n",
    "print(\"percentage of Fraud Risk\", round(pct_of_Diabet_risk*100,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select input and target variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label encoding the data \n",
    "from sklearn.preprocessing import LabelEncoder \n",
    "  \n",
    "le = LabelEncoder() \n",
    "  \n",
    "df_treated['Age']= le.fit_transform(df_treated['Age']) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72.0</td>\n",
       "      <td>35</td>\n",
       "      <td>30.5</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66.0</td>\n",
       "      <td>29</td>\n",
       "      <td>30.5</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64.0</td>\n",
       "      <td>23</td>\n",
       "      <td>30.5</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66.0</td>\n",
       "      <td>23</td>\n",
       "      <td>94.0</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40.0</td>\n",
       "      <td>35</td>\n",
       "      <td>168.0</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>10</td>\n",
       "      <td>101</td>\n",
       "      <td>76.0</td>\n",
       "      <td>48</td>\n",
       "      <td>180.0</td>\n",
       "      <td>32.9</td>\n",
       "      <td>0.171</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>2</td>\n",
       "      <td>122</td>\n",
       "      <td>70.0</td>\n",
       "      <td>27</td>\n",
       "      <td>30.5</td>\n",
       "      <td>36.8</td>\n",
       "      <td>0.340</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>5</td>\n",
       "      <td>121</td>\n",
       "      <td>72.0</td>\n",
       "      <td>23</td>\n",
       "      <td>112.0</td>\n",
       "      <td>26.2</td>\n",
       "      <td>0.245</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>1</td>\n",
       "      <td>126</td>\n",
       "      <td>60.0</td>\n",
       "      <td>23</td>\n",
       "      <td>30.5</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.349</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>70.0</td>\n",
       "      <td>31</td>\n",
       "      <td>30.5</td>\n",
       "      <td>30.4</td>\n",
       "      <td>0.315</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>768 rows  9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0              6      148           72.0             35     30.5  33.6   \n",
       "1              1       85           66.0             29     30.5  26.6   \n",
       "2              8      183           64.0             23     30.5  23.3   \n",
       "3              1       89           66.0             23     94.0  28.1   \n",
       "4              0      137           40.0             35    168.0  43.1   \n",
       "..           ...      ...            ...            ...      ...   ...   \n",
       "763           10      101           76.0             48    180.0  32.9   \n",
       "764            2      122           70.0             27     30.5  36.8   \n",
       "765            5      121           72.0             23    112.0  26.2   \n",
       "766            1      126           60.0             23     30.5  30.1   \n",
       "767            1       93           70.0             31     30.5  30.4   \n",
       "\n",
       "     DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                       0.627    0        1  \n",
       "1                       0.351    1        0  \n",
       "2                       0.672    1        1  \n",
       "3                       0.167    1        0  \n",
       "4                       2.288    1        1  \n",
       "..                        ...  ...      ...  \n",
       "763                     0.171    0        0  \n",
       "764                     0.340    1        0  \n",
       "765                     0.245    1        0  \n",
       "766                     0.349    1        1  \n",
       "767                     0.315    1        0  \n",
       "\n",
       "[768 rows x 9 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_treated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "# creating instance of one-hot-encoder\n",
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "# passing bridge-types-cat column (label encoded values of bridge_types)\n",
    "enc_df = pd.DataFrame(enc.fit_transform(df_treated[['Age']]).toarray())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72.0</td>\n",
       "      <td>35</td>\n",
       "      <td>30.5</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66.0</td>\n",
       "      <td>29</td>\n",
       "      <td>30.5</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64.0</td>\n",
       "      <td>23</td>\n",
       "      <td>30.5</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66.0</td>\n",
       "      <td>23</td>\n",
       "      <td>94.0</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40.0</td>\n",
       "      <td>35</td>\n",
       "      <td>168.0</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>10</td>\n",
       "      <td>101</td>\n",
       "      <td>76.0</td>\n",
       "      <td>48</td>\n",
       "      <td>180.0</td>\n",
       "      <td>32.9</td>\n",
       "      <td>0.171</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>2</td>\n",
       "      <td>122</td>\n",
       "      <td>70.0</td>\n",
       "      <td>27</td>\n",
       "      <td>30.5</td>\n",
       "      <td>36.8</td>\n",
       "      <td>0.340</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>5</td>\n",
       "      <td>121</td>\n",
       "      <td>72.0</td>\n",
       "      <td>23</td>\n",
       "      <td>112.0</td>\n",
       "      <td>26.2</td>\n",
       "      <td>0.245</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>1</td>\n",
       "      <td>126</td>\n",
       "      <td>60.0</td>\n",
       "      <td>23</td>\n",
       "      <td>30.5</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.349</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>70.0</td>\n",
       "      <td>31</td>\n",
       "      <td>30.5</td>\n",
       "      <td>30.4</td>\n",
       "      <td>0.315</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>768 rows  8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0              6      148           72.0             35     30.5  33.6   \n",
       "1              1       85           66.0             29     30.5  26.6   \n",
       "2              8      183           64.0             23     30.5  23.3   \n",
       "3              1       89           66.0             23     94.0  28.1   \n",
       "4              0      137           40.0             35    168.0  43.1   \n",
       "..           ...      ...            ...            ...      ...   ...   \n",
       "763           10      101           76.0             48    180.0  32.9   \n",
       "764            2      122           70.0             27     30.5  36.8   \n",
       "765            5      121           72.0             23    112.0  26.2   \n",
       "766            1      126           60.0             23     30.5  30.1   \n",
       "767            1       93           70.0             31     30.5  30.4   \n",
       "\n",
       "     DiabetesPedigreeFunction  Outcome  \n",
       "0                       0.627        1  \n",
       "1                       0.351        0  \n",
       "2                       0.672        1  \n",
       "3                       0.167        0  \n",
       "4                       2.288        1  \n",
       "..                        ...      ...  \n",
       "763                     0.171        0  \n",
       "764                     0.340        0  \n",
       "765                     0.245        0  \n",
       "766                     0.349        1  \n",
       "767                     0.315        0  \n",
       "\n",
       "[768 rows x 8 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final = df_treated.drop(['Age'], axis = 1) \n",
    "df_final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72.0</td>\n",
       "      <td>35</td>\n",
       "      <td>30.5</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66.0</td>\n",
       "      <td>29</td>\n",
       "      <td>30.5</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64.0</td>\n",
       "      <td>23</td>\n",
       "      <td>30.5</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66.0</td>\n",
       "      <td>23</td>\n",
       "      <td>94.0</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40.0</td>\n",
       "      <td>35</td>\n",
       "      <td>168.0</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>10</td>\n",
       "      <td>101</td>\n",
       "      <td>76.0</td>\n",
       "      <td>48</td>\n",
       "      <td>180.0</td>\n",
       "      <td>32.9</td>\n",
       "      <td>0.171</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>2</td>\n",
       "      <td>122</td>\n",
       "      <td>70.0</td>\n",
       "      <td>27</td>\n",
       "      <td>30.5</td>\n",
       "      <td>36.8</td>\n",
       "      <td>0.340</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>5</td>\n",
       "      <td>121</td>\n",
       "      <td>72.0</td>\n",
       "      <td>23</td>\n",
       "      <td>112.0</td>\n",
       "      <td>26.2</td>\n",
       "      <td>0.245</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>1</td>\n",
       "      <td>126</td>\n",
       "      <td>60.0</td>\n",
       "      <td>23</td>\n",
       "      <td>30.5</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.349</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>70.0</td>\n",
       "      <td>31</td>\n",
       "      <td>30.5</td>\n",
       "      <td>30.4</td>\n",
       "      <td>0.315</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>768 rows  9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0              6      148           72.0             35     30.5  33.6   \n",
       "1              1       85           66.0             29     30.5  26.6   \n",
       "2              8      183           64.0             23     30.5  23.3   \n",
       "3              1       89           66.0             23     94.0  28.1   \n",
       "4              0      137           40.0             35    168.0  43.1   \n",
       "..           ...      ...            ...            ...      ...   ...   \n",
       "763           10      101           76.0             48    180.0  32.9   \n",
       "764            2      122           70.0             27     30.5  36.8   \n",
       "765            5      121           72.0             23    112.0  26.2   \n",
       "766            1      126           60.0             23     30.5  30.1   \n",
       "767            1       93           70.0             31     30.5  30.4   \n",
       "\n",
       "     DiabetesPedigreeFunction    0    1  \n",
       "0                       0.627  1.0  0.0  \n",
       "1                       0.351  0.0  1.0  \n",
       "2                       0.672  0.0  1.0  \n",
       "3                       0.167  0.0  1.0  \n",
       "4                       2.288  0.0  1.0  \n",
       "..                        ...  ...  ...  \n",
       "763                     0.171  1.0  0.0  \n",
       "764                     0.340  0.0  1.0  \n",
       "765                     0.245  0.0  1.0  \n",
       "766                     0.349  0.0  1.0  \n",
       "767                     0.315  0.0  1.0  \n",
       "\n",
       "[768 rows x 9 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df_final[df_final.columns[0:7]]\n",
    "# merge one hot encoded 'Age' column with the other features of the dataframe\n",
    "X = X.join(enc_df) \n",
    "X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>768 rows  1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Outcome\n",
       "0          1\n",
       "1          0\n",
       "2          1\n",
       "3          0\n",
       "4          1\n",
       "..       ...\n",
       "763        0\n",
       "764        0\n",
       "765        0\n",
       "766        1\n",
       "767        0\n",
       "\n",
       "[768 rows x 1 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df_final[df_final.columns[7:]]\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_x Shape ::  (537, 9)\n",
      "Train_y Shape ::  (537, 1)\n",
      "Test_x Shape ::  (231, 9)\n",
      "Test_y Shape ::  (231, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"Train_x Shape :: \", X_train.shape)\n",
    "print(\"Train_y Shape :: \", y_train.shape)\n",
    "print(\"Test_x Shape :: \", X_test.shape)\n",
    "print(\"Test_y Shape :: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_train = lgb.Dataset(X_train, label=y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building the model with default parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Completion Time :  881.1715593338013\n",
      "Trained LGBM model ::  LGBMClassifier(metric='binary_logloss', objective='binary')\n"
     ]
    }
   ],
   "source": [
    "def LGBM_classifier(features, target):\n",
    "    \"\"\"\n",
    "    To train the LGBM classifier with features and target data\n",
    "    :param features:\n",
    "    :param target:\n",
    "    :return: trained LGBM classifier\n",
    "    \"\"\"\n",
    "    model = LGBMClassifier(metric='binary_logloss', objective='binary')\n",
    "    model.fit(features, target)\n",
    "    return model\n",
    "\n",
    "start = time.time()\n",
    "trained_model = LGBM_classifier(X_train, y_train.values.ravel())\n",
    "print(\"> Completion Time : \", time.time() - start)\n",
    "print(\"Trained LGBM model :: \", trained_model)\n",
    "predictions = trained_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy ::  1.0\n",
      "LGBM Model Test Accuracy is ::  0.7619047619047619\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Accuracy :: \", accuracy_score(y_train, trained_model.predict(X_train)))\n",
    "print(\"LGBM Model Test Accuracy is :: \", accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check The feature Importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f435105b050>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "feat_imp = pd.Series(trained_model.feature_importances_, index=X.columns)\n",
    "feat_imp.nlargest(12).plot(kind='barh', figsize=(8,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unveiling Diabetes Detection AI Model for Data Scientist using Boolean Rule Column Generation explainer and Logistic Rule Regression models provided by AI 360 Explainability Toolkit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data scientist: Boolean Rule and Logistic Rule Regression models\n",
    "In evaluating a machine learning model for deployment, a data scientist would ideally like to understand the behavior of the model as a whole, not just in specific instances. This is especially true in regulated industries such as banking where higher standards of explainability may be required. \n",
    "\n",
    "For example, the data scientist may have to present the model to:\n",
    "\n",
    "1) technical and business managers for review before deployment, 2) a lending expert to compare the model to the expert's knowledge, or 3) a regulator to check for compliance.\n",
    "\n",
    "BRCG, which is designed to produce a very simple OR-of-ANDs rule (known more formally as disjunctive normal form, DNF) or alternatively an AND-of-ORs rule (conjunctive normal form, CNF) to predict whether an applicant is not at Fraud risk (Y = 1). For a binary classification problem such as we have here, a DNF rule is equivalent to a rule set, where AND clauses in the DNF correspond to individual rules in the rule set. Furthermore, it can be shown that a CNF rule for Y = 1 is equivalent to a DNF rule for Y = 0.\n",
    "BRCG is distinguished by its use of the optimization technique of column generation to search the space of possible clauses, which is exponential in size. To learn more about column generation, please see NeurIPS paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72.0</td>\n",
       "      <td>35</td>\n",
       "      <td>30.5</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66.0</td>\n",
       "      <td>29</td>\n",
       "      <td>30.5</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64.0</td>\n",
       "      <td>23</td>\n",
       "      <td>30.5</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66.0</td>\n",
       "      <td>23</td>\n",
       "      <td>94.0</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40.0</td>\n",
       "      <td>35</td>\n",
       "      <td>168.0</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>10</td>\n",
       "      <td>101</td>\n",
       "      <td>76.0</td>\n",
       "      <td>48</td>\n",
       "      <td>180.0</td>\n",
       "      <td>32.9</td>\n",
       "      <td>0.171</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>2</td>\n",
       "      <td>122</td>\n",
       "      <td>70.0</td>\n",
       "      <td>27</td>\n",
       "      <td>30.5</td>\n",
       "      <td>36.8</td>\n",
       "      <td>0.340</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>5</td>\n",
       "      <td>121</td>\n",
       "      <td>72.0</td>\n",
       "      <td>23</td>\n",
       "      <td>112.0</td>\n",
       "      <td>26.2</td>\n",
       "      <td>0.245</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>1</td>\n",
       "      <td>126</td>\n",
       "      <td>60.0</td>\n",
       "      <td>23</td>\n",
       "      <td>30.5</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.349</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>70.0</td>\n",
       "      <td>31</td>\n",
       "      <td>30.5</td>\n",
       "      <td>30.4</td>\n",
       "      <td>0.315</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>768 rows  9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0              6      148           72.0             35     30.5  33.6   \n",
       "1              1       85           66.0             29     30.5  26.6   \n",
       "2              8      183           64.0             23     30.5  23.3   \n",
       "3              1       89           66.0             23     94.0  28.1   \n",
       "4              0      137           40.0             35    168.0  43.1   \n",
       "..           ...      ...            ...            ...      ...   ...   \n",
       "763           10      101           76.0             48    180.0  32.9   \n",
       "764            2      122           70.0             27     30.5  36.8   \n",
       "765            5      121           72.0             23    112.0  26.2   \n",
       "766            1      126           60.0             23     30.5  30.1   \n",
       "767            1       93           70.0             31     30.5  30.4   \n",
       "\n",
       "     DiabetesPedigreeFunction    0    1  \n",
       "0                       0.627  1.0  0.0  \n",
       "1                       0.351  0.0  1.0  \n",
       "2                       0.672  0.0  1.0  \n",
       "3                       0.167  0.0  1.0  \n",
       "4                       2.288  0.0  1.0  \n",
       "..                        ...  ...  ...  \n",
       "763                     0.171  1.0  0.0  \n",
       "764                     0.340  0.0  1.0  \n",
       "765                     0.245  0.0  1.0  \n",
       "766                     0.349  0.0  1.0  \n",
       "767                     0.315  0.0  1.0  \n",
       "\n",
       "[768 rows x 9 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df_final[df_final.columns[0:7]]\n",
    "# merge one hot encoded 'Age' column with the other features of the dataframe\n",
    "X = X.join(enc_df) \n",
    "X\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      1\n",
       "1      0\n",
       "2      1\n",
       "3      0\n",
       "4      1\n",
       "      ..\n",
       "763    0\n",
       "764    0\n",
       "765    0\n",
       "766    1\n",
       "767    0\n",
       "Name: Outcome, Length: 768, dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df_final[\"Outcome\"]\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768, 9)\n",
      "(768,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>580</th>\n",
       "      <td>0</td>\n",
       "      <td>151</td>\n",
       "      <td>90.0</td>\n",
       "      <td>46</td>\n",
       "      <td>30.5</td>\n",
       "      <td>42.1</td>\n",
       "      <td>0.371</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>1</td>\n",
       "      <td>83</td>\n",
       "      <td>68.0</td>\n",
       "      <td>23</td>\n",
       "      <td>30.5</td>\n",
       "      <td>18.2</td>\n",
       "      <td>0.624</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>2</td>\n",
       "      <td>122</td>\n",
       "      <td>70.0</td>\n",
       "      <td>27</td>\n",
       "      <td>30.5</td>\n",
       "      <td>36.8</td>\n",
       "      <td>0.340</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>4</td>\n",
       "      <td>146</td>\n",
       "      <td>78.0</td>\n",
       "      <td>23</td>\n",
       "      <td>30.5</td>\n",
       "      <td>38.5</td>\n",
       "      <td>0.520</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>757</th>\n",
       "      <td>0</td>\n",
       "      <td>123</td>\n",
       "      <td>72.0</td>\n",
       "      <td>23</td>\n",
       "      <td>30.5</td>\n",
       "      <td>36.3</td>\n",
       "      <td>0.258</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "580            0      151           90.0             46     30.5  42.1   \n",
       "418            1       83           68.0             23     30.5  18.2   \n",
       "764            2      122           70.0             27     30.5  36.8   \n",
       "363            4      146           78.0             23     30.5  38.5   \n",
       "757            0      123           72.0             23     30.5  36.3   \n",
       "\n",
       "     DiabetesPedigreeFunction    0    1  \n",
       "580                     0.371  0.0  1.0  \n",
       "418                     0.624  0.0  1.0  \n",
       "764                     0.340  0.0  1.0  \n",
       "363                     0.520  1.0  0.0  \n",
       "757                     0.258  1.0  0.0  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "dfTrain, dfTest, yTrain, yTest = train_test_split(X, y, random_state=0,test_size=0.3)\n",
    "dfTrain.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binarize data and also return standardized ordinal features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>operation</th>\n",
       "      <th colspan=\"9\" halign=\"left\">&lt;=</th>\n",
       "      <th colspan=\"9\" halign=\"left\">&gt;</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>value</th>\n",
       "      <th>86.6</th>\n",
       "      <th>95.2</th>\n",
       "      <th>102.8</th>\n",
       "      <th>111.0</th>\n",
       "      <th>118.0</th>\n",
       "      <th>125.6</th>\n",
       "      <th>135.2</th>\n",
       "      <th>147.0</th>\n",
       "      <th>168.0</th>\n",
       "      <th>86.6</th>\n",
       "      <th>95.2</th>\n",
       "      <th>102.8</th>\n",
       "      <th>111.0</th>\n",
       "      <th>118.0</th>\n",
       "      <th>125.6</th>\n",
       "      <th>135.2</th>\n",
       "      <th>147.0</th>\n",
       "      <th>168.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>580</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>757</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "operation    <=                                                     >        \\\n",
       "value     86.6  95.2  102.8 111.0 118.0 125.6 135.2 147.0 168.0 86.6  95.2    \n",
       "580           0     0     0     0     0     0     0     0     1     1     1   \n",
       "418           1     1     1     1     1     1     1     1     1     0     0   \n",
       "764           0     0     0     0     0     1     1     1     1     1     1   \n",
       "363           0     0     0     0     0     0     0     1     1     1     1   \n",
       "757           0     0     0     0     0     1     1     1     1     1     1   \n",
       "\n",
       "operation                                            \n",
       "value     102.8 111.0 118.0 125.6 135.2 147.0 168.0  \n",
       "580           1     1     1     1     1     1     0  \n",
       "418           0     0     0     0     0     0     0  \n",
       "764           1     1     1     0     0     0     0  \n",
       "363           1     1     1     1     1     0     0  \n",
       "757           1     1     1     0     0     0     0  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Binarize data and also return standardized ordinal features\n",
    "from aix360.algorithms.rbm import FeatureBinarizer\n",
    "fb = FeatureBinarizer(negations=True, returnOrd=True)\n",
    "dfTrain, dfTrainStd = fb.fit_transform(dfTrain)\n",
    "dfTest, dfTestStd = fb.transform(dfTest)\n",
    "dfTrain['Glucose'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning CNF rule with complexity parameters lambda0=0.001, lambda1=0.001\n",
      "Initial LP solved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages/cvxpy/expressions/expression.py:550: UserWarning: \n",
      "This use of ``*`` has resulted in matrix multiplication.\n",
      "Using ``*`` for matrix multiplication has been deprecated since CVXPY 1.1.\n",
      "    Use ``*`` for matrix-scalar and vector-scalar multiplication.\n",
      "    Use ``@`` for matrix-matrix and matrix-vector multiplication.\n",
      "    Use ``multiply`` for elementwise multiplication.\n",
      "\n",
      "  warnings.warn(__STAR_MATMUL_WARNING__, UserWarning)\n",
      "/opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages/cvxpy/expressions/expression.py:550: UserWarning: \n",
      "This use of ``*`` has resulted in matrix multiplication.\n",
      "Using ``*`` for matrix multiplication has been deprecated since CVXPY 1.1.\n",
      "    Use ``*`` for matrix-scalar and vector-scalar multiplication.\n",
      "    Use ``@`` for matrix-matrix and matrix-vector multiplication.\n",
      "    Use ``multiply`` for elementwise multiplication.\n",
      "\n",
      "  warnings.warn(__STAR_MATMUL_WARNING__, UserWarning)\n",
      "/opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages/cvxpy/expressions/expression.py:550: UserWarning: \n",
      "This use of ``*`` has resulted in matrix multiplication.\n",
      "Using ``*`` for matrix multiplication has been deprecated since CVXPY 1.1.\n",
      "    Use ``*`` for matrix-scalar and vector-scalar multiplication.\n",
      "    Use ``@`` for matrix-matrix and matrix-vector multiplication.\n",
      "    Use ``multiply`` for elementwise multiplication.\n",
      "\n",
      "  warnings.warn(__STAR_MATMUL_WARNING__, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1, Objective: 0.2534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages/cvxpy/expressions/expression.py:550: UserWarning: \n",
      "This use of ``*`` has resulted in matrix multiplication.\n",
      "Using ``*`` for matrix multiplication has been deprecated since CVXPY 1.1.\n",
      "    Use ``*`` for matrix-scalar and vector-scalar multiplication.\n",
      "    Use ``@`` for matrix-matrix and matrix-vector multiplication.\n",
      "    Use ``multiply`` for elementwise multiplication.\n",
      "\n",
      "  warnings.warn(__STAR_MATMUL_WARNING__, UserWarning)\n",
      "/opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages/cvxpy/expressions/expression.py:550: UserWarning: \n",
      "This use of ``*`` has resulted in matrix multiplication.\n",
      "Using ``*`` for matrix multiplication has been deprecated since CVXPY 1.1.\n",
      "    Use ``*`` for matrix-scalar and vector-scalar multiplication.\n",
      "    Use ``@`` for matrix-matrix and matrix-vector multiplication.\n",
      "    Use ``multiply`` for elementwise multiplication.\n",
      "\n",
      "  warnings.warn(__STAR_MATMUL_WARNING__, UserWarning)\n",
      "/opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages/cvxpy/expressions/expression.py:550: UserWarning: \n",
      "This use of ``*`` has resulted in matrix multiplication.\n",
      "Using ``*`` for matrix multiplication has been deprecated since CVXPY 1.1.\n",
      "    Use ``*`` for matrix-scalar and vector-scalar multiplication.\n",
      "    Use ``@`` for matrix-matrix and matrix-vector multiplication.\n",
      "    Use ``multiply`` for elementwise multiplication.\n",
      "\n",
      "  warnings.warn(__STAR_MATMUL_WARNING__, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 2, Objective: 0.2484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages/cvxpy/expressions/expression.py:550: UserWarning: \n",
      "This use of ``*`` has resulted in matrix multiplication.\n",
      "Using ``*`` for matrix multiplication has been deprecated since CVXPY 1.1.\n",
      "    Use ``*`` for matrix-scalar and vector-scalar multiplication.\n",
      "    Use ``@`` for matrix-matrix and matrix-vector multiplication.\n",
      "    Use ``multiply`` for elementwise multiplication.\n",
      "\n",
      "  warnings.warn(__STAR_MATMUL_WARNING__, UserWarning)\n",
      "/opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages/cvxpy/expressions/expression.py:550: UserWarning: \n",
      "This use of ``*`` has resulted in matrix multiplication.\n",
      "Using ``*`` for matrix multiplication has been deprecated since CVXPY 1.1.\n",
      "    Use ``*`` for matrix-scalar and vector-scalar multiplication.\n",
      "    Use ``@`` for matrix-matrix and matrix-vector multiplication.\n",
      "    Use ``multiply`` for elementwise multiplication.\n",
      "\n",
      "  warnings.warn(__STAR_MATMUL_WARNING__, UserWarning)\n",
      "/opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages/cvxpy/expressions/expression.py:550: UserWarning: \n",
      "This use of ``*`` has resulted in matrix multiplication.\n",
      "Using ``*`` for matrix multiplication has been deprecated since CVXPY 1.1.\n",
      "    Use ``*`` for matrix-scalar and vector-scalar multiplication.\n",
      "    Use ``@`` for matrix-matrix and matrix-vector multiplication.\n",
      "    Use ``multiply`` for elementwise multiplication.\n",
      "\n",
      "  warnings.warn(__STAR_MATMUL_WARNING__, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 3, Objective: 0.2471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages/cvxpy/expressions/expression.py:550: UserWarning: \n",
      "This use of ``*`` has resulted in matrix multiplication.\n",
      "Using ``*`` for matrix multiplication has been deprecated since CVXPY 1.1.\n",
      "    Use ``*`` for matrix-scalar and vector-scalar multiplication.\n",
      "    Use ``@`` for matrix-matrix and matrix-vector multiplication.\n",
      "    Use ``multiply`` for elementwise multiplication.\n",
      "\n",
      "  warnings.warn(__STAR_MATMUL_WARNING__, UserWarning)\n",
      "/opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages/cvxpy/expressions/expression.py:550: UserWarning: \n",
      "This use of ``*`` has resulted in matrix multiplication.\n",
      "Using ``*`` for matrix multiplication has been deprecated since CVXPY 1.1.\n",
      "    Use ``*`` for matrix-scalar and vector-scalar multiplication.\n",
      "    Use ``@`` for matrix-matrix and matrix-vector multiplication.\n",
      "    Use ``multiply`` for elementwise multiplication.\n",
      "\n",
      "  warnings.warn(__STAR_MATMUL_WARNING__, UserWarning)\n",
      "/opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages/cvxpy/expressions/expression.py:550: UserWarning: \n",
      "This use of ``*`` has resulted in matrix multiplication.\n",
      "Using ``*`` for matrix multiplication has been deprecated since CVXPY 1.1.\n",
      "    Use ``*`` for matrix-scalar and vector-scalar multiplication.\n",
      "    Use ``@`` for matrix-matrix and matrix-vector multiplication.\n",
      "    Use ``multiply`` for elementwise multiplication.\n",
      "\n",
      "  warnings.warn(__STAR_MATMUL_WARNING__, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 4, Objective: 0.2424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages/cvxpy/expressions/expression.py:550: UserWarning: \n",
      "This use of ``*`` has resulted in matrix multiplication.\n",
      "Using ``*`` for matrix multiplication has been deprecated since CVXPY 1.1.\n",
      "    Use ``*`` for matrix-scalar and vector-scalar multiplication.\n",
      "    Use ``@`` for matrix-matrix and matrix-vector multiplication.\n",
      "    Use ``multiply`` for elementwise multiplication.\n",
      "\n",
      "  warnings.warn(__STAR_MATMUL_WARNING__, UserWarning)\n",
      "/opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages/cvxpy/expressions/expression.py:550: UserWarning: \n",
      "This use of ``*`` has resulted in matrix multiplication.\n",
      "Using ``*`` for matrix multiplication has been deprecated since CVXPY 1.1.\n",
      "    Use ``*`` for matrix-scalar and vector-scalar multiplication.\n",
      "    Use ``@`` for matrix-matrix and matrix-vector multiplication.\n",
      "    Use ``multiply`` for elementwise multiplication.\n",
      "\n",
      "  warnings.warn(__STAR_MATMUL_WARNING__, UserWarning)\n",
      "/opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages/cvxpy/expressions/expression.py:550: UserWarning: \n",
      "This use of ``*`` has resulted in matrix multiplication.\n",
      "Using ``*`` for matrix multiplication has been deprecated since CVXPY 1.1.\n",
      "    Use ``*`` for matrix-scalar and vector-scalar multiplication.\n",
      "    Use ``@`` for matrix-matrix and matrix-vector multiplication.\n",
      "    Use ``multiply`` for elementwise multiplication.\n",
      "\n",
      "  warnings.warn(__STAR_MATMUL_WARNING__, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 5, Objective: 0.2395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages/cvxpy/expressions/expression.py:550: UserWarning: \n",
      "This use of ``*`` has resulted in matrix multiplication.\n",
      "Using ``*`` for matrix multiplication has been deprecated since CVXPY 1.1.\n",
      "    Use ``*`` for matrix-scalar and vector-scalar multiplication.\n",
      "    Use ``@`` for matrix-matrix and matrix-vector multiplication.\n",
      "    Use ``multiply`` for elementwise multiplication.\n",
      "\n",
      "  warnings.warn(__STAR_MATMUL_WARNING__, UserWarning)\n",
      "/opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages/cvxpy/expressions/expression.py:550: UserWarning: \n",
      "This use of ``*`` has resulted in matrix multiplication.\n",
      "Using ``*`` for matrix multiplication has been deprecated since CVXPY 1.1.\n",
      "    Use ``*`` for matrix-scalar and vector-scalar multiplication.\n",
      "    Use ``@`` for matrix-matrix and matrix-vector multiplication.\n",
      "    Use ``multiply`` for elementwise multiplication.\n",
      "\n",
      "  warnings.warn(__STAR_MATMUL_WARNING__, UserWarning)\n",
      "/opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages/cvxpy/expressions/expression.py:550: UserWarning: \n",
      "This use of ``*`` has resulted in matrix multiplication.\n",
      "Using ``*`` for matrix multiplication has been deprecated since CVXPY 1.1.\n",
      "    Use ``*`` for matrix-scalar and vector-scalar multiplication.\n",
      "    Use ``@`` for matrix-matrix and matrix-vector multiplication.\n",
      "    Use ``multiply`` for elementwise multiplication.\n",
      "\n",
      "  warnings.warn(__STAR_MATMUL_WARNING__, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 6, Objective: 0.2377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages/cvxpy/expressions/expression.py:550: UserWarning: \n",
      "This use of ``*`` has resulted in matrix multiplication.\n",
      "Using ``*`` for matrix multiplication has been deprecated since CVXPY 1.1.\n",
      "    Use ``*`` for matrix-scalar and vector-scalar multiplication.\n",
      "    Use ``@`` for matrix-matrix and matrix-vector multiplication.\n",
      "    Use ``multiply`` for elementwise multiplication.\n",
      "\n",
      "  warnings.warn(__STAR_MATMUL_WARNING__, UserWarning)\n",
      "/opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages/cvxpy/expressions/expression.py:550: UserWarning: \n",
      "This use of ``*`` has resulted in matrix multiplication.\n",
      "Using ``*`` for matrix multiplication has been deprecated since CVXPY 1.1.\n",
      "    Use ``*`` for matrix-scalar and vector-scalar multiplication.\n",
      "    Use ``@`` for matrix-matrix and matrix-vector multiplication.\n",
      "    Use ``multiply`` for elementwise multiplication.\n",
      "\n",
      "  warnings.warn(__STAR_MATMUL_WARNING__, UserWarning)\n",
      "/opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages/cvxpy/expressions/expression.py:550: UserWarning: \n",
      "This use of ``*`` has resulted in matrix multiplication.\n",
      "Using ``*`` for matrix multiplication has been deprecated since CVXPY 1.1.\n",
      "    Use ``*`` for matrix-scalar and vector-scalar multiplication.\n",
      "    Use ``@`` for matrix-matrix and matrix-vector multiplication.\n",
      "    Use ``multiply`` for elementwise multiplication.\n",
      "\n",
      "  warnings.warn(__STAR_MATMUL_WARNING__, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 7, Objective: 0.2353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages/cvxpy/expressions/expression.py:550: UserWarning: \n",
      "This use of ``*`` has resulted in matrix multiplication.\n",
      "Using ``*`` for matrix multiplication has been deprecated since CVXPY 1.1.\n",
      "    Use ``*`` for matrix-scalar and vector-scalar multiplication.\n",
      "    Use ``@`` for matrix-matrix and matrix-vector multiplication.\n",
      "    Use ``multiply`` for elementwise multiplication.\n",
      "\n",
      "  warnings.warn(__STAR_MATMUL_WARNING__, UserWarning)\n",
      "/opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages/cvxpy/expressions/expression.py:550: UserWarning: \n",
      "This use of ``*`` has resulted in matrix multiplication.\n",
      "Using ``*`` for matrix multiplication has been deprecated since CVXPY 1.1.\n",
      "    Use ``*`` for matrix-scalar and vector-scalar multiplication.\n",
      "    Use ``@`` for matrix-matrix and matrix-vector multiplication.\n",
      "    Use ``multiply`` for elementwise multiplication.\n",
      "\n",
      "  warnings.warn(__STAR_MATMUL_WARNING__, UserWarning)\n",
      "/opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages/cvxpy/expressions/expression.py:550: UserWarning: \n",
      "This use of ``*`` has resulted in matrix multiplication.\n",
      "Using ``*`` for matrix multiplication has been deprecated since CVXPY 1.1.\n",
      "    Use ``*`` for matrix-scalar and vector-scalar multiplication.\n",
      "    Use ``@`` for matrix-matrix and matrix-vector multiplication.\n",
      "    Use ``multiply`` for elementwise multiplication.\n",
      "\n",
      "  warnings.warn(__STAR_MATMUL_WARNING__, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 8, Objective: 0.2346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages/cvxpy/expressions/expression.py:550: UserWarning: \n",
      "This use of ``*`` has resulted in matrix multiplication.\n",
      "Using ``*`` for matrix multiplication has been deprecated since CVXPY 1.1.\n",
      "    Use ``*`` for matrix-scalar and vector-scalar multiplication.\n",
      "    Use ``@`` for matrix-matrix and matrix-vector multiplication.\n",
      "    Use ``multiply`` for elementwise multiplication.\n",
      "\n",
      "  warnings.warn(__STAR_MATMUL_WARNING__, UserWarning)\n",
      "/opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages/cvxpy/expressions/expression.py:550: UserWarning: \n",
      "This use of ``*`` has resulted in matrix multiplication.\n",
      "Using ``*`` for matrix multiplication has been deprecated since CVXPY 1.1.\n",
      "    Use ``*`` for matrix-scalar and vector-scalar multiplication.\n",
      "    Use ``@`` for matrix-matrix and matrix-vector multiplication.\n",
      "    Use ``multiply`` for elementwise multiplication.\n",
      "\n",
      "  warnings.warn(__STAR_MATMUL_WARNING__, UserWarning)\n",
      "/opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages/cvxpy/expressions/expression.py:550: UserWarning: \n",
      "This use of ``*`` has resulted in matrix multiplication.\n",
      "Using ``*`` for matrix multiplication has been deprecated since CVXPY 1.1.\n",
      "    Use ``*`` for matrix-scalar and vector-scalar multiplication.\n",
      "    Use ``@`` for matrix-matrix and matrix-vector multiplication.\n",
      "    Use ``multiply`` for elementwise multiplication.\n",
      "\n",
      "  warnings.warn(__STAR_MATMUL_WARNING__, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 9, Objective: 0.2326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages/cvxpy/expressions/expression.py:550: UserWarning: \n",
      "This use of ``*`` has resulted in matrix multiplication.\n",
      "Using ``*`` for matrix multiplication has been deprecated since CVXPY 1.1.\n",
      "    Use ``*`` for matrix-scalar and vector-scalar multiplication.\n",
      "    Use ``@`` for matrix-matrix and matrix-vector multiplication.\n",
      "    Use ``multiply`` for elementwise multiplication.\n",
      "\n",
      "  warnings.warn(__STAR_MATMUL_WARNING__, UserWarning)\n",
      "/opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages/cvxpy/expressions/expression.py:550: UserWarning: \n",
      "This use of ``*`` has resulted in matrix multiplication.\n",
      "Using ``*`` for matrix multiplication has been deprecated since CVXPY 1.1.\n",
      "    Use ``*`` for matrix-scalar and vector-scalar multiplication.\n",
      "    Use ``@`` for matrix-matrix and matrix-vector multiplication.\n",
      "    Use ``multiply`` for elementwise multiplication.\n",
      "\n",
      "  warnings.warn(__STAR_MATMUL_WARNING__, UserWarning)\n",
      "/opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages/cvxpy/expressions/expression.py:550: UserWarning: \n",
      "This use of ``*`` has resulted in matrix multiplication.\n",
      "Using ``*`` for matrix multiplication has been deprecated since CVXPY 1.1.\n",
      "    Use ``*`` for matrix-scalar and vector-scalar multiplication.\n",
      "    Use ``@`` for matrix-matrix and matrix-vector multiplication.\n",
      "    Use ``multiply`` for elementwise multiplication.\n",
      "\n",
      "  warnings.warn(__STAR_MATMUL_WARNING__, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 10, Objective: 0.2313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages/cvxpy/expressions/expression.py:550: UserWarning: \n",
      "This use of ``*`` has resulted in matrix multiplication.\n",
      "Using ``*`` for matrix multiplication has been deprecated since CVXPY 1.1.\n",
      "    Use ``*`` for matrix-scalar and vector-scalar multiplication.\n",
      "    Use ``@`` for matrix-matrix and matrix-vector multiplication.\n",
      "    Use ``multiply`` for elementwise multiplication.\n",
      "\n",
      "  warnings.warn(__STAR_MATMUL_WARNING__, UserWarning)\n",
      "/opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages/cvxpy/expressions/expression.py:550: UserWarning: \n",
      "This use of ``*`` has resulted in matrix multiplication.\n",
      "Using ``*`` for matrix multiplication has been deprecated since CVXPY 1.1.\n",
      "    Use ``*`` for matrix-scalar and vector-scalar multiplication.\n",
      "    Use ``@`` for matrix-matrix and matrix-vector multiplication.\n",
      "    Use ``multiply`` for elementwise multiplication.\n",
      "\n",
      "  warnings.warn(__STAR_MATMUL_WARNING__, UserWarning)\n",
      "/opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages/cvxpy/expressions/expression.py:550: UserWarning: \n",
      "This use of ``*`` has resulted in matrix multiplication.\n",
      "Using ``*`` for matrix multiplication has been deprecated since CVXPY 1.1.\n",
      "    Use ``*`` for matrix-scalar and vector-scalar multiplication.\n",
      "    Use ``@`` for matrix-matrix and matrix-vector multiplication.\n",
      "    Use ``multiply`` for elementwise multiplication.\n",
      "\n",
      "  warnings.warn(__STAR_MATMUL_WARNING__, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 11, Objective: 0.2301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages/cvxpy/expressions/expression.py:550: UserWarning: \n",
      "This use of ``*`` has resulted in matrix multiplication.\n",
      "Using ``*`` for matrix multiplication has been deprecated since CVXPY 1.1.\n",
      "    Use ``*`` for matrix-scalar and vector-scalar multiplication.\n",
      "    Use ``@`` for matrix-matrix and matrix-vector multiplication.\n",
      "    Use ``multiply`` for elementwise multiplication.\n",
      "\n",
      "  warnings.warn(__STAR_MATMUL_WARNING__, UserWarning)\n",
      "/opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages/cvxpy/expressions/expression.py:550: UserWarning: \n",
      "This use of ``*`` has resulted in matrix multiplication.\n",
      "Using ``*`` for matrix multiplication has been deprecated since CVXPY 1.1.\n",
      "    Use ``*`` for matrix-scalar and vector-scalar multiplication.\n",
      "    Use ``@`` for matrix-matrix and matrix-vector multiplication.\n",
      "    Use ``multiply`` for elementwise multiplication.\n",
      "\n",
      "  warnings.warn(__STAR_MATMUL_WARNING__, UserWarning)\n",
      "/opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages/cvxpy/expressions/expression.py:550: UserWarning: \n",
      "This use of ``*`` has resulted in matrix multiplication.\n",
      "Using ``*`` for matrix multiplication has been deprecated since CVXPY 1.1.\n",
      "    Use ``*`` for matrix-scalar and vector-scalar multiplication.\n",
      "    Use ``@`` for matrix-matrix and matrix-vector multiplication.\n",
      "    Use ``multiply`` for elementwise multiplication.\n",
      "\n",
      "  warnings.warn(__STAR_MATMUL_WARNING__, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 12, Objective: 0.2300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages/cvxpy/expressions/expression.py:550: UserWarning: \n",
      "This use of ``*`` has resulted in matrix multiplication.\n",
      "Using ``*`` for matrix multiplication has been deprecated since CVXPY 1.1.\n",
      "    Use ``*`` for matrix-scalar and vector-scalar multiplication.\n",
      "    Use ``@`` for matrix-matrix and matrix-vector multiplication.\n",
      "    Use ``multiply`` for elementwise multiplication.\n",
      "\n",
      "  warnings.warn(__STAR_MATMUL_WARNING__, UserWarning)\n",
      "/opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages/cvxpy/expressions/expression.py:550: UserWarning: \n",
      "This use of ``*`` has resulted in matrix multiplication.\n",
      "Using ``*`` for matrix multiplication has been deprecated since CVXPY 1.1.\n",
      "    Use ``*`` for matrix-scalar and vector-scalar multiplication.\n",
      "    Use ``@`` for matrix-matrix and matrix-vector multiplication.\n",
      "    Use ``multiply`` for elementwise multiplication.\n",
      "\n",
      "  warnings.warn(__STAR_MATMUL_WARNING__, UserWarning)\n",
      "/opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages/cvxpy/expressions/expression.py:550: UserWarning: \n",
      "This use of ``*`` has resulted in matrix multiplication.\n",
      "Using ``*`` for matrix multiplication has been deprecated since CVXPY 1.1.\n",
      "    Use ``*`` for matrix-scalar and vector-scalar multiplication.\n",
      "    Use ``@`` for matrix-matrix and matrix-vector multiplication.\n",
      "    Use ``multiply`` for elementwise multiplication.\n",
      "\n",
      "  warnings.warn(__STAR_MATMUL_WARNING__, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 13, Objective: 0.2300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages/cvxpy/expressions/expression.py:550: UserWarning: \n",
      "This use of ``*`` has resulted in matrix multiplication.\n",
      "Using ``*`` for matrix multiplication has been deprecated since CVXPY 1.1.\n",
      "    Use ``*`` for matrix-scalar and vector-scalar multiplication.\n",
      "    Use ``@`` for matrix-matrix and matrix-vector multiplication.\n",
      "    Use ``multiply`` for elementwise multiplication.\n",
      "\n",
      "  warnings.warn(__STAR_MATMUL_WARNING__, UserWarning)\n",
      "/opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages/cvxpy/expressions/expression.py:550: UserWarning: \n",
      "This use of ``*`` has resulted in matrix multiplication.\n",
      "Using ``*`` for matrix multiplication has been deprecated since CVXPY 1.1.\n",
      "    Use ``*`` for matrix-scalar and vector-scalar multiplication.\n",
      "    Use ``@`` for matrix-matrix and matrix-vector multiplication.\n",
      "    Use ``multiply`` for elementwise multiplication.\n",
      "\n",
      "  warnings.warn(__STAR_MATMUL_WARNING__, UserWarning)\n",
      "/opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages/cvxpy/expressions/expression.py:550: UserWarning: \n",
      "This use of ``*`` has resulted in matrix multiplication.\n",
      "Using ``*`` for matrix multiplication has been deprecated since CVXPY 1.1.\n",
      "    Use ``*`` for matrix-scalar and vector-scalar multiplication.\n",
      "    Use ``@`` for matrix-matrix and matrix-vector multiplication.\n",
      "    Use ``multiply`` for elementwise multiplication.\n",
      "\n",
      "  warnings.warn(__STAR_MATMUL_WARNING__, UserWarning)\n",
      "/opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages/aix360/algorithms/rbm/beam_search.py:58: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  zOut = pd.Series(index=X.columns)\n"
     ]
    }
   ],
   "source": [
    "# Instantiate BRCG with small complexity penalty and large beam search width\n",
    "from aix360.algorithms.rbm import BooleanRuleCG\n",
    "br = BooleanRuleCG(lambda0=1e-3, lambda1=1e-3, CNF=True)\n",
    "\n",
    "# Train, print, and evaluate model\n",
    "br.fit(dfTrain, yTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.7895716945996276\n",
      "Test accuracy: 0.7272727272727273\n",
      "Predict Y=0 if ANY of the following rules are satisfied, otherwise Y=1:\n",
      "['Glucose <= 86.60', 'BMI <= 26.64', 'Glucose <= 135.20 AND DiabetesPedigreeFunction <= 0.22', 'Pregnancies <= 4.00 AND Glucose <= 125.60', 'Pregnancies <= 7.00 AND Glucose <= 168.00 AND Glucose > 95.20 AND BloodPressure > 70.00 AND BMI <= 41.74 AND BMI > 24.06 AND 0 not  AND 1  ']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print('Training accuracy:', accuracy_score(yTrain, br.predict(dfTrain)))\n",
    "print('Test accuracy:', accuracy_score(yTest, br.predict(dfTest)))\n",
    "print('Predict Y=0 if ANY of the following rules are satisfied, otherwise Y=1:')\n",
    "print(br.explain()['rules'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### You will see something like this, \n",
    "Predict Y=0 if ANY of the following rules are satisfied, otherwise Y=1:\n",
    "\n",
    "['Glucose <= 86.60', 'BMI <= 26.64', 'Glucose <= 135.20 AND DiabetesPedigreeFunction <= 0.22', 'Pregnancies <= 4.00 AND Glucose <= 125.60', 'Pregnancies <= 7.00 AND Glucose <= 168.00 AND Glucose > 95.20 AND BloodPressure > 70.00 AND BMI <= 41.74 AND BMI > 24.06 AND 0 not  AND 1  ']\n",
    "\n",
    "`The above results shows the rules identified by the model in the data to a data Scientist.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part-2 Protodash Explainer\n",
    "\n",
    "* The method selects applications from the training set that are similar in different ways to the user application we want to explain. For example, a patient is predicted at Diabetes Risk. There could be mutliple reasons for that, this algorithm compares the profile of differently similar patients and give a doctor better perspective and wholistic view of the patient so that they give better and personalised guidance. \n",
    "\n",
    "* It doesn't give standard explanation for every case by using basic similarity techniques such as which use metrics such as euclidean distance, cosine similarity amongst others. \n",
    "`Protodash provides a much more well rounded and comprehensive view of why the decision for the applicant may be justifiable.`\n",
    "\n",
    "\n",
    "More Technical definition of Protodash : \n",
    "\n",
    "ProtodashExplainer provides exemplar-based explanations for summarizing datasets as well\n",
    "as explaining predictions made by an AI model. It employs a fast gradient based algorithm to find prototypes along with their (non-negative) importance weights. The algorithm minimizes the maximummean discrepancy metric and has constant factor approximation guarantees for this weakly submodular function.\n",
    "\n",
    " [References:](https://arxiv.org/abs/1707.01212).\n",
    "   Paper by : `Karthik S. Gurumoorthy, Amit Dhurandhar, Guillermo Cecchi,\"ProtoDash: Fast Interpretable Prototype Selection\"\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential, Model, load_model, model_from_json\n",
    "from keras.layers import Dense\n",
    "from keras.callbacks import EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.core.display import display, HTML\n",
    "from matplotlib import pyplot\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "from aix360.algorithms.protodash import ProtodashExplainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### load the data again here! Follow the steps: \n",
    "\n",
    "* Load the `diabetes-data` as csv in the notebook.\n",
    "* Click on the 0100 on the top right corner.\n",
    "* Drag and Drop Fraud-Data.csv\n",
    "* Click on `Insert to Code` and then `Pandas Dataframe.`\n",
    "* Name the dataframe as `df`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>Old</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>Young</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>Young</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>Young</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>Young</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction    Age  Outcome  \n",
       "0                     0.627    Old        1  \n",
       "1                     0.351  Young        0  \n",
       "2                     0.672  Young        1  \n",
       "3                     0.167  Young        0  \n",
       "4                     2.288  Young        1  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load the data here \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_treated = df.copy()\n",
    "df_treated['Insulin'].replace(0, df_treated['Insulin'].median(), inplace=True)\n",
    "df_treated['SkinThickness'].replace(0, df_treated['SkinThickness'].median(), inplace=True)\n",
    "df_treated['BMI'].replace(0, df_treated['BMI'].mean(), inplace=True)\n",
    "df_treated['Glucose'].replace(0, df_treated['Glucose'].median(), inplace=True)\n",
    "df_treated['BloodPressure'].replace(0,df_treated['BloodPressure'].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin',\n",
       "       'BMI', 'DiabetesPedigreeFunction', 'Outcome', 'Age_is_Old',\n",
       "       'Age_is_Young'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# generate binary values using get_dummies\n",
    "dum_df = pd.get_dummies(df_treated, columns=[\"Age\"], prefix=[\"Age_is\"] )\n",
    "dum_df\n",
    "dum_df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age_is_Old</th>\n",
       "      <th>Age_is_Young</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72.0</td>\n",
       "      <td>35</td>\n",
       "      <td>30.5</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66.0</td>\n",
       "      <td>29</td>\n",
       "      <td>30.5</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64.0</td>\n",
       "      <td>23</td>\n",
       "      <td>30.5</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66.0</td>\n",
       "      <td>23</td>\n",
       "      <td>94.0</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40.0</td>\n",
       "      <td>35</td>\n",
       "      <td>168.0</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>10</td>\n",
       "      <td>101</td>\n",
       "      <td>76.0</td>\n",
       "      <td>48</td>\n",
       "      <td>180.0</td>\n",
       "      <td>32.9</td>\n",
       "      <td>0.171</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>2</td>\n",
       "      <td>122</td>\n",
       "      <td>70.0</td>\n",
       "      <td>27</td>\n",
       "      <td>30.5</td>\n",
       "      <td>36.8</td>\n",
       "      <td>0.340</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>5</td>\n",
       "      <td>121</td>\n",
       "      <td>72.0</td>\n",
       "      <td>23</td>\n",
       "      <td>112.0</td>\n",
       "      <td>26.2</td>\n",
       "      <td>0.245</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>1</td>\n",
       "      <td>126</td>\n",
       "      <td>60.0</td>\n",
       "      <td>23</td>\n",
       "      <td>30.5</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.349</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>70.0</td>\n",
       "      <td>31</td>\n",
       "      <td>30.5</td>\n",
       "      <td>30.4</td>\n",
       "      <td>0.315</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>768 rows  10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0              6      148           72.0             35     30.5  33.6   \n",
       "1              1       85           66.0             29     30.5  26.6   \n",
       "2              8      183           64.0             23     30.5  23.3   \n",
       "3              1       89           66.0             23     94.0  28.1   \n",
       "4              0      137           40.0             35    168.0  43.1   \n",
       "..           ...      ...            ...            ...      ...   ...   \n",
       "763           10      101           76.0             48    180.0  32.9   \n",
       "764            2      122           70.0             27     30.5  36.8   \n",
       "765            5      121           72.0             23    112.0  26.2   \n",
       "766            1      126           60.0             23     30.5  30.1   \n",
       "767            1       93           70.0             31     30.5  30.4   \n",
       "\n",
       "     DiabetesPedigreeFunction  Age_is_Old  Age_is_Young  Outcome  \n",
       "0                       0.627           1             0        1  \n",
       "1                       0.351           0             1        0  \n",
       "2                       0.672           0             1        1  \n",
       "3                       0.167           0             1        0  \n",
       "4                       2.288           0             1        1  \n",
       "..                        ...         ...           ...      ...  \n",
       "763                     0.171           1             0        0  \n",
       "764                     0.340           0             1        0  \n",
       "765                     0.245           0             1        0  \n",
       "766                     0.349           0             1        1  \n",
       "767                     0.315           0             1        0  \n",
       "\n",
       "[768 rows x 10 columns]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final = dum_df[['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin','BMI', 'DiabetesPedigreeFunction', 'Age_is_Old',\n",
    "       'Age_is_Young','Outcome']] \n",
    "\n",
    "\n",
    "\n",
    "df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age_is_Old</th>\n",
       "      <th>Age_is_Young</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72.0</td>\n",
       "      <td>35</td>\n",
       "      <td>30.5</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66.0</td>\n",
       "      <td>29</td>\n",
       "      <td>30.5</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64.0</td>\n",
       "      <td>23</td>\n",
       "      <td>30.5</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66.0</td>\n",
       "      <td>23</td>\n",
       "      <td>94.0</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40.0</td>\n",
       "      <td>35</td>\n",
       "      <td>168.0</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>10</td>\n",
       "      <td>101</td>\n",
       "      <td>76.0</td>\n",
       "      <td>48</td>\n",
       "      <td>180.0</td>\n",
       "      <td>32.9</td>\n",
       "      <td>0.171</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>2</td>\n",
       "      <td>122</td>\n",
       "      <td>70.0</td>\n",
       "      <td>27</td>\n",
       "      <td>30.5</td>\n",
       "      <td>36.8</td>\n",
       "      <td>0.340</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>5</td>\n",
       "      <td>121</td>\n",
       "      <td>72.0</td>\n",
       "      <td>23</td>\n",
       "      <td>112.0</td>\n",
       "      <td>26.2</td>\n",
       "      <td>0.245</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>1</td>\n",
       "      <td>126</td>\n",
       "      <td>60.0</td>\n",
       "      <td>23</td>\n",
       "      <td>30.5</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.349</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>70.0</td>\n",
       "      <td>31</td>\n",
       "      <td>30.5</td>\n",
       "      <td>30.4</td>\n",
       "      <td>0.315</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>768 rows  9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0              6      148           72.0             35     30.5  33.6   \n",
       "1              1       85           66.0             29     30.5  26.6   \n",
       "2              8      183           64.0             23     30.5  23.3   \n",
       "3              1       89           66.0             23     94.0  28.1   \n",
       "4              0      137           40.0             35    168.0  43.1   \n",
       "..           ...      ...            ...            ...      ...   ...   \n",
       "763           10      101           76.0             48    180.0  32.9   \n",
       "764            2      122           70.0             27     30.5  36.8   \n",
       "765            5      121           72.0             23    112.0  26.2   \n",
       "766            1      126           60.0             23     30.5  30.1   \n",
       "767            1       93           70.0             31     30.5  30.4   \n",
       "\n",
       "     DiabetesPedigreeFunction  Age_is_Old  Age_is_Young  \n",
       "0                       0.627           1             0  \n",
       "1                       0.351           0             1  \n",
       "2                       0.672           0             1  \n",
       "3                       0.167           0             1  \n",
       "4                       2.288           0             1  \n",
       "..                        ...         ...           ...  \n",
       "763                     0.171           1             0  \n",
       "764                     0.340           0             1  \n",
       "765                     0.245           0             1  \n",
       "766                     0.349           0             1  \n",
       "767                     0.315           0             1  \n",
       "\n",
       "[768 rows x 9 columns]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df_final[df_final.columns[0:9]]\n",
    "\n",
    "X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>768 rows  1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Outcome\n",
       "0          1\n",
       "1          0\n",
       "2          1\n",
       "3          0\n",
       "4          1\n",
       "..       ...\n",
       "763        0\n",
       "764        0\n",
       "765        0\n",
       "766        1\n",
       "767        0\n",
       "\n",
       "[768 rows x 1 columns]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "y =df_final[df_final.columns[9:]]\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the data with 70:30 mix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = np.vstack((X_train, X_test))\n",
    "Zmax = np.max(Z, axis=0)\n",
    "Zmin = np.min(Z, axis=0)\n",
    "\n",
    "#normalize an array of samples to range [-0.5, 0.5]\n",
    "def normalize(V):\n",
    "    VN = (V - Zmin)/(Zmax - Zmin)\n",
    "    VN = VN - 0.5\n",
    "    return(VN)\n",
    "    \n",
    "# rescale a sample to recover original values for normalized values. \n",
    "def rescale(X):\n",
    "    return(np.multiply ( X + 0.5, (Zmax - Zmin) ) + Zmin)\n",
    "\n",
    "N = normalize(Z)\n",
    "xn_train = N[0:X_train.shape[0], :]\n",
    "xn_test  = N[X_train.shape[0]:, :]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.44117647, -0.03548387,  0.05102041, -0.26086957, -0.30048077,\n",
       "       -0.13394683, -0.32152007, -0.5       ,  0.5       ])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xn_test[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Designing a basic Neural Network.\n",
    "def nn_small():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(10, input_dim=9, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(4, kernel_initializer='normal'  )  )\n",
    "    model.add(Dense(2, kernel_initializer='normal'  )  )\n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_7 (Dense)              (None, 10)                100       \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 4)                 44        \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 2)                 10        \n",
      "=================================================================\n",
      "Total params: 154\n",
      "Trainable params: 154\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "537/537 [==============================] - 0s 212us/step - loss: 0.4724 - accuracy: 0.9963\n",
      "Epoch 2/200\n",
      "537/537 [==============================] - 0s 52us/step - loss: 0.4724 - accuracy: 1.0000\n",
      "Epoch 3/200\n",
      "537/537 [==============================] - 0s 40us/step - loss: 0.4724 - accuracy: 1.0000\n",
      "Epoch 4/200\n",
      "537/537 [==============================] - 0s 45us/step - loss: 0.4724 - accuracy: 1.0000\n",
      "Epoch 5/200\n",
      "537/537 [==============================] - 0s 39us/step - loss: 0.4724 - accuracy: 1.0000\n",
      "Epoch 6/200\n",
      "537/537 [==============================] - 0s 43us/step - loss: 0.4724 - accuracy: 1.0000\n",
      "Epoch 7/200\n",
      "537/537 [==============================] - 0s 47us/step - loss: 0.4725 - accuracy: 1.0000\n",
      "Epoch 8/200\n",
      "537/537 [==============================] - 0s 41us/step - loss: 0.4725 - accuracy: 1.0000\n",
      "Epoch 9/200\n",
      "537/537 [==============================] - 0s 51us/step - loss: 0.4725 - accuracy: 1.0000\n",
      "Epoch 10/200\n",
      "537/537 [==============================] - 0s 42us/step - loss: 0.4725 - accuracy: 1.0000\n",
      "Epoch 11/200\n",
      "537/537 [==============================] - 0s 35us/step - loss: 0.4726 - accuracy: 1.0000\n",
      "Epoch 12/200\n",
      "537/537 [==============================] - 0s 32us/step - loss: 0.4726 - accuracy: 1.0000\n",
      "Epoch 13/200\n",
      "537/537 [==============================] - 0s 34us/step - loss: 0.4727 - accuracy: 1.0000\n",
      "Epoch 14/200\n",
      "537/537 [==============================] - 0s 35us/step - loss: 0.4727 - accuracy: 0.9981\n",
      "Epoch 15/200\n",
      "537/537 [==============================] - 0s 42us/step - loss: 0.4728 - accuracy: 0.9981\n",
      "Epoch 16/200\n",
      "537/537 [==============================] - 0s 39us/step - loss: 0.4728 - accuracy: 0.9963\n",
      "Epoch 17/200\n",
      "537/537 [==============================] - 0s 33us/step - loss: 0.4729 - accuracy: 0.9963\n",
      "Epoch 18/200\n",
      "537/537 [==============================] - 0s 26us/step - loss: 0.4729 - accuracy: 0.9944\n",
      "Epoch 19/200\n",
      "537/537 [==============================] - 0s 32us/step - loss: 0.4729 - accuracy: 0.9888\n",
      "Epoch 20/200\n",
      "537/537 [==============================] - 0s 29us/step - loss: 0.4729 - accuracy: 0.9870\n",
      "Epoch 21/200\n",
      "537/537 [==============================] - 0s 29us/step - loss: 0.4729 - accuracy: 0.9870\n",
      "Epoch 22/200\n",
      "537/537 [==============================] - 0s 27us/step - loss: 0.4729 - accuracy: 0.9851\n",
      "Epoch 23/200\n",
      "537/537 [==============================] - 0s 27us/step - loss: 0.4729 - accuracy: 0.9851\n",
      "Epoch 24/200\n",
      "537/537 [==============================] - 0s 28us/step - loss: 0.4729 - accuracy: 0.9814\n",
      "Epoch 25/200\n",
      "537/537 [==============================] - 0s 32us/step - loss: 0.4728 - accuracy: 0.9777\n",
      "Epoch 26/200\n",
      "537/537 [==============================] - 0s 33us/step - loss: 0.4728 - accuracy: 0.9777\n",
      "Epoch 27/200\n",
      "537/537 [==============================] - 0s 27us/step - loss: 0.4728 - accuracy: 0.9739\n",
      "Epoch 28/200\n",
      "537/537 [==============================] - 0s 26us/step - loss: 0.4728 - accuracy: 0.9683\n",
      "Epoch 29/200\n",
      "537/537 [==============================] - 0s 26us/step - loss: 0.4728 - accuracy: 0.9646\n",
      "Epoch 30/200\n",
      "537/537 [==============================] - 0s 27us/step - loss: 0.4728 - accuracy: 0.9646\n",
      "Epoch 31/200\n",
      "537/537 [==============================] - 0s 31us/step - loss: 0.4727 - accuracy: 0.9646\n",
      "Epoch 32/200\n",
      "537/537 [==============================] - 0s 25us/step - loss: 0.4727 - accuracy: 0.9628\n",
      "Epoch 33/200\n",
      "537/537 [==============================] - 0s 24us/step - loss: 0.4727 - accuracy: 0.9590\n",
      "Epoch 34/200\n",
      "537/537 [==============================] - 0s 24us/step - loss: 0.4727 - accuracy: 0.9572\n",
      "Epoch 35/200\n",
      "537/537 [==============================] - 0s 25us/step - loss: 0.4727 - accuracy: 0.9497\n",
      "Epoch 36/200\n",
      "537/537 [==============================] - 0s 24us/step - loss: 0.4727 - accuracy: 0.9497\n",
      "Epoch 37/200\n",
      "537/537 [==============================] - 0s 24us/step - loss: 0.4727 - accuracy: 0.9460\n",
      "Epoch 38/200\n",
      "537/537 [==============================] - 0s 24us/step - loss: 0.4727 - accuracy: 0.9460\n",
      "Epoch 39/200\n",
      "537/537 [==============================] - 0s 26us/step - loss: 0.4727 - accuracy: 0.9441\n",
      "Epoch 40/200\n",
      "537/537 [==============================] - 0s 24us/step - loss: 0.4727 - accuracy: 0.9404\n",
      "Epoch 41/200\n",
      "537/537 [==============================] - 0s 23us/step - loss: 0.4726 - accuracy: 0.9348\n",
      "Epoch 42/200\n",
      "537/537 [==============================] - 0s 23us/step - loss: 0.4726 - accuracy: 0.9311\n",
      "Epoch 43/200\n",
      "537/537 [==============================] - 0s 24us/step - loss: 0.4726 - accuracy: 0.9292\n",
      "Epoch 44/200\n",
      "537/537 [==============================] - 0s 24us/step - loss: 0.4726 - accuracy: 0.9255\n",
      "Epoch 45/200\n",
      "537/537 [==============================] - 0s 23us/step - loss: 0.4726 - accuracy: 0.9255\n",
      "Epoch 46/200\n",
      "537/537 [==============================] - 0s 22us/step - loss: 0.4726 - accuracy: 0.9236\n",
      "Epoch 47/200\n",
      "537/537 [==============================] - 0s 23us/step - loss: 0.4726 - accuracy: 0.9181\n",
      "Epoch 48/200\n",
      "537/537 [==============================] - 0s 24us/step - loss: 0.4726 - accuracy: 0.9181\n",
      "Epoch 49/200\n",
      "537/537 [==============================] - 0s 23us/step - loss: 0.4726 - accuracy: 0.9181\n",
      "Epoch 50/200\n",
      "537/537 [==============================] - 0s 21us/step - loss: 0.4726 - accuracy: 0.9162\n",
      "Epoch 51/200\n",
      "537/537 [==============================] - 0s 21us/step - loss: 0.4726 - accuracy: 0.9143\n",
      "Epoch 52/200\n",
      "537/537 [==============================] - 0s 23us/step - loss: 0.4726 - accuracy: 0.9106\n",
      "Epoch 53/200\n",
      "537/537 [==============================] - 0s 23us/step - loss: 0.4726 - accuracy: 0.9088\n",
      "Epoch 54/200\n",
      "537/537 [==============================] - 0s 22us/step - loss: 0.4726 - accuracy: 0.9088\n",
      "Epoch 55/200\n",
      "537/537 [==============================] - 0s 23us/step - loss: 0.4726 - accuracy: 0.9088\n",
      "Epoch 56/200\n",
      "537/537 [==============================] - 0s 22us/step - loss: 0.4726 - accuracy: 0.9069\n",
      "Epoch 57/200\n",
      "537/537 [==============================] - 0s 23us/step - loss: 0.4726 - accuracy: 0.9050\n",
      "Epoch 58/200\n",
      "537/537 [==============================] - 0s 23us/step - loss: 0.4726 - accuracy: 0.9050\n",
      "Epoch 59/200\n",
      "537/537 [==============================] - 0s 23us/step - loss: 0.4726 - accuracy: 0.9050\n",
      "Epoch 60/200\n",
      "537/537 [==============================] - 0s 22us/step - loss: 0.4726 - accuracy: 0.9032\n",
      "Epoch 61/200\n",
      "537/537 [==============================] - 0s 27us/step - loss: 0.4726 - accuracy: 0.9032\n",
      "Epoch 62/200\n",
      "537/537 [==============================] - 0s 23us/step - loss: 0.4726 - accuracy: 0.9032\n",
      "Epoch 63/200\n",
      "537/537 [==============================] - 0s 25us/step - loss: 0.4726 - accuracy: 0.9032\n",
      "Epoch 64/200\n",
      "537/537 [==============================] - 0s 23us/step - loss: 0.4725 - accuracy: 0.9032\n",
      "Epoch 65/200\n",
      "537/537 [==============================] - 0s 24us/step - loss: 0.4725 - accuracy: 0.9032\n",
      "Epoch 66/200\n",
      "537/537 [==============================] - 0s 23us/step - loss: 0.4725 - accuracy: 0.9032\n",
      "Epoch 67/200\n",
      "537/537 [==============================] - 0s 23us/step - loss: 0.4725 - accuracy: 0.9013\n",
      "Epoch 68/200\n",
      "537/537 [==============================] - 0s 24us/step - loss: 0.4725 - accuracy: 0.8994\n",
      "Epoch 69/200\n",
      "537/537 [==============================] - 0s 22us/step - loss: 0.4725 - accuracy: 0.8976\n",
      "Epoch 70/200\n",
      "537/537 [==============================] - 0s 21us/step - loss: 0.4725 - accuracy: 0.8976\n",
      "Epoch 71/200\n",
      "537/537 [==============================] - 0s 22us/step - loss: 0.4725 - accuracy: 0.8957\n",
      "Epoch 72/200\n",
      "537/537 [==============================] - 0s 22us/step - loss: 0.4725 - accuracy: 0.8939\n",
      "Epoch 73/200\n",
      "537/537 [==============================] - 0s 23us/step - loss: 0.4725 - accuracy: 0.8939\n",
      "Epoch 74/200\n",
      "537/537 [==============================] - 0s 23us/step - loss: 0.4725 - accuracy: 0.8939\n",
      "Epoch 75/200\n",
      "537/537 [==============================] - 0s 23us/step - loss: 0.4725 - accuracy: 0.8939\n",
      "Epoch 76/200\n",
      "537/537 [==============================] - 0s 23us/step - loss: 0.4725 - accuracy: 0.8939\n",
      "Epoch 77/200\n",
      "537/537 [==============================] - 0s 24us/step - loss: 0.4725 - accuracy: 0.8920\n",
      "Epoch 78/200\n",
      "537/537 [==============================] - 0s 24us/step - loss: 0.4725 - accuracy: 0.8920\n",
      "Epoch 79/200\n",
      "537/537 [==============================] - 0s 24us/step - loss: 0.4725 - accuracy: 0.8920\n",
      "Epoch 80/200\n",
      "537/537 [==============================] - 0s 23us/step - loss: 0.4725 - accuracy: 0.8920\n",
      "Epoch 81/200\n",
      "537/537 [==============================] - 0s 22us/step - loss: 0.4725 - accuracy: 0.8920\n",
      "Epoch 82/200\n",
      "537/537 [==============================] - 0s 23us/step - loss: 0.4725 - accuracy: 0.8920\n",
      "Epoch 83/200\n",
      "537/537 [==============================] - 0s 21us/step - loss: 0.4725 - accuracy: 0.8901\n",
      "Epoch 84/200\n",
      "537/537 [==============================] - 0s 23us/step - loss: 0.4725 - accuracy: 0.8883\n",
      "Epoch 85/200\n",
      "537/537 [==============================] - 0s 23us/step - loss: 0.4725 - accuracy: 0.8883\n",
      "Epoch 86/200\n",
      "537/537 [==============================] - 0s 23us/step - loss: 0.4725 - accuracy: 0.8883\n",
      "Epoch 87/200\n",
      "537/537 [==============================] - 0s 23us/step - loss: 0.4725 - accuracy: 0.8883\n",
      "Epoch 88/200\n",
      "537/537 [==============================] - 0s 23us/step - loss: 0.4725 - accuracy: 0.8901\n",
      "Epoch 89/200\n",
      "537/537 [==============================] - 0s 23us/step - loss: 0.4725 - accuracy: 0.8901\n",
      "Epoch 90/200\n",
      "537/537 [==============================] - 0s 23us/step - loss: 0.4725 - accuracy: 0.8883\n",
      "Epoch 91/200\n",
      "537/537 [==============================] - 0s 23us/step - loss: 0.4725 - accuracy: 0.8883\n",
      "Epoch 92/200\n",
      "537/537 [==============================] - 0s 24us/step - loss: 0.4725 - accuracy: 0.8864\n",
      "Epoch 93/200\n",
      "537/537 [==============================] - 0s 23us/step - loss: 0.4725 - accuracy: 0.8845\n",
      "Epoch 94/200\n",
      "537/537 [==============================] - 0s 22us/step - loss: 0.4725 - accuracy: 0.8845\n",
      "Epoch 95/200\n",
      "537/537 [==============================] - 0s 22us/step - loss: 0.4725 - accuracy: 0.8845\n",
      "Epoch 96/200\n",
      "537/537 [==============================] - 0s 22us/step - loss: 0.4725 - accuracy: 0.8845\n",
      "Epoch 97/200\n",
      "537/537 [==============================] - 0s 22us/step - loss: 0.4725 - accuracy: 0.8845\n",
      "Epoch 98/200\n",
      "537/537 [==============================] - 0s 23us/step - loss: 0.4725 - accuracy: 0.8845\n",
      "Epoch 99/200\n",
      "537/537 [==============================] - 0s 22us/step - loss: 0.4725 - accuracy: 0.8845\n",
      "Epoch 100/200\n",
      "537/537 [==============================] - 0s 22us/step - loss: 0.4725 - accuracy: 0.8827\n",
      "Epoch 101/200\n",
      "537/537 [==============================] - 0s 22us/step - loss: 0.4725 - accuracy: 0.8827\n",
      "Epoch 102/200\n",
      "537/537 [==============================] - 0s 23us/step - loss: 0.4725 - accuracy: 0.8808\n",
      "Epoch 103/200\n",
      "537/537 [==============================] - 0s 22us/step - loss: 0.4725 - accuracy: 0.8808\n",
      "Epoch 104/200\n",
      "537/537 [==============================] - 0s 23us/step - loss: 0.4725 - accuracy: 0.8790\n",
      "Epoch 105/200\n",
      "537/537 [==============================] - 0s 23us/step - loss: 0.4725 - accuracy: 0.8790\n",
      "Epoch 106/200\n",
      "537/537 [==============================] - 0s 22us/step - loss: 0.4725 - accuracy: 0.8790\n",
      "Epoch 107/200\n",
      "537/537 [==============================] - 0s 24us/step - loss: 0.4725 - accuracy: 0.8790\n",
      "Epoch 108/200\n",
      "537/537 [==============================] - 0s 23us/step - loss: 0.4725 - accuracy: 0.8808\n",
      "Epoch 109/200\n",
      "537/537 [==============================] - 0s 24us/step - loss: 0.4725 - accuracy: 0.8808\n",
      "Epoch 110/200\n",
      "537/537 [==============================] - 0s 24us/step - loss: 0.4725 - accuracy: 0.8808\n",
      "Epoch 111/200\n",
      "537/537 [==============================] - 0s 25us/step - loss: 0.4725 - accuracy: 0.8808\n",
      "Epoch 112/200\n",
      "537/537 [==============================] - 0s 24us/step - loss: 0.4725 - accuracy: 0.8808\n",
      "Epoch 113/200\n",
      "537/537 [==============================] - 0s 24us/step - loss: 0.4725 - accuracy: 0.8808\n",
      "Epoch 114/200\n",
      "537/537 [==============================] - 0s 23us/step - loss: 0.4725 - accuracy: 0.8808\n",
      "Epoch 115/200\n",
      "537/537 [==============================] - 0s 23us/step - loss: 0.4725 - accuracy: 0.8808\n",
      "Epoch 116/200\n",
      "537/537 [==============================] - 0s 23us/step - loss: 0.4725 - accuracy: 0.8808\n",
      "Epoch 117/200\n",
      "537/537 [==============================] - 0s 24us/step - loss: 0.4725 - accuracy: 0.8808\n",
      "Epoch 118/200\n",
      "537/537 [==============================] - 0s 25us/step - loss: 0.4725 - accuracy: 0.8808\n",
      "Epoch 119/200\n",
      "537/537 [==============================] - 0s 24us/step - loss: 0.4725 - accuracy: 0.8808\n",
      "Epoch 120/200\n",
      "537/537 [==============================] - 0s 24us/step - loss: 0.4725 - accuracy: 0.8808\n",
      "Epoch 121/200\n",
      "537/537 [==============================] - 0s 24us/step - loss: 0.4725 - accuracy: 0.8808\n",
      "Epoch 122/200\n",
      "537/537 [==============================] - 0s 26us/step - loss: 0.4725 - accuracy: 0.8808\n",
      "Epoch 123/200\n",
      "537/537 [==============================] - 0s 24us/step - loss: 0.4725 - accuracy: 0.8808\n",
      "Epoch 124/200\n",
      "537/537 [==============================] - 0s 22us/step - loss: 0.4725 - accuracy: 0.8808\n",
      "Epoch 125/200\n",
      "537/537 [==============================] - 0s 23us/step - loss: 0.4725 - accuracy: 0.8808\n",
      "Epoch 126/200\n",
      "537/537 [==============================] - 0s 23us/step - loss: 0.4725 - accuracy: 0.8827\n",
      "Epoch 127/200\n",
      "537/537 [==============================] - 0s 24us/step - loss: 0.4725 - accuracy: 0.8827\n",
      "Epoch 128/200\n",
      "537/537 [==============================] - 0s 25us/step - loss: 0.4725 - accuracy: 0.8827\n",
      "Epoch 129/200\n",
      "537/537 [==============================] - 0s 24us/step - loss: 0.4725 - accuracy: 0.8845\n",
      "Epoch 130/200\n",
      "537/537 [==============================] - 0s 24us/step - loss: 0.4725 - accuracy: 0.8845\n",
      "Epoch 131/200\n",
      "537/537 [==============================] - 0s 24us/step - loss: 0.4725 - accuracy: 0.8845\n",
      "Epoch 132/200\n",
      "537/537 [==============================] - 0s 24us/step - loss: 0.4725 - accuracy: 0.8845\n",
      "Epoch 133/200\n",
      "537/537 [==============================] - 0s 23us/step - loss: 0.4725 - accuracy: 0.8845\n",
      "Epoch 134/200\n",
      "537/537 [==============================] - 0s 22us/step - loss: 0.4725 - accuracy: 0.8845\n",
      "Epoch 135/200\n",
      "537/537 [==============================] - 0s 23us/step - loss: 0.4725 - accuracy: 0.8864\n",
      "Epoch 136/200\n",
      "537/537 [==============================] - 0s 23us/step - loss: 0.4725 - accuracy: 0.8864\n",
      "Epoch 137/200\n",
      "537/537 [==============================] - 0s 23us/step - loss: 0.4725 - accuracy: 0.8864\n",
      "Epoch 138/200\n",
      "537/537 [==============================] - 0s 25us/step - loss: 0.4725 - accuracy: 0.8864\n",
      "Epoch 139/200\n",
      "537/537 [==============================] - 0s 24us/step - loss: 0.4725 - accuracy: 0.8864\n",
      "Epoch 140/200\n",
      "537/537 [==============================] - 0s 24us/step - loss: 0.4725 - accuracy: 0.8864\n",
      "Epoch 141/200\n",
      "537/537 [==============================] - 0s 23us/step - loss: 0.4725 - accuracy: 0.8864\n",
      "Epoch 142/200\n",
      "537/537 [==============================] - 0s 23us/step - loss: 0.4725 - accuracy: 0.8864\n",
      "Epoch 143/200\n",
      "537/537 [==============================] - 0s 23us/step - loss: 0.4725 - accuracy: 0.8845\n",
      "Epoch 144/200\n",
      "537/537 [==============================] - 0s 24us/step - loss: 0.4725 - accuracy: 0.8845\n",
      "Epoch 145/200\n",
      "537/537 [==============================] - 0s 24us/step - loss: 0.4725 - accuracy: 0.8845\n",
      "Epoch 146/200\n",
      "537/537 [==============================] - 0s 23us/step - loss: 0.4725 - accuracy: 0.8845\n",
      "Epoch 147/200\n",
      "537/537 [==============================] - 0s 23us/step - loss: 0.4725 - accuracy: 0.8845\n",
      "Epoch 148/200\n",
      "537/537 [==============================] - 0s 26us/step - loss: 0.4725 - accuracy: 0.8845\n",
      "Epoch 149/200\n",
      "537/537 [==============================] - 0s 23us/step - loss: 0.4725 - accuracy: 0.8845\n",
      "Epoch 150/200\n",
      "537/537 [==============================] - 0s 23us/step - loss: 0.4725 - accuracy: 0.8845\n",
      "Epoch 151/200\n",
      "537/537 [==============================] - 0s 23us/step - loss: 0.4725 - accuracy: 0.8883\n",
      "Epoch 152/200\n",
      "537/537 [==============================] - 0s 23us/step - loss: 0.4725 - accuracy: 0.8883\n",
      "Epoch 153/200\n",
      "537/537 [==============================] - 0s 23us/step - loss: 0.4725 - accuracy: 0.8883\n",
      "Epoch 154/200\n",
      "537/537 [==============================] - 0s 24us/step - loss: 0.4725 - accuracy: 0.8883\n",
      "Epoch 155/200\n",
      "537/537 [==============================] - 0s 22us/step - loss: 0.4725 - accuracy: 0.8920\n",
      "Epoch 156/200\n",
      "537/537 [==============================] - 0s 22us/step - loss: 0.4725 - accuracy: 0.8939\n",
      "Epoch 157/200\n",
      "537/537 [==============================] - 0s 25us/step - loss: 0.4725 - accuracy: 0.8939\n",
      "Epoch 158/200\n",
      "537/537 [==============================] - 0s 24us/step - loss: 0.4725 - accuracy: 0.8939\n",
      "Epoch 159/200\n",
      "537/537 [==============================] - 0s 23us/step - loss: 0.4725 - accuracy: 0.8957\n",
      "Epoch 160/200\n",
      "537/537 [==============================] - 0s 23us/step - loss: 0.4725 - accuracy: 0.8957\n",
      "Epoch 161/200\n",
      "537/537 [==============================] - 0s 23us/step - loss: 0.4725 - accuracy: 0.8939\n",
      "Epoch 162/200\n",
      "537/537 [==============================] - 0s 23us/step - loss: 0.4725 - accuracy: 0.8939\n",
      "Epoch 163/200\n",
      "537/537 [==============================] - 0s 24us/step - loss: 0.4725 - accuracy: 0.8920\n",
      "Epoch 164/200\n",
      "537/537 [==============================] - 0s 23us/step - loss: 0.4725 - accuracy: 0.8939\n",
      "Epoch 165/200\n",
      "537/537 [==============================] - 0s 22us/step - loss: 0.4725 - accuracy: 0.8901\n",
      "Epoch 166/200\n",
      "537/537 [==============================] - 0s 22us/step - loss: 0.4725 - accuracy: 0.8845\n",
      "Epoch 167/200\n",
      "537/537 [==============================] - 0s 24us/step - loss: 0.4725 - accuracy: 0.8827\n",
      "Epoch 168/200\n",
      "537/537 [==============================] - 0s 23us/step - loss: 0.4725 - accuracy: 0.8734\n",
      "Epoch 169/200\n",
      "537/537 [==============================] - 0s 22us/step - loss: 0.4725 - accuracy: 0.8734\n",
      "Epoch 170/200\n",
      "537/537 [==============================] - 0s 22us/step - loss: 0.4725 - accuracy: 0.8585\n",
      "Epoch 171/200\n",
      "537/537 [==============================] - 0s 25us/step - loss: 0.4725 - accuracy: 0.8492\n",
      "Epoch 172/200\n",
      "537/537 [==============================] - 0s 23us/step - loss: 0.4725 - accuracy: 0.8492\n",
      "Epoch 173/200\n",
      "537/537 [==============================] - 0s 23us/step - loss: 0.4725 - accuracy: 0.8454\n",
      "Epoch 174/200\n",
      "537/537 [==============================] - 0s 22us/step - loss: 0.4725 - accuracy: 0.8380\n",
      "Epoch 175/200\n",
      "537/537 [==============================] - 0s 21us/step - loss: 0.4725 - accuracy: 0.8287\n",
      "Epoch 176/200\n",
      "537/537 [==============================] - 0s 22us/step - loss: 0.4725 - accuracy: 0.8287\n",
      "Epoch 177/200\n",
      "537/537 [==============================] - 0s 24us/step - loss: 0.4725 - accuracy: 0.8305\n",
      "Epoch 178/200\n",
      "537/537 [==============================] - 0s 23us/step - loss: 0.4725 - accuracy: 0.8287\n",
      "Epoch 179/200\n",
      "537/537 [==============================] - 0s 23us/step - loss: 0.4725 - accuracy: 0.8268\n",
      "Epoch 180/200\n",
      "537/537 [==============================] - 0s 22us/step - loss: 0.4725 - accuracy: 0.8305\n",
      "Epoch 181/200\n",
      "537/537 [==============================] - 0s 24us/step - loss: 0.4725 - accuracy: 0.8250\n",
      "Epoch 182/200\n",
      "537/537 [==============================] - 0s 25us/step - loss: 0.4725 - accuracy: 0.8417\n",
      "Epoch 183/200\n",
      "537/537 [==============================] - 0s 22us/step - loss: 0.4725 - accuracy: 0.8510\n",
      "Epoch 184/200\n",
      "537/537 [==============================] - 0s 23us/step - loss: 0.4725 - accuracy: 0.8454\n",
      "Epoch 185/200\n",
      "537/537 [==============================] - 0s 23us/step - loss: 0.4725 - accuracy: 0.8585\n",
      "Epoch 186/200\n",
      "537/537 [==============================] - 0s 23us/step - loss: 0.4725 - accuracy: 0.8603\n",
      "Epoch 187/200\n",
      "537/537 [==============================] - 0s 23us/step - loss: 0.4725 - accuracy: 0.8696\n",
      "Epoch 188/200\n",
      "537/537 [==============================] - 0s 22us/step - loss: 0.4725 - accuracy: 0.8771\n",
      "Epoch 189/200\n",
      "537/537 [==============================] - 0s 23us/step - loss: 0.4725 - accuracy: 0.8864\n",
      "Epoch 190/200\n",
      "537/537 [==============================] - 0s 23us/step - loss: 0.4725 - accuracy: 0.8845\n",
      "Epoch 191/200\n",
      "537/537 [==============================] - 0s 24us/step - loss: 0.4725 - accuracy: 0.8901\n",
      "Epoch 192/200\n",
      "537/537 [==============================] - 0s 24us/step - loss: 0.4725 - accuracy: 0.8901\n",
      "Epoch 193/200\n",
      "537/537 [==============================] - 0s 23us/step - loss: 0.4725 - accuracy: 0.8939\n",
      "Epoch 194/200\n",
      "537/537 [==============================] - 0s 24us/step - loss: 0.4725 - accuracy: 0.8939\n",
      "Epoch 195/200\n",
      "537/537 [==============================] - 0s 24us/step - loss: 0.4725 - accuracy: 0.8939\n",
      "Epoch 196/200\n",
      "537/537 [==============================] - 0s 22us/step - loss: 0.4725 - accuracy: 0.8957\n",
      "Epoch 197/200\n",
      "537/537 [==============================] - 0s 21us/step - loss: 0.4725 - accuracy: 0.8939\n",
      "Epoch 198/200\n",
      "537/537 [==============================] - 0s 23us/step - loss: 0.4725 - accuracy: 0.8976\n",
      "Epoch 199/200\n",
      "537/537 [==============================] - 0s 22us/step - loss: 0.4725 - accuracy: 0.8994\n",
      "Epoch 200/200\n",
      "537/537 [==============================] - 0s 24us/step - loss: 0.4725 - accuracy: 0.9032\n",
      "Train accuracy: 0.8621973991394043\n",
      "Test accuracy: 0.8917748928070068\n"
     ]
    }
   ],
   "source": [
    "# Set random seeds for repeatability\n",
    "np.random.seed(1) \n",
    "tf.set_random_seed(2) \n",
    "\n",
    "\n",
    "class_names = ['Diabetes-Risk', 'No-Diabetes-Risk']\n",
    "# loss function\n",
    "def fn(correct, predicted):\n",
    "    return tf.nn.softmax_cross_entropy_with_logits(labels=correct, logits=predicted)\n",
    "\n",
    "# compile and print model summary\n",
    "nn = nn_small()\n",
    "nn.compile(loss=fn, optimizer='adam', metrics=['accuracy'])\n",
    "nn.summary()\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', patience=10)\n",
    "\n",
    "history = nn.fit(xn_train, y_train, batch_size=50, epochs=200, verbose=1, shuffle=False, callbacks=[es])\n",
    "\n",
    "\n",
    "# evaluate model accuracy        \n",
    "score = nn.evaluate(xn_train, y_train, verbose=0) #Compute training set accuracy\n",
    "#print('Train loss:', score[0])\n",
    "print('Train accuracy:', score[1])\n",
    "\n",
    "score = nn.evaluate(xn_test, y_test, verbose=0) #Compute test set accuracy\n",
    "#print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0\n",
      " 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 1 0 1 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 1 0\n",
      " 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1\n",
      " 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 1]\n",
      "[[-0.14705882  0.16451613  0.07142857 -0.32608696 -0.48016827 -0.26891616\n",
      "  -0.45730145  0.5        -0.5         1.        ]\n",
      " [-0.14705882  0.0483871   0.17346939 -0.5        -0.125      -0.47137014\n",
      "  -0.28479932  0.5        -0.5         1.        ]\n",
      " [ 0.26470588 -0.1        -0.03061224 -0.32608696 -0.48016827 -0.17280164\n",
      "  -0.42613151  0.5        -0.5         1.        ]\n",
      " [-0.20588235  0.14516129  0.09183673 -0.29347826 -0.17427885 -0.21779141\n",
      "  -0.34030743  0.5        -0.5         1.        ]\n",
      " [-0.5         0.33225806  0.05102041 -0.22826087 -0.19831731  0.07873211\n",
      "  -0.03842869  0.5        -0.5         1.        ]\n",
      " [-0.14705882  0.28709677  0.01020408 -0.32608696 -0.48016827 -0.32822086\n",
      "  -0.40350128  0.5        -0.5         1.        ]\n",
      " [-0.20588235  0.23548387 -0.03061224 -0.32608696 -0.48016827 -0.26278119\n",
      "  -0.44491887  0.5        -0.5         1.        ]\n",
      " [ 0.14705882  0.21612903  0.03061224 -0.27173913 -0.33653846 -0.19120654\n",
      "   0.04440649  0.5        -0.5         1.        ]\n",
      " [-0.02941176  0.02258065  0.23469388 -0.32608696 -0.48016827 -0.21794319\n",
      "  -0.43424424  0.5        -0.5         1.        ]\n",
      " [-0.08823529  0.09354839  0.17346939 -0.32608696 -0.48016827 -0.2607362\n",
      "  -0.44363792  0.5        -0.5         1.        ]\n",
      " [-0.08823529  0.18387097  0.05102041 -0.26086957 -0.36538462 -0.15235174\n",
      "  -0.23783091  0.5        -0.5         1.        ]\n",
      " [ 0.08823529 -0.04193548  0.25510204 -0.32608696 -0.48016827 -0.38139059\n",
      "  -0.0969257  -0.5         0.5         1.        ]\n",
      " [-0.38235294 -0.08064516  0.19387755 -0.32608696 -0.48016827  0.00102249\n",
      "  -0.17250213  0.5        -0.5         1.        ]\n",
      " [-0.26470588 -0.06774194 -0.01020408 -0.06521739 -0.26802885 -0.11349693\n",
      "   0.06020495  0.5        -0.5         1.        ]\n",
      " [ 0.20588235 -0.13870968  0.1122449  -0.2173913  -0.390625   -0.25869121\n",
      "  -0.32493595 -0.5         0.5         1.        ]\n",
      " [-0.08823529  0.02258065  0.13265306 -0.32608696 -0.48016827 -0.10327198\n",
      "  -0.40350128  0.5        -0.5         1.        ]\n",
      " [-0.02941176  0.38387097 -0.05102041 -0.18478261  0.078125   -0.25664622\n",
      "  -0.2707088   0.5        -0.5         1.        ]\n",
      " [-0.26470588  0.15806452  0.05102041 -0.32608696 -0.48016827 -0.08486708\n",
      "  -0.31127242  0.5        -0.5         1.        ]\n",
      " [-0.26470588 -0.20322581  0.15306122 -0.06521739 -0.45192308 -0.10122699\n",
      "  -0.37873612 -0.5         0.5         1.        ]\n",
      " [-0.5        -0.18387097  0.2755102  -0.15217391 -0.43028846  0.01533742\n",
      "  -0.09735269 -0.5         0.5         1.        ]\n",
      " [ 0.02941176 -0.06129032  0.09183673 -0.31521739 -0.48016827 -0.29550102\n",
      "   0.01409052  0.5        -0.5         1.        ]\n",
      " [-0.38235294 -0.10645161  0.02040816 -0.32608696 -0.48016827 -0.39570552\n",
      "  -0.294193    0.5        -0.5         1.        ]\n",
      " [-0.38235294 -0.08709677  0.07142857 -0.32608696 -0.48016827 -0.3200409\n",
      "  -0.42271563  0.5        -0.5         1.        ]\n",
      " [-0.38235294  0.48709677 -0.03061224  0.5        -0.48016827 -0.16257669\n",
      "  -0.28778822  0.5        -0.5         1.        ]\n",
      " [-0.26470588  0.08064516 -0.01020408 -0.32608696 -0.48016827 -0.38548057\n",
      "  -0.41502989  0.5        -0.5         1.        ]\n",
      " [-0.26470588  0.15806452  0.19387755 -0.32608696 -0.48016827 -0.23415133\n",
      "  -0.30315969  0.5        -0.5         1.        ]\n",
      " [-0.20588235 -0.11935484  0.35714286 -0.17391304 -0.48016827 -0.07055215\n",
      "  -0.4030743   0.5        -0.5         1.        ]\n",
      " [-0.26470588  0.06774194  0.13265306 -0.23913043 -0.48016827 -0.299591\n",
      "  -0.35439795  0.5        -0.5         1.        ]\n",
      " [-0.14705882 -0.11935484 -0.01020408 -0.22826087 -0.28846154 -0.10122699\n",
      "  -0.39496157  0.5        -0.5         1.        ]\n",
      " [-0.38235294  0.23548387  0.17346939 -0.32608696 -0.48016827 -0.22597137\n",
      "  -0.18958155  0.5        -0.5         1.        ]\n",
      " [-0.02941176 -0.17096774 -0.01020408 -0.32608696 -0.48016827 -0.1196319\n",
      "  -0.32621691  0.5        -0.5         1.        ]\n",
      " [-0.5        -0.41612903 -0.13265306 -0.32608696 -0.48016827 -0.42842536\n",
      "  -0.21947054  0.5        -0.5         1.        ]\n",
      " [ 0.02941176 -0.19677419 -0.05102041 -0.32608696 -0.48016827 -0.37730061\n",
      "  -0.44790777  0.5        -0.5         1.        ]\n",
      " [-0.20588235 -0.08064516  0.02040816 -0.29347826 -0.48016827 -0.13599182\n",
      "  -0.30017079  0.5        -0.5         1.        ]\n",
      " [ 0.08823529 -0.13225806  0.03061224 -0.05434783 -0.30048077 -0.1993865\n",
      "  -0.46029035  0.5        -0.5         1.        ]\n",
      " [-0.38235294 -0.01612903 -0.03974011 -0.32608696 -0.48016827 -0.47137014\n",
      "  -0.17805295  0.5        -0.5         1.        ]\n",
      " [ 0.08823529 -0.34516129  0.33673469 -0.32608696 -0.45793269 -0.14621677\n",
      "  -0.41161401 -0.5         0.5         1.        ]\n",
      " [ 0.20588235 -0.00322581  0.05102041 -0.39130435 -0.48016827 -0.33026585\n",
      "  -0.42271563  0.5        -0.5         1.        ]\n",
      " [-0.5         0.25483871 -0.23469388 -0.32608696 -0.48016827 -0.42433538\n",
      "  -0.42485056  0.5        -0.5         1.        ]\n",
      " [-0.44117647  0.3         0.15306122 -0.26086957 -0.48016827 -0.15644172\n",
      "  -0.14688301  0.5        -0.5         1.        ]\n",
      " [-0.14705882 -0.12580645  0.17346939 -0.15217391 -0.48016827 -0.14212679\n",
      "  -0.24551665 -0.5         0.5         1.        ]\n",
      " [ 0.08823529  0.11290323  0.07142857 -0.32608696 -0.48016827 -0.31799591\n",
      "   0.08198121  0.5        -0.5         1.        ]\n",
      " [-0.26470588  0.1516129   0.09183673 -0.38043478 -0.48016827 -0.20756646\n",
      "  -0.43296328  0.5        -0.5         1.        ]\n",
      " [ 0.08823529  0.26129032  0.1122449  -0.32608696 -0.48016827 -0.30572597\n",
      "  -0.45559351  0.5        -0.5         1.        ]\n",
      " [-0.20588235  0.06774194  0.07142857 -0.32608696 -0.48016827 -0.32413088\n",
      "  -0.45388557  0.5        -0.5         1.        ]\n",
      " [-0.38235294 -0.13870968 -0.03061224 -0.01086957 -0.44831731 -0.04396728\n",
      "  -0.2442357  -0.5         0.5         1.        ]\n",
      " [-0.02941176  0.01612903  0.03061224 -0.31521739  0.20432692 -0.28527607\n",
      "  -0.23996584  0.5        -0.5         1.        ]\n",
      " [ 0.08823529  0.17096774  0.1122449  -0.05434783 -0.23197115 -0.10327198\n",
      "  -0.1058924   0.5        -0.5         1.        ]\n",
      " [-0.02941176 -0.08064516  0.03061224 -0.15217391 -0.37980769 -0.30163599\n",
      "  -0.26003416 -0.5         0.5         1.        ]\n",
      " [-0.02941176  0.3516129   0.17346939 -0.20652174 -0.15625    -0.18302658\n",
      "  -0.33390265  0.5        -0.5         1.        ]\n",
      " [-0.5         0.1         0.1122449  -0.2826087  -0.48016827 -0.31390593\n",
      "  -0.43467122  0.5        -0.5         1.        ]\n",
      " [ 0.14705882  0.13870968  0.21428571 -0.2173913  -0.34134615 -0.12372188\n",
      "  -0.42485056  0.5        -0.5         1.        ]\n",
      " [ 0.26470588  0.1516129   0.09183673 -0.36956522 -0.38461538 -0.41820041\n",
      "  -0.42869342  0.5        -0.5         1.        ]\n",
      " [-0.02941176 -0.07419355  0.03061224 -0.32608696 -0.48016827 -0.30368098\n",
      "  -0.43210931  0.5        -0.5         1.        ]\n",
      " [-0.02941176 -0.30645161 -0.03061224 -0.14130435 -0.45793269 -0.15030675\n",
      "  -0.2322801  -0.5         0.5         1.        ]\n",
      " [ 0.02941176  0.22258065  0.13265306 -0.32608696 -0.48016827 -0.36503067\n",
      "  -0.43509821  0.5        -0.5         1.        ]\n",
      " [-0.02941176 -0.14516129  0.1122449  -0.32608696 -0.48016827 -0.14826176\n",
      "  -0.3676345   0.5        -0.5         1.        ]\n",
      " [ 0.08823529 -0.17741935 -0.01020408 -0.38043478 -0.48016827 -0.3997955\n",
      "  -0.27924851  0.5        -0.5         1.        ]\n",
      " [ 0.14705882  0.03548387  0.33673469 -0.32608696 -0.48016827 -0.07464213\n",
      "  -0.45217763  0.5        -0.5         1.        ]\n",
      " [-0.20588235 -0.0483871   0.01020408 -0.32608696 -0.48016827 -0.36298569\n",
      "  -0.21562767  0.5        -0.5         1.        ]\n",
      " [-0.14705882  0.1        -0.12244898 -0.32608696 -0.48016827 -0.37730061\n",
      "  -0.46883006  0.5        -0.5         1.        ]\n",
      " [-0.26470588 -0.08064516 -0.09183673 -0.09782609 -0.39783654 -0.1605317\n",
      "  -0.14688301 -0.5         0.5         1.        ]\n",
      " [-0.32352941  0.04193548  0.05102041 -0.32608696 -0.48016827 -0.4406953\n",
      "  -0.41887276  0.5        -0.5         1.        ]\n",
      " [-0.38235294 -0.10645161  0.07142857 -0.08695652 -0.28725962 -0.18302658\n",
      "  -0.22971819 -0.5         0.5         1.        ]\n",
      " [-0.44117647  0.27419355  0.09183673 -0.10869565 -0.43629808 -0.20143149\n",
      "  -0.38770282  0.5        -0.5         1.        ]\n",
      " [-0.32352941  0.13225806  0.07142857 -0.41304348 -0.48016827 -0.20961145\n",
      "  -0.44790777  0.5        -0.5         1.        ]\n",
      " [-0.20588235 -0.15806452  0.03061224 -0.2826087  -0.48016827 -0.14417178\n",
      "  -0.37190436  0.5        -0.5         1.        ]\n",
      " [-0.32352941  0.3516129   0.13265306 -0.2826087  -0.32932692 -0.19120654\n",
      "  -0.04056362  0.5        -0.5         1.        ]\n",
      " [ 0.08823529 -0.20322581  0.12244898 -0.22826087 -0.48016827 -0.15848671\n",
      "  -0.18104184  0.5        -0.5         1.        ]\n",
      " [-0.44117647  0.08709677 -0.19387755 -0.32608696 -0.48016827 -0.32617587\n",
      "  -0.23996584  0.5        -0.5         1.        ]\n",
      " [ 0.20588235 -0.19032258 -0.1122449  -0.5        -0.20673077 -0.30777096\n",
      "  -0.13791631 -0.5         0.5         1.        ]\n",
      " [-0.14705882  0.26129032 -0.1122449  -0.32608696 -0.48016827 -0.37525562\n",
      "  -0.45730145  0.5        -0.5         1.        ]\n",
      " [-0.5        -0.10645161  0.1122449  -0.32608696 -0.48016827 -0.30163599\n",
      "  -0.21690863  0.5        -0.5         1.        ]\n",
      " [ 0.02941176 -0.12580645  0.03061224 -0.17391304 -0.48016827 -0.1993865\n",
      "  -0.24935952 -0.5         0.5         1.        ]]\n"
     ]
    }
   ],
   "source": [
    "p_train = nn.predict_classes(xn_train) # Use trained neural network to predict train points\n",
    "print(p_train)\n",
    "p_train = p_train.reshape((p_train.shape[0],1))\n",
    "\n",
    "z_train = np.hstack((xn_train, p_train)) # Store (normalized) instances that were predicted as Good/No Fraud Risk\n",
    "z_train_good = z_train[z_train[:,-1]==1, :]\n",
    "\n",
    "zun_train = np.hstack((xn_train, p_train)) # Store (unnormalized) instances that were predicted as Good \n",
    "zun_train_good = zun_train[zun_train[:,-1]==1, :]\n",
    "print(zun_train_good)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_test = nn.predict_classes(xn_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chosen Sample: 0\n",
      "Prediction made by the model: No-Diabetes-Risk\n",
      "Prediction probabilities: [[-1511.812 -1511.798]]\n",
      "\n",
      "[[-0.08823529  0.09354839  0.01020408 -0.29347826 -0.35456731 -0.3404908\n",
      "  -0.25704526  0.5        -0.5         1.        ]]\n",
      "[[  7.    136.     74.     26.    135.     26.      0.647   1.      0.   ]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Pregnancies</th>\n",
       "      <td>7.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Glucose</th>\n",
       "      <td>136.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BloodPressure</th>\n",
       "      <td>74.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SkinThickness</th>\n",
       "      <td>26.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Insulin</th>\n",
       "      <td>135.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BMI</th>\n",
       "      <td>26.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <td>0.647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Outcome</th>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                0\n",
       "Pregnancies                 7.000\n",
       "Glucose                   136.000\n",
       "BloodPressure              74.000\n",
       "SkinThickness              26.000\n",
       "Insulin                   135.000\n",
       "BMI                        26.000\n",
       "DiabetesPedigreeFunction    0.647\n",
       "Age                         1.000\n",
       "Outcome                     0.000"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = 0\n",
    "\n",
    "X = xn_test[idx].reshape((1,) + xn_test[idx].shape)\n",
    "# print(X)\n",
    "print(\"Chosen Sample:\", idx)\n",
    "print(\"Prediction made by the model:\", class_names[np.argmax(nn.predict_proba(X))])\n",
    "print(\"Prediction probabilities:\", nn.predict_proba(X))\n",
    "print(\"\")\n",
    "\n",
    "# attach the prediction made by the model to X\n",
    "X = np.hstack((X, nn.predict_classes(X).reshape((1,1))))\n",
    "print(X)\n",
    "\n",
    "x_test = X_test.to_numpy()\n",
    "Xun = x_test[idx].reshape((1, ) + x_test[idx].shape)\n",
    "print(Xun)\n",
    "\n",
    "dfx = pd.DataFrame.from_records(Xun) # Create dataframe with original feature values\n",
    "dfx\n",
    "dfx[7] = int(X[0, -1])\n",
    "dfx.columns = df.columns\n",
    "dfx.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = ProtodashExplainer()\n",
    "(W, S, setValues) = explainer.explain(X, z_train_good, m=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['Diabetes-Risk ', 'No-Diabetes-Risk']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Pregnancies</th>\n",
       "      <td>-0.0882353</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.264706</td>\n",
       "      <td>-0.0294118</td>\n",
       "      <td>0.0882353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Glucose</th>\n",
       "      <td>0.183871</td>\n",
       "      <td>-0.416129</td>\n",
       "      <td>0.151613</td>\n",
       "      <td>0.383871</td>\n",
       "      <td>0.112903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BloodPressure</th>\n",
       "      <td>0.0510204</td>\n",
       "      <td>-0.132653</td>\n",
       "      <td>0.0918367</td>\n",
       "      <td>-0.0510204</td>\n",
       "      <td>0.0714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SkinThickness</th>\n",
       "      <td>-0.26087</td>\n",
       "      <td>-0.326087</td>\n",
       "      <td>-0.369565</td>\n",
       "      <td>-0.184783</td>\n",
       "      <td>-0.326087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Insulin</th>\n",
       "      <td>-0.365385</td>\n",
       "      <td>-0.480168</td>\n",
       "      <td>-0.384615</td>\n",
       "      <td>0.078125</td>\n",
       "      <td>-0.480168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BMI</th>\n",
       "      <td>-0.152352</td>\n",
       "      <td>-0.428425</td>\n",
       "      <td>-0.4182</td>\n",
       "      <td>-0.256646</td>\n",
       "      <td>-0.317996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <td>-0.237831</td>\n",
       "      <td>-0.219471</td>\n",
       "      <td>-0.428693</td>\n",
       "      <td>-0.270709</td>\n",
       "      <td>0.0819812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age_is_Old</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age_is_Young</th>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Outcome</th>\n",
       "      <td>No-Diabetes-Risk</td>\n",
       "      <td>No-Diabetes-Risk</td>\n",
       "      <td>No-Diabetes-Risk</td>\n",
       "      <td>No-Diabetes-Risk</td>\n",
       "      <td>No-Diabetes-Risk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Weight</th>\n",
       "      <td>0.276126</td>\n",
       "      <td>0.223478</td>\n",
       "      <td>0.237959</td>\n",
       "      <td>0.161081</td>\n",
       "      <td>0.101356</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         0                 1  \\\n",
       "Pregnancies                     -0.0882353              -0.5   \n",
       "Glucose                           0.183871         -0.416129   \n",
       "BloodPressure                    0.0510204         -0.132653   \n",
       "SkinThickness                     -0.26087         -0.326087   \n",
       "Insulin                          -0.365385         -0.480168   \n",
       "BMI                              -0.152352         -0.428425   \n",
       "DiabetesPedigreeFunction         -0.237831         -0.219471   \n",
       "Age_is_Old                             0.5               0.5   \n",
       "Age_is_Young                          -0.5              -0.5   \n",
       "Outcome                   No-Diabetes-Risk  No-Diabetes-Risk   \n",
       "Weight                            0.276126          0.223478   \n",
       "\n",
       "                                         2                 3                 4  \n",
       "Pregnancies                       0.264706        -0.0294118         0.0882353  \n",
       "Glucose                           0.151613          0.383871          0.112903  \n",
       "BloodPressure                    0.0918367        -0.0510204         0.0714286  \n",
       "SkinThickness                    -0.369565         -0.184783         -0.326087  \n",
       "Insulin                          -0.384615          0.078125         -0.480168  \n",
       "BMI                                -0.4182         -0.256646         -0.317996  \n",
       "DiabetesPedigreeFunction         -0.428693         -0.270709         0.0819812  \n",
       "Age_is_Old                             0.5               0.5               0.5  \n",
       "Age_is_Young                          -0.5              -0.5              -0.5  \n",
       "Outcome                   No-Diabetes-Risk  No-Diabetes-Risk  No-Diabetes-Risk  \n",
       "Weight                            0.237959          0.161081          0.101356  "
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs = pd.DataFrame.from_records(zun_train_good[S, 0:-1].astype('double'))\n",
    "RP=[]\n",
    "for i in range(S.shape[0]):\n",
    "    RP.append(class_names[int(z_train_good[S[i], -1])]) # Append class names\n",
    "dfs[23] = RP\n",
    "dfs.columns = df_final.columns  \n",
    "dfs[\"Weight\"] = np.around(W, 5)/np.sum(np.around(W, 5)) # Calculate normalized importance weights\n",
    "dfs.transpose()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note : The above table `This gives the profile of the instances similar to each other who have no Diabetes risk to the Doctor.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part-3 : Demostrating `Contrastive Explanations Method (CEM) algorithm using AI Explainability 360` on Diabetes Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contrastive Explanations Method (CEM) algorithm available in AI Explainability 360."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `The algorithm outputs a contrastive explanation which consists of two parts: a) pertinent negatives (PNs) and b) pertinent positives (PPs). PNs identify a minimal set of features which if altered would change the classification of the original input.`\n",
    "\n",
    "\n",
    "Compute Pertinent Negatives (PN):\n",
    "In order to compute pertinent negatives, the CEM explainer computes a user profile that is close to the original applicant but for whom the decision of fraud risk is different. The explainer alters a minimal set of features by a minimal (positive) amount. This will help the user whose loan application was initially rejected say, to ascertain how to get it accepted.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential, Model, load_model, model_from_json\n",
    "from keras.layers import Dense\n",
    "from keras.callbacks import EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.core.display import display, HTML\n",
    "from matplotlib import pyplot\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the `Diabetes-Data` as csv in the notebook. \n",
    "\n",
    "* Click on the `0100` on the top right corner. \n",
    "* Drag and Drop `diabetes-data.csv` \n",
    "* Select the Cell below. \n",
    "* Click on `Insert to Code` and then `Pandas Dataframe.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>Old</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>Young</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>Young</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>Young</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>Young</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction    Age  Outcome  \n",
       "0                     0.627    Old        1  \n",
       "1                     0.351  Young        0  \n",
       "2                     0.672  Young        1  \n",
       "3                     0.167  Young        0  \n",
       "4                     2.288  Young        1  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load the data here \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Insulin'].replace(0, df['Insulin'].median(), inplace=True)\n",
    "df['SkinThickness'].replace(0, df['SkinThickness'].median(), inplace=True)\n",
    "df['BMI'].replace(0, df['BMI'].mean(), inplace=True)\n",
    "df['Glucose'].replace(0, df['Glucose'].median(), inplace=True)\n",
    "df['BloodPressure'].replace(0,df['BloodPressure'].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age_is_Old</th>\n",
       "      <th>Age_is_Young</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72.0</td>\n",
       "      <td>35</td>\n",
       "      <td>30.5</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66.0</td>\n",
       "      <td>29</td>\n",
       "      <td>30.5</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64.0</td>\n",
       "      <td>23</td>\n",
       "      <td>30.5</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66.0</td>\n",
       "      <td>23</td>\n",
       "      <td>94.0</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40.0</td>\n",
       "      <td>35</td>\n",
       "      <td>168.0</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>10</td>\n",
       "      <td>101</td>\n",
       "      <td>76.0</td>\n",
       "      <td>48</td>\n",
       "      <td>180.0</td>\n",
       "      <td>32.9</td>\n",
       "      <td>0.171</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>2</td>\n",
       "      <td>122</td>\n",
       "      <td>70.0</td>\n",
       "      <td>27</td>\n",
       "      <td>30.5</td>\n",
       "      <td>36.8</td>\n",
       "      <td>0.340</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>5</td>\n",
       "      <td>121</td>\n",
       "      <td>72.0</td>\n",
       "      <td>23</td>\n",
       "      <td>112.0</td>\n",
       "      <td>26.2</td>\n",
       "      <td>0.245</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>1</td>\n",
       "      <td>126</td>\n",
       "      <td>60.0</td>\n",
       "      <td>23</td>\n",
       "      <td>30.5</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.349</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>70.0</td>\n",
       "      <td>31</td>\n",
       "      <td>30.5</td>\n",
       "      <td>30.4</td>\n",
       "      <td>0.315</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>768 rows  10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0              6      148           72.0             35     30.5  33.6   \n",
       "1              1       85           66.0             29     30.5  26.6   \n",
       "2              8      183           64.0             23     30.5  23.3   \n",
       "3              1       89           66.0             23     94.0  28.1   \n",
       "4              0      137           40.0             35    168.0  43.1   \n",
       "..           ...      ...            ...            ...      ...   ...   \n",
       "763           10      101           76.0             48    180.0  32.9   \n",
       "764            2      122           70.0             27     30.5  36.8   \n",
       "765            5      121           72.0             23    112.0  26.2   \n",
       "766            1      126           60.0             23     30.5  30.1   \n",
       "767            1       93           70.0             31     30.5  30.4   \n",
       "\n",
       "     DiabetesPedigreeFunction  Age_is_Old  Age_is_Young  Outcome  \n",
       "0                       0.627           1             0        1  \n",
       "1                       0.351           0             1        0  \n",
       "2                       0.672           0             1        1  \n",
       "3                       0.167           0             1        0  \n",
       "4                       2.288           0             1        1  \n",
       "..                        ...         ...           ...      ...  \n",
       "763                     0.171           1             0        0  \n",
       "764                     0.340           0             1        0  \n",
       "765                     0.245           0             1        0  \n",
       "766                     0.349           0             1        1  \n",
       "767                     0.315           0             1        0  \n",
       "\n",
       "[768 rows x 10 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dum_df = pd.get_dummies(df, columns=[\"Age\"], prefix=[\"Age_is\"] )\n",
    "\n",
    "df_final = dum_df[['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin','BMI', 'DiabetesPedigreeFunction', 'Age_is_Old',\n",
    "       'Age_is_Young','Outcome']] \n",
    "\n",
    "\n",
    "\n",
    "df_final\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age_is_Old</th>\n",
       "      <th>Age_is_Young</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72.0</td>\n",
       "      <td>35</td>\n",
       "      <td>30.5</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66.0</td>\n",
       "      <td>29</td>\n",
       "      <td>30.5</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64.0</td>\n",
       "      <td>23</td>\n",
       "      <td>30.5</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66.0</td>\n",
       "      <td>23</td>\n",
       "      <td>94.0</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40.0</td>\n",
       "      <td>35</td>\n",
       "      <td>168.0</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>10</td>\n",
       "      <td>101</td>\n",
       "      <td>76.0</td>\n",
       "      <td>48</td>\n",
       "      <td>180.0</td>\n",
       "      <td>32.9</td>\n",
       "      <td>0.171</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>2</td>\n",
       "      <td>122</td>\n",
       "      <td>70.0</td>\n",
       "      <td>27</td>\n",
       "      <td>30.5</td>\n",
       "      <td>36.8</td>\n",
       "      <td>0.340</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>5</td>\n",
       "      <td>121</td>\n",
       "      <td>72.0</td>\n",
       "      <td>23</td>\n",
       "      <td>112.0</td>\n",
       "      <td>26.2</td>\n",
       "      <td>0.245</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>1</td>\n",
       "      <td>126</td>\n",
       "      <td>60.0</td>\n",
       "      <td>23</td>\n",
       "      <td>30.5</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.349</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>70.0</td>\n",
       "      <td>31</td>\n",
       "      <td>30.5</td>\n",
       "      <td>30.4</td>\n",
       "      <td>0.315</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>768 rows  9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0              6      148           72.0             35     30.5  33.6   \n",
       "1              1       85           66.0             29     30.5  26.6   \n",
       "2              8      183           64.0             23     30.5  23.3   \n",
       "3              1       89           66.0             23     94.0  28.1   \n",
       "4              0      137           40.0             35    168.0  43.1   \n",
       "..           ...      ...            ...            ...      ...   ...   \n",
       "763           10      101           76.0             48    180.0  32.9   \n",
       "764            2      122           70.0             27     30.5  36.8   \n",
       "765            5      121           72.0             23    112.0  26.2   \n",
       "766            1      126           60.0             23     30.5  30.1   \n",
       "767            1       93           70.0             31     30.5  30.4   \n",
       "\n",
       "     DiabetesPedigreeFunction  Age_is_Old  Age_is_Young  \n",
       "0                       0.627           1             0  \n",
       "1                       0.351           0             1  \n",
       "2                       0.672           0             1  \n",
       "3                       0.167           0             1  \n",
       "4                       2.288           0             1  \n",
       "..                        ...         ...           ...  \n",
       "763                     0.171           1             0  \n",
       "764                     0.340           0             1  \n",
       "765                     0.245           0             1  \n",
       "766                     0.349           0             1  \n",
       "767                     0.315           0             1  \n",
       "\n",
       "[768 rows x 9 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df_final[df_final.columns[0:9]]\n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>768 rows  1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Outcome\n",
       "0          1\n",
       "1          0\n",
       "2          1\n",
       "3          0\n",
       "4          1\n",
       "..       ...\n",
       "763        0\n",
       "764        0\n",
       "765        0\n",
       "766        1\n",
       "767        0\n",
       "\n",
       "[768 rows x 1 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "y =df_final[df_final.columns[9:]]\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=1,stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalising the dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = np.vstack((x_train, x_test))\n",
    "Zmax = np.max(Z, axis=0)\n",
    "Zmin = np.min(Z, axis=0)\n",
    "\n",
    "#normalize an array of samples to range [-0.5, 0.5]\n",
    "def normalize(V):\n",
    "    VN = (V - Zmin)/(Zmax - Zmin)\n",
    "    VN = VN - 0.5\n",
    "    return(VN)\n",
    "    \n",
    "# rescale a sample to recover original values for normalized values. \n",
    "def rescale(X):\n",
    "    return(np.multiply ( X + 0.5, (Zmax - Zmin) ) + Zmin)\n",
    "\n",
    "N = normalize(Z)\n",
    "xn_train = N[0:x_train.shape[0], :]\n",
    "xn_test  = N[x_train.shape[0]:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.44117647, -0.20322581, -0.1122449 , -0.44565217, -0.46514423,\n",
       "       -0.31595092, -0.28565329, -0.5       ,  0.5       ])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xn_test[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define and train a Neural Network Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aix360.algorithms.contrastive import CEMExplainer, KerasClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_small():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(10, input_dim=9, kernel_initializer='normal', activation='relu'))\n",
    "#     model.add(Dense(4, kernel_initializer='normal'  )  )\n",
    "    model.add(Dense(2, kernel_initializer='normal'  )  )\n",
    "    return model  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-18-71be93c94e89>:10: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 10)                100       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 22        \n",
      "=================================================================\n",
      "Total params: 122\n",
      "Trainable params: 122\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/200\n",
      "460/460 [==============================] - 0s 221us/step - loss: 0.4852 - accuracy: 0.8978\n",
      "Epoch 2/200\n",
      "460/460 [==============================] - 0s 16us/step - loss: 0.4852 - accuracy: 0.8957\n",
      "Epoch 3/200\n",
      "460/460 [==============================] - 0s 26us/step - loss: 0.4852 - accuracy: 0.9087\n",
      "Epoch 4/200\n",
      "460/460 [==============================] - 0s 17us/step - loss: 0.4852 - accuracy: 0.9217\n",
      "Epoch 5/200\n",
      "460/460 [==============================] - 0s 18us/step - loss: 0.4852 - accuracy: 0.9413\n",
      "Epoch 6/200\n",
      "460/460 [==============================] - 0s 16us/step - loss: 0.4852 - accuracy: 0.9478\n",
      "Epoch 7/200\n",
      "460/460 [==============================] - 0s 30us/step - loss: 0.4852 - accuracy: 0.9543\n",
      "Epoch 8/200\n",
      "460/460 [==============================] - 0s 14us/step - loss: 0.4852 - accuracy: 0.9630\n",
      "Epoch 9/200\n",
      "460/460 [==============================] - 0s 16us/step - loss: 0.4852 - accuracy: 0.9652\n",
      "Epoch 10/200\n",
      "460/460 [==============================] - 0s 17us/step - loss: 0.4852 - accuracy: 0.9652\n",
      "Epoch 11/200\n",
      "460/460 [==============================] - 0s 16us/step - loss: 0.4852 - accuracy: 0.9674\n",
      "Epoch 12/200\n",
      "460/460 [==============================] - 0s 22us/step - loss: 0.4852 - accuracy: 0.9739\n",
      "Epoch 13/200\n",
      "460/460 [==============================] - 0s 15us/step - loss: 0.4852 - accuracy: 0.9761\n",
      "Epoch 14/200\n",
      "460/460 [==============================] - 0s 25us/step - loss: 0.4852 - accuracy: 0.9783\n",
      "Epoch 15/200\n",
      "460/460 [==============================] - 0s 15us/step - loss: 0.4852 - accuracy: 0.9783\n",
      "Epoch 16/200\n",
      "460/460 [==============================] - 0s 23us/step - loss: 0.4852 - accuracy: 0.9783\n",
      "Epoch 17/200\n",
      "460/460 [==============================] - 0s 16us/step - loss: 0.4852 - accuracy: 0.9783\n",
      "Epoch 18/200\n",
      "460/460 [==============================] - 0s 25us/step - loss: 0.4852 - accuracy: 0.9783\n",
      "Epoch 19/200\n",
      "460/460 [==============================] - 0s 18us/step - loss: 0.4852 - accuracy: 0.9783\n",
      "Epoch 20/200\n",
      "460/460 [==============================] - 0s 23us/step - loss: 0.4852 - accuracy: 0.9783\n",
      "Epoch 21/200\n",
      "460/460 [==============================] - 0s 17us/step - loss: 0.4853 - accuracy: 0.9783\n",
      "Epoch 22/200\n",
      "460/460 [==============================] - 0s 17us/step - loss: 0.4853 - accuracy: 0.9761\n",
      "Epoch 23/200\n",
      "460/460 [==============================] - 0s 15us/step - loss: 0.4853 - accuracy: 0.9783\n",
      "Epoch 24/200\n",
      "460/460 [==============================] - 0s 20us/step - loss: 0.4853 - accuracy: 0.9783\n",
      "Epoch 25/200\n",
      "460/460 [==============================] - 0s 15us/step - loss: 0.4853 - accuracy: 0.9783\n",
      "Epoch 26/200\n",
      "460/460 [==============================] - 0s 19us/step - loss: 0.4853 - accuracy: 0.9783\n",
      "Epoch 27/200\n",
      "460/460 [==============================] - 0s 13us/step - loss: 0.4853 - accuracy: 0.9783\n",
      "Epoch 28/200\n",
      "460/460 [==============================] - 0s 12us/step - loss: 0.4853 - accuracy: 0.9783\n",
      "Epoch 29/200\n",
      "460/460 [==============================] - 0s 13us/step - loss: 0.4853 - accuracy: 0.9783\n",
      "Epoch 30/200\n",
      "460/460 [==============================] - 0s 13us/step - loss: 0.4853 - accuracy: 0.9783\n",
      "Epoch 31/200\n",
      "460/460 [==============================] - 0s 12us/step - loss: 0.4853 - accuracy: 0.9783\n",
      "Epoch 32/200\n",
      "460/460 [==============================] - 0s 32us/step - loss: 0.4853 - accuracy: 0.9783\n",
      "Epoch 33/200\n",
      "460/460 [==============================] - 0s 13us/step - loss: 0.4853 - accuracy: 0.9761\n",
      "Epoch 34/200\n",
      "460/460 [==============================] - 0s 23us/step - loss: 0.4853 - accuracy: 0.9761\n",
      "Epoch 35/200\n",
      "460/460 [==============================] - 0s 13us/step - loss: 0.4853 - accuracy: 0.9761\n",
      "Epoch 36/200\n",
      "460/460 [==============================] - 0s 13us/step - loss: 0.4853 - accuracy: 0.9717\n",
      "Epoch 37/200\n",
      "460/460 [==============================] - 0s 21us/step - loss: 0.4853 - accuracy: 0.9717\n",
      "Epoch 38/200\n",
      "460/460 [==============================] - 0s 27us/step - loss: 0.4853 - accuracy: 0.9717\n",
      "Epoch 39/200\n",
      "460/460 [==============================] - 0s 12us/step - loss: 0.4853 - accuracy: 0.9696\n",
      "Epoch 40/200\n",
      "460/460 [==============================] - 0s 12us/step - loss: 0.4853 - accuracy: 0.9717\n",
      "Epoch 41/200\n",
      "460/460 [==============================] - 0s 13us/step - loss: 0.4853 - accuracy: 0.9717\n",
      "Epoch 42/200\n",
      "460/460 [==============================] - 0s 12us/step - loss: 0.4853 - accuracy: 0.9761\n",
      "Epoch 43/200\n",
      "460/460 [==============================] - 0s 12us/step - loss: 0.4853 - accuracy: 0.9761\n",
      "Epoch 44/200\n",
      "460/460 [==============================] - 0s 17us/step - loss: 0.4853 - accuracy: 0.9761\n",
      "Epoch 45/200\n",
      "460/460 [==============================] - 0s 13us/step - loss: 0.4854 - accuracy: 0.9761\n",
      "Epoch 46/200\n",
      "460/460 [==============================] - 0s 12us/step - loss: 0.4854 - accuracy: 0.9783\n",
      "Epoch 47/200\n",
      "460/460 [==============================] - 0s 12us/step - loss: 0.4854 - accuracy: 0.9783\n",
      "Epoch 48/200\n",
      "460/460 [==============================] - 0s 12us/step - loss: 0.4854 - accuracy: 0.9783\n",
      "Epoch 49/200\n",
      "460/460 [==============================] - 0s 13us/step - loss: 0.4854 - accuracy: 0.9783\n",
      "Epoch 50/200\n",
      "460/460 [==============================] - 0s 16us/step - loss: 0.4854 - accuracy: 0.9783\n",
      "Epoch 51/200\n",
      "460/460 [==============================] - 0s 13us/step - loss: 0.4854 - accuracy: 0.9783\n",
      "Epoch 52/200\n",
      "460/460 [==============================] - 0s 15us/step - loss: 0.4854 - accuracy: 0.9783\n",
      "Epoch 53/200\n",
      "460/460 [==============================] - 0s 12us/step - loss: 0.4854 - accuracy: 0.9783\n",
      "Epoch 54/200\n",
      "460/460 [==============================] - 0s 12us/step - loss: 0.4854 - accuracy: 0.9783\n",
      "Epoch 55/200\n",
      "460/460 [==============================] - 0s 13us/step - loss: 0.4854 - accuracy: 0.9783\n",
      "Epoch 56/200\n",
      "460/460 [==============================] - 0s 14us/step - loss: 0.4854 - accuracy: 0.9761\n",
      "Epoch 57/200\n",
      "460/460 [==============================] - 0s 12us/step - loss: 0.4854 - accuracy: 0.9761\n",
      "Epoch 58/200\n",
      "460/460 [==============================] - 0s 13us/step - loss: 0.4854 - accuracy: 0.9761\n",
      "Epoch 59/200\n",
      "460/460 [==============================] - 0s 13us/step - loss: 0.4854 - accuracy: 0.9739\n",
      "Epoch 60/200\n",
      "460/460 [==============================] - 0s 14us/step - loss: 0.4854 - accuracy: 0.9717\n",
      "Epoch 61/200\n",
      "460/460 [==============================] - 0s 12us/step - loss: 0.4854 - accuracy: 0.9696\n",
      "Epoch 62/200\n",
      "460/460 [==============================] - 0s 12us/step - loss: 0.4854 - accuracy: 0.9696\n",
      "Epoch 63/200\n",
      "460/460 [==============================] - 0s 13us/step - loss: 0.4854 - accuracy: 0.9696\n",
      "Epoch 64/200\n",
      "460/460 [==============================] - 0s 12us/step - loss: 0.4854 - accuracy: 0.9674\n",
      "Epoch 65/200\n",
      "460/460 [==============================] - 0s 13us/step - loss: 0.4854 - accuracy: 0.9674\n",
      "Epoch 66/200\n",
      "460/460 [==============================] - 0s 13us/step - loss: 0.4854 - accuracy: 0.9630\n",
      "Epoch 67/200\n",
      "460/460 [==============================] - 0s 12us/step - loss: 0.4854 - accuracy: 0.9630\n",
      "Epoch 68/200\n",
      "460/460 [==============================] - 0s 13us/step - loss: 0.4854 - accuracy: 0.9630\n",
      "Epoch 69/200\n",
      "460/460 [==============================] - 0s 13us/step - loss: 0.4854 - accuracy: 0.9609\n",
      "Epoch 70/200\n",
      "460/460 [==============================] - 0s 13us/step - loss: 0.4854 - accuracy: 0.9609\n",
      "Epoch 71/200\n",
      "460/460 [==============================] - 0s 12us/step - loss: 0.4854 - accuracy: 0.9587\n",
      "Epoch 72/200\n",
      "460/460 [==============================] - 0s 13us/step - loss: 0.4854 - accuracy: 0.9543\n",
      "Epoch 73/200\n",
      "460/460 [==============================] - 0s 12us/step - loss: 0.4854 - accuracy: 0.9543\n",
      "Epoch 74/200\n",
      "460/460 [==============================] - 0s 12us/step - loss: 0.4854 - accuracy: 0.9543\n",
      "Epoch 75/200\n",
      "460/460 [==============================] - 0s 12us/step - loss: 0.4854 - accuracy: 0.9522\n",
      "Epoch 76/200\n",
      "460/460 [==============================] - 0s 12us/step - loss: 0.4854 - accuracy: 0.9500\n",
      "Epoch 77/200\n",
      "460/460 [==============================] - 0s 12us/step - loss: 0.4854 - accuracy: 0.9500\n",
      "Epoch 78/200\n",
      "460/460 [==============================] - 0s 12us/step - loss: 0.4854 - accuracy: 0.9500\n",
      "Epoch 79/200\n",
      "460/460 [==============================] - 0s 12us/step - loss: 0.4854 - accuracy: 0.9500\n",
      "Epoch 80/200\n",
      "460/460 [==============================] - 0s 12us/step - loss: 0.4854 - accuracy: 0.9478\n",
      "Epoch 81/200\n",
      "460/460 [==============================] - 0s 12us/step - loss: 0.4854 - accuracy: 0.9478\n",
      "Epoch 82/200\n",
      "460/460 [==============================] - 0s 19us/step - loss: 0.4854 - accuracy: 0.9478\n",
      "Epoch 83/200\n",
      "460/460 [==============================] - 0s 11us/step - loss: 0.4854 - accuracy: 0.9457\n",
      "Epoch 84/200\n",
      "460/460 [==============================] - 0s 12us/step - loss: 0.4854 - accuracy: 0.9435\n",
      "Epoch 85/200\n",
      "460/460 [==============================] - 0s 13us/step - loss: 0.4854 - accuracy: 0.9413\n",
      "Epoch 86/200\n",
      "460/460 [==============================] - 0s 12us/step - loss: 0.4854 - accuracy: 0.9391\n",
      "Epoch 87/200\n",
      "460/460 [==============================] - 0s 16us/step - loss: 0.4854 - accuracy: 0.9370\n",
      "Epoch 88/200\n",
      "460/460 [==============================] - 0s 11us/step - loss: 0.4854 - accuracy: 0.9348\n",
      "Epoch 89/200\n",
      "460/460 [==============================] - 0s 12us/step - loss: 0.4854 - accuracy: 0.9348\n",
      "Epoch 90/200\n",
      "460/460 [==============================] - 0s 12us/step - loss: 0.4854 - accuracy: 0.9348\n",
      "Epoch 91/200\n",
      "460/460 [==============================] - 0s 12us/step - loss: 0.4854 - accuracy: 0.9326\n",
      "Epoch 92/200\n",
      "460/460 [==============================] - 0s 12us/step - loss: 0.4854 - accuracy: 0.9304\n",
      "Epoch 93/200\n",
      "460/460 [==============================] - 0s 12us/step - loss: 0.4854 - accuracy: 0.9283\n",
      "Epoch 94/200\n",
      "460/460 [==============================] - 0s 12us/step - loss: 0.4854 - accuracy: 0.9283\n",
      "Epoch 95/200\n",
      "460/460 [==============================] - 0s 12us/step - loss: 0.4854 - accuracy: 0.9239\n",
      "Epoch 96/200\n",
      "460/460 [==============================] - 0s 11us/step - loss: 0.4854 - accuracy: 0.9217\n",
      "Epoch 97/200\n",
      "460/460 [==============================] - 0s 12us/step - loss: 0.4854 - accuracy: 0.9196\n",
      "Epoch 98/200\n",
      "460/460 [==============================] - 0s 12us/step - loss: 0.4854 - accuracy: 0.9174\n",
      "Epoch 99/200\n",
      "460/460 [==============================] - 0s 12us/step - loss: 0.4854 - accuracy: 0.9174\n",
      "Epoch 100/200\n",
      "460/460 [==============================] - 0s 12us/step - loss: 0.4854 - accuracy: 0.9152\n",
      "Epoch 101/200\n",
      "460/460 [==============================] - 0s 12us/step - loss: 0.4854 - accuracy: 0.9152\n",
      "Epoch 102/200\n",
      "460/460 [==============================] - 0s 12us/step - loss: 0.4854 - accuracy: 0.9152\n",
      "Epoch 103/200\n",
      "460/460 [==============================] - 0s 13us/step - loss: 0.4854 - accuracy: 0.9152\n",
      "Epoch 104/200\n",
      "460/460 [==============================] - 0s 12us/step - loss: 0.4854 - accuracy: 0.9152\n",
      "Epoch 105/200\n",
      "460/460 [==============================] - 0s 12us/step - loss: 0.4854 - accuracy: 0.9152\n",
      "Epoch 106/200\n",
      "460/460 [==============================] - 0s 11us/step - loss: 0.4854 - accuracy: 0.9152\n",
      "Epoch 107/200\n",
      "460/460 [==============================] - 0s 12us/step - loss: 0.4854 - accuracy: 0.9130\n",
      "Epoch 108/200\n",
      "460/460 [==============================] - 0s 12us/step - loss: 0.4854 - accuracy: 0.9130\n",
      "Epoch 109/200\n",
      "460/460 [==============================] - 0s 12us/step - loss: 0.4854 - accuracy: 0.9130\n",
      "Epoch 110/200\n",
      "460/460 [==============================] - 0s 12us/step - loss: 0.4854 - accuracy: 0.9130\n",
      "Epoch 111/200\n",
      "460/460 [==============================] - 0s 11us/step - loss: 0.4854 - accuracy: 0.9109\n",
      "Epoch 112/200\n",
      "460/460 [==============================] - 0s 12us/step - loss: 0.4854 - accuracy: 0.9109\n",
      "Epoch 113/200\n",
      "460/460 [==============================] - 0s 12us/step - loss: 0.4854 - accuracy: 0.9109\n",
      "Epoch 114/200\n",
      "460/460 [==============================] - 0s 12us/step - loss: 0.4854 - accuracy: 0.9087\n",
      "Epoch 115/200\n",
      "460/460 [==============================] - 0s 11us/step - loss: 0.4854 - accuracy: 0.9087\n",
      "Epoch 116/200\n",
      "460/460 [==============================] - 0s 11us/step - loss: 0.4854 - accuracy: 0.9087\n",
      "Epoch 117/200\n",
      "460/460 [==============================] - 0s 11us/step - loss: 0.4854 - accuracy: 0.9087\n",
      "Epoch 118/200\n",
      "460/460 [==============================] - 0s 12us/step - loss: 0.4854 - accuracy: 0.9087\n",
      "Epoch 119/200\n",
      "460/460 [==============================] - 0s 12us/step - loss: 0.4854 - accuracy: 0.9087\n",
      "Epoch 120/200\n",
      "460/460 [==============================] - 0s 12us/step - loss: 0.4854 - accuracy: 0.9065\n",
      "Epoch 121/200\n",
      "460/460 [==============================] - 0s 12us/step - loss: 0.4854 - accuracy: 0.9065\n",
      "Epoch 122/200\n",
      "460/460 [==============================] - 0s 11us/step - loss: 0.4854 - accuracy: 0.9065\n",
      "Epoch 123/200\n",
      "460/460 [==============================] - 0s 12us/step - loss: 0.4854 - accuracy: 0.9065\n",
      "Epoch 124/200\n",
      "460/460 [==============================] - 0s 12us/step - loss: 0.4854 - accuracy: 0.9065\n",
      "Epoch 125/200\n",
      "460/460 [==============================] - 0s 11us/step - loss: 0.4854 - accuracy: 0.9065\n",
      "Epoch 126/200\n",
      "460/460 [==============================] - 0s 12us/step - loss: 0.4854 - accuracy: 0.9065\n",
      "Epoch 127/200\n",
      "460/460 [==============================] - 0s 12us/step - loss: 0.4854 - accuracy: 0.9065\n",
      "Epoch 128/200\n",
      "460/460 [==============================] - 0s 12us/step - loss: 0.4854 - accuracy: 0.9065\n",
      "Epoch 129/200\n",
      "460/460 [==============================] - 0s 11us/step - loss: 0.4854 - accuracy: 0.9065\n",
      "Epoch 130/200\n",
      "460/460 [==============================] - 0s 11us/step - loss: 0.4854 - accuracy: 0.9065\n",
      "Epoch 131/200\n",
      "460/460 [==============================] - 0s 11us/step - loss: 0.4854 - accuracy: 0.9043\n",
      "Epoch 132/200\n",
      "460/460 [==============================] - 0s 11us/step - loss: 0.4854 - accuracy: 0.9043\n",
      "Epoch 133/200\n",
      "460/460 [==============================] - 0s 12us/step - loss: 0.4854 - accuracy: 0.9043\n",
      "Epoch 134/200\n",
      "460/460 [==============================] - 0s 11us/step - loss: 0.4854 - accuracy: 0.9043\n",
      "Epoch 135/200\n",
      "460/460 [==============================] - 0s 12us/step - loss: 0.4854 - accuracy: 0.9022\n",
      "Epoch 136/200\n",
      "460/460 [==============================] - 0s 12us/step - loss: 0.4854 - accuracy: 0.9022\n",
      "Epoch 137/200\n",
      "460/460 [==============================] - 0s 11us/step - loss: 0.4854 - accuracy: 0.9022\n",
      "Epoch 138/200\n",
      "460/460 [==============================] - 0s 12us/step - loss: 0.4854 - accuracy: 0.9022\n",
      "Epoch 139/200\n",
      "460/460 [==============================] - 0s 13us/step - loss: 0.4854 - accuracy: 0.9022\n",
      "Epoch 140/200\n",
      "460/460 [==============================] - 0s 12us/step - loss: 0.4854 - accuracy: 0.9022\n",
      "Epoch 141/200\n",
      "460/460 [==============================] - 0s 11us/step - loss: 0.4854 - accuracy: 0.9022\n",
      "Epoch 142/200\n",
      "460/460 [==============================] - 0s 11us/step - loss: 0.4854 - accuracy: 0.9022\n",
      "Epoch 143/200\n",
      "460/460 [==============================] - 0s 12us/step - loss: 0.4854 - accuracy: 0.9022\n",
      "Epoch 144/200\n",
      "460/460 [==============================] - 0s 11us/step - loss: 0.4854 - accuracy: 0.9022\n",
      "Epoch 145/200\n",
      "460/460 [==============================] - 0s 11us/step - loss: 0.4854 - accuracy: 0.9022\n",
      "Epoch 146/200\n",
      "460/460 [==============================] - 0s 10us/step - loss: 0.4854 - accuracy: 0.9022\n",
      "Epoch 147/200\n",
      "460/460 [==============================] - 0s 12us/step - loss: 0.4854 - accuracy: 0.9022\n",
      "Epoch 148/200\n",
      "460/460 [==============================] - 0s 11us/step - loss: 0.4854 - accuracy: 0.9022\n",
      "Epoch 149/200\n",
      "460/460 [==============================] - 0s 13us/step - loss: 0.4854 - accuracy: 0.9022\n",
      "Epoch 150/200\n",
      "460/460 [==============================] - 0s 11us/step - loss: 0.4854 - accuracy: 0.9022\n",
      "Epoch 151/200\n",
      "460/460 [==============================] - 0s 10us/step - loss: 0.4854 - accuracy: 0.9022\n",
      "Epoch 152/200\n",
      "460/460 [==============================] - 0s 11us/step - loss: 0.4854 - accuracy: 0.9022\n",
      "Epoch 153/200\n",
      "460/460 [==============================] - 0s 11us/step - loss: 0.4854 - accuracy: 0.9022\n",
      "Epoch 154/200\n",
      "460/460 [==============================] - 0s 11us/step - loss: 0.4854 - accuracy: 0.9022\n",
      "Epoch 155/200\n",
      "460/460 [==============================] - 0s 11us/step - loss: 0.4854 - accuracy: 0.9022\n",
      "Epoch 156/200\n",
      "460/460 [==============================] - 0s 12us/step - loss: 0.4854 - accuracy: 0.9022\n",
      "Epoch 157/200\n",
      "460/460 [==============================] - 0s 11us/step - loss: 0.4854 - accuracy: 0.9022\n",
      "Epoch 158/200\n",
      "460/460 [==============================] - 0s 11us/step - loss: 0.4854 - accuracy: 0.9022\n",
      "Epoch 159/200\n",
      "460/460 [==============================] - 0s 12us/step - loss: 0.4854 - accuracy: 0.9022\n",
      "Epoch 160/200\n",
      "460/460 [==============================] - 0s 11us/step - loss: 0.4854 - accuracy: 0.9022\n",
      "Epoch 161/200\n",
      "460/460 [==============================] - 0s 11us/step - loss: 0.4854 - accuracy: 0.9022\n",
      "Epoch 162/200\n",
      "460/460 [==============================] - 0s 11us/step - loss: 0.4854 - accuracy: 0.9022\n",
      "Epoch 163/200\n",
      "460/460 [==============================] - 0s 12us/step - loss: 0.4854 - accuracy: 0.9022\n",
      "Epoch 164/200\n",
      "460/460 [==============================] - 0s 11us/step - loss: 0.4854 - accuracy: 0.9022\n",
      "Epoch 165/200\n",
      "460/460 [==============================] - 0s 12us/step - loss: 0.4854 - accuracy: 0.9022\n",
      "Epoch 166/200\n",
      "460/460 [==============================] - 0s 11us/step - loss: 0.4854 - accuracy: 0.9022\n",
      "Epoch 167/200\n",
      "460/460 [==============================] - 0s 11us/step - loss: 0.4854 - accuracy: 0.9022\n",
      "Epoch 168/200\n",
      "460/460 [==============================] - 0s 12us/step - loss: 0.4854 - accuracy: 0.9022\n",
      "Epoch 169/200\n",
      "460/460 [==============================] - 0s 11us/step - loss: 0.4854 - accuracy: 0.9022\n",
      "Epoch 170/200\n",
      "460/460 [==============================] - 0s 11us/step - loss: 0.4854 - accuracy: 0.9022\n",
      "Epoch 171/200\n",
      "460/460 [==============================] - 0s 11us/step - loss: 0.4854 - accuracy: 0.9022\n",
      "Epoch 172/200\n",
      "460/460 [==============================] - 0s 11us/step - loss: 0.4854 - accuracy: 0.9022\n",
      "Epoch 173/200\n",
      "460/460 [==============================] - 0s 11us/step - loss: 0.4854 - accuracy: 0.9022\n",
      "Epoch 174/200\n",
      "460/460 [==============================] - 0s 11us/step - loss: 0.4854 - accuracy: 0.9022\n",
      "Epoch 175/200\n",
      "460/460 [==============================] - 0s 15us/step - loss: 0.4854 - accuracy: 0.9022\n",
      "Epoch 176/200\n",
      "460/460 [==============================] - 0s 11us/step - loss: 0.4854 - accuracy: 0.9022\n",
      "Epoch 177/200\n",
      "460/460 [==============================] - 0s 12us/step - loss: 0.4854 - accuracy: 0.9022\n",
      "Epoch 178/200\n",
      "460/460 [==============================] - 0s 12us/step - loss: 0.4854 - accuracy: 0.9022\n",
      "Epoch 179/200\n",
      "460/460 [==============================] - 0s 11us/step - loss: 0.4854 - accuracy: 0.9022\n",
      "Epoch 180/200\n",
      "460/460 [==============================] - 0s 10us/step - loss: 0.4854 - accuracy: 0.9022\n",
      "Epoch 181/200\n",
      "460/460 [==============================] - 0s 12us/step - loss: 0.4854 - accuracy: 0.9022\n",
      "Epoch 182/200\n",
      "460/460 [==============================] - 0s 11us/step - loss: 0.4854 - accuracy: 0.9022\n",
      "Epoch 183/200\n",
      "460/460 [==============================] - 0s 11us/step - loss: 0.4854 - accuracy: 0.9022\n",
      "Epoch 184/200\n",
      "460/460 [==============================] - 0s 12us/step - loss: 0.4854 - accuracy: 0.9022\n",
      "Epoch 185/200\n",
      "460/460 [==============================] - 0s 11us/step - loss: 0.4854 - accuracy: 0.9022\n",
      "Epoch 186/200\n",
      "460/460 [==============================] - 0s 11us/step - loss: 0.4854 - accuracy: 0.9022\n",
      "Epoch 187/200\n",
      "460/460 [==============================] - 0s 11us/step - loss: 0.4854 - accuracy: 0.9000\n",
      "Epoch 188/200\n",
      "460/460 [==============================] - 0s 11us/step - loss: 0.4854 - accuracy: 0.9000\n",
      "Epoch 189/200\n",
      "460/460 [==============================] - 0s 11us/step - loss: 0.4854 - accuracy: 0.9000\n",
      "Epoch 190/200\n",
      "460/460 [==============================] - 0s 12us/step - loss: 0.4854 - accuracy: 0.9000\n",
      "Epoch 191/200\n",
      "460/460 [==============================] - 0s 11us/step - loss: 0.4854 - accuracy: 0.9000\n",
      "Epoch 192/200\n",
      "460/460 [==============================] - 0s 11us/step - loss: 0.4854 - accuracy: 0.9000\n",
      "Epoch 193/200\n",
      "460/460 [==============================] - 0s 12us/step - loss: 0.4854 - accuracy: 0.9000\n",
      "Epoch 194/200\n",
      "460/460 [==============================] - 0s 10us/step - loss: 0.4854 - accuracy: 0.9000\n",
      "Epoch 195/200\n",
      "460/460 [==============================] - 0s 11us/step - loss: 0.4854 - accuracy: 0.9000\n",
      "Epoch 196/200\n",
      "460/460 [==============================] - 0s 11us/step - loss: 0.4854 - accuracy: 0.9000\n",
      "Epoch 197/200\n",
      "460/460 [==============================] - 0s 12us/step - loss: 0.4854 - accuracy: 0.9000\n",
      "Epoch 198/200\n",
      "460/460 [==============================] - 0s 11us/step - loss: 0.4854 - accuracy: 0.9000\n",
      "Epoch 199/200\n",
      "460/460 [==============================] - 0s 12us/step - loss: 0.4854 - accuracy: 0.9000\n",
      "Epoch 200/200\n",
      "460/460 [==============================] - 0s 11us/step - loss: 0.4854 - accuracy: 0.9000\n",
      "Train accuracy: 0.897826075553894\n",
      "Test loss: 0.4817979506083897\n",
      "Test accuracy: 0.8668830990791321\n"
     ]
    }
   ],
   "source": [
    "# Set random seeds for repeatability\n",
    "np.random.seed(1) \n",
    "tf.set_random_seed(2) \n",
    "\n",
    "\n",
    "class_names = ['no-Diabetes-risk', 'Diabetes-risk']\n",
    "\n",
    "# loss function\n",
    "def fn(correct, predicted):\n",
    "    return tf.nn.softmax_cross_entropy_with_logits(labels=correct, logits=predicted)\n",
    "\n",
    "# compile and print model summary\n",
    "nn = nn_small()\n",
    "nn.compile(loss=fn, optimizer='adam', metrics=['accuracy'])\n",
    "nn.summary()\n",
    "\n",
    "nn.fit(xn_train, y_train, batch_size=100, epochs=200, verbose=1, shuffle=False)\n",
    "\n",
    "\n",
    "# evaluate model accuracy        \n",
    "score = nn.evaluate(xn_train, y_train, verbose=0) #Compute training set accuracy\n",
    "#print('Train loss:', score[0])\n",
    "print('Train accuracy:', score[1])\n",
    "\n",
    "score = nn.evaluate(xn_test, y_test, verbose=0) #Compute test set accuracy\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing PN for Sample: 1\n",
      "Prediction made by the model: [[-16.136536 -16.114416]]\n",
      "Prediction probabilities: Diabetes-risk\n",
      "\n",
      "WARNING:tensorflow:From /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages/aix360/algorithms/contrastive/CEM_aen.py:60: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages/aix360/algorithms/contrastive/CEM_aen.py:151: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages/aix360/algorithms/contrastive/CEM_aen.py:213: The name tf.train.polynomial_decay is deprecated. Please use tf.compat.v1.train.polynomial_decay instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages/tensorflow/python/keras/optimizer_v2/learning_rate_schedule.py:409: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "WARNING:tensorflow:From /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages/aix360/algorithms/contrastive/CEM_aen.py:216: The name tf.train.GradientDescentOptimizer is deprecated. Please use tf.compat.v1.train.GradientDescentOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages/aix360/algorithms/contrastive/CEM_aen.py:230: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "iter:0 const:[10.]\n",
      "Loss_Overall:0.4212, Loss_Attack:0.4212\n",
      "Loss_L2Dist:0.0000, Loss_L1Dist:0.0000, AE_loss:0.0\n",
      "target_lab_score:-16.1144, max_nontarget_lab_score:-16.1365\n",
      "\n",
      "iter:250 const:[10.]\n",
      "Loss_Overall:0.4212, Loss_Attack:0.4212\n",
      "Loss_L2Dist:0.0000, Loss_L1Dist:0.0000, AE_loss:0.0\n",
      "target_lab_score:-16.1144, max_nontarget_lab_score:-16.1365\n",
      "\n",
      "iter:0 const:[100.]\n",
      "Loss_Overall:4.2121, Loss_Attack:4.2121\n",
      "Loss_L2Dist:0.0000, Loss_L1Dist:0.0000, AE_loss:0.0\n",
      "target_lab_score:-16.1144, max_nontarget_lab_score:-16.1365\n",
      "\n",
      "iter:250 const:[100.]\n",
      "Loss_Overall:4.2121, Loss_Attack:4.2121\n",
      "Loss_L2Dist:0.0000, Loss_L1Dist:0.0000, AE_loss:0.0\n",
      "target_lab_score:-16.1144, max_nontarget_lab_score:-16.1365\n",
      "\n",
      "iter:0 const:[1000.]\n",
      "Loss_Overall:17.7589, Loss_Attack:17.5128\n",
      "Loss_L2Dist:0.2012, Loss_L1Dist:0.4486, AE_loss:0.0\n",
      "target_lab_score:-20.6493, max_nontarget_lab_score:-20.6468\n",
      "\n",
      "iter:250 const:[1000.]\n",
      "Loss_Overall:0.7677, Loss_Attack:0.0000\n",
      "Loss_L2Dist:0.6849, Loss_L1Dist:0.8276, AE_loss:0.0\n",
      "target_lab_score:-24.4815, max_nontarget_lab_score:-24.4582\n",
      "\n",
      "iter:0 const:[10000.]\n",
      "Loss_Overall:1.1000, Loss_Attack:0.0000\n",
      "Loss_L2Dist:1.0000, Loss_L1Dist:1.0000, AE_loss:0.0\n",
      "target_lab_score:-26.2243, max_nontarget_lab_score:-26.1916\n",
      "\n",
      "iter:250 const:[10000.]\n",
      "Loss_Overall:58.4834, Loss_Attack:57.9788\n",
      "Loss_L2Dist:0.4384, Loss_L1Dist:0.6621, AE_loss:0.0\n",
      "target_lab_score:-22.8080, max_nontarget_lab_score:-22.7938\n",
      "\n",
      "iter:0 const:[100000.]\n",
      "Loss_Overall:1.1000, Loss_Attack:0.0000\n",
      "Loss_L2Dist:1.0000, Loss_L1Dist:1.0000, AE_loss:0.0\n",
      "target_lab_score:-26.2243, max_nontarget_lab_score:-26.1916\n",
      "\n",
      "iter:250 const:[100000.]\n",
      "Loss_Overall:580.2927, Loss_Attack:579.7881\n",
      "Loss_L2Dist:0.4384, Loss_L1Dist:0.6621, AE_loss:0.0\n",
      "target_lab_score:-22.8080, max_nontarget_lab_score:-22.7938\n",
      "\n",
      "iter:0 const:[1000000.]\n",
      "Loss_Overall:1.1000, Loss_Attack:0.0000\n",
      "Loss_L2Dist:1.0000, Loss_L1Dist:1.0000, AE_loss:0.0\n",
      "target_lab_score:-26.2243, max_nontarget_lab_score:-26.1916\n",
      "\n",
      "iter:250 const:[1000000.]\n",
      "Loss_Overall:5798.3867, Loss_Attack:5797.8818\n",
      "Loss_L2Dist:0.4384, Loss_L1Dist:0.6621, AE_loss:0.0\n",
      "target_lab_score:-22.8080, max_nontarget_lab_score:-22.7938\n",
      "\n",
      "iter:0 const:[10000000.]\n",
      "Loss_Overall:1.1000, Loss_Attack:0.0000\n",
      "Loss_L2Dist:1.0000, Loss_L1Dist:1.0000, AE_loss:0.0\n",
      "target_lab_score:-26.2243, max_nontarget_lab_score:-26.1916\n",
      "\n",
      "iter:250 const:[10000000.]\n",
      "Loss_Overall:57979.3203, Loss_Attack:57978.8164\n",
      "Loss_L2Dist:0.4384, Loss_L1Dist:0.6621, AE_loss:0.0\n",
      "target_lab_score:-22.8080, max_nontarget_lab_score:-22.7938\n",
      "\n",
      "iter:0 const:[1.e+08]\n",
      "Loss_Overall:1.1000, Loss_Attack:0.0000\n",
      "Loss_L2Dist:1.0000, Loss_L1Dist:1.0000, AE_loss:0.0\n",
      "target_lab_score:-26.2243, max_nontarget_lab_score:-26.1916\n",
      "\n",
      "iter:250 const:[1.e+08]\n",
      "Loss_Overall:579788.6875, Loss_Attack:579788.1875\n",
      "Loss_L2Dist:0.4384, Loss_L1Dist:0.6621, AE_loss:0.0\n",
      "target_lab_score:-22.8080, max_nontarget_lab_score:-22.7938\n",
      "\n",
      "iter:0 const:[1.e+09]\n",
      "Loss_Overall:1.1000, Loss_Attack:0.0000\n",
      "Loss_L2Dist:1.0000, Loss_L1Dist:1.0000, AE_loss:0.0\n",
      "target_lab_score:-26.2243, max_nontarget_lab_score:-26.1916\n",
      "\n",
      "iter:250 const:[1.e+09]\n",
      "Loss_Overall:5797882.0000, Loss_Attack:5797881.5000\n",
      "Loss_L2Dist:0.4384, Loss_L1Dist:0.6621, AE_loss:0.0\n",
      "target_lab_score:-22.8080, max_nontarget_lab_score:-22.7938\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# try on samples.\n",
    "idx =1\n",
    "# print(xn_test[idx].reshape((1,) + xn_test[idx].shape))\n",
    "      \n",
    "X = xn_test[idx].reshape((1,) + xn_test[idx].shape)\n",
    "print(\"Computing PN for Sample:\", idx)\n",
    "print(\"Prediction made by the model:\", nn.predict_proba(X))\n",
    "print(\"Prediction probabilities:\", class_names[np.argmax(nn.predict_proba(X))])\n",
    "print(\"\")\n",
    "\n",
    "mymodel = KerasClassifier(nn)\n",
    "explainer = CEMExplainer(mymodel)\n",
    "\n",
    "arg_mode = 'PN' # Find pertinent negatives\n",
    "arg_max_iter = 500 # Maximum number of iterations to search for the optimal PN for given parameter settings\n",
    "arg_init_const = 10.0 # Initial coefficient value for main loss term that encourages class change\n",
    "arg_b = 9 # No. of updates to the coefficient of the main loss term\n",
    "arg_kappa = 0.02 # Minimum confidence gap between the PNs (changed) class probability and original class' probability\n",
    "arg_beta = 1e-1 # Controls sparsity of the solution (L1 loss)\n",
    "arg_gamma = 100 # Controls how much to adhere to a (optionally trained) auto-encoder\n",
    "my_AE_model = None # Pointer to an auto-encoder\n",
    "arg_alpha = 0.01 # Penalizes L2 norm of the solution\n",
    "arg_threshold = 1. # Automatically turn off features <= arg_threshold if arg_threshold < 1\n",
    "arg_offset = 0.5 # the model assumes classifier trained on data normalized\n",
    "                # in [-arg_offset, arg_offset] range, where arg_offset is 0 or 0.5\n",
    "# Find PN for patient 1 \n",
    "(adv_pn, delta_pn, info_pn) = explainer.explain_instance(X, arg_mode, my_AE_model, arg_kappa, arg_b,\n",
    "                                                         arg_max_iter, arg_init_const, arg_beta, arg_gamma,\n",
    "                                                            arg_alpha, arg_threshold, arg_offset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample: 1\n",
      "prediction(X) [[-16.136536 -16.114416]] Diabetes-risk\n",
      "prediction(Xpn) [[-43.4475   -43.518078]] no-Diabetes-risk\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_d89fb1b2_4f37_11eb_9b0b_a1c59707b4b4row0_col0 {\n",
       "            background-color:  white;\n",
       "        }    #T_d89fb1b2_4f37_11eb_9b0b_a1c59707b4b4row0_col1 {\n",
       "            background-color:  white;\n",
       "        }    #T_d89fb1b2_4f37_11eb_9b0b_a1c59707b4b4row0_col2 {\n",
       "            background-color:  white;\n",
       "        }    #T_d89fb1b2_4f37_11eb_9b0b_a1c59707b4b4row1_col0 {\n",
       "            background-color:  yellow;\n",
       "        }    #T_d89fb1b2_4f37_11eb_9b0b_a1c59707b4b4row1_col1 {\n",
       "            background-color:  yellow;\n",
       "        }    #T_d89fb1b2_4f37_11eb_9b0b_a1c59707b4b4row1_col2 {\n",
       "            background-color:  yellow;\n",
       "        }    #T_d89fb1b2_4f37_11eb_9b0b_a1c59707b4b4row2_col0 {\n",
       "            background-color:  yellow;\n",
       "        }    #T_d89fb1b2_4f37_11eb_9b0b_a1c59707b4b4row2_col1 {\n",
       "            background-color:  yellow;\n",
       "        }    #T_d89fb1b2_4f37_11eb_9b0b_a1c59707b4b4row2_col2 {\n",
       "            background-color:  yellow;\n",
       "        }    #T_d89fb1b2_4f37_11eb_9b0b_a1c59707b4b4row3_col0 {\n",
       "            background-color:  yellow;\n",
       "        }    #T_d89fb1b2_4f37_11eb_9b0b_a1c59707b4b4row3_col1 {\n",
       "            background-color:  yellow;\n",
       "        }    #T_d89fb1b2_4f37_11eb_9b0b_a1c59707b4b4row3_col2 {\n",
       "            background-color:  yellow;\n",
       "        }    #T_d89fb1b2_4f37_11eb_9b0b_a1c59707b4b4row4_col0 {\n",
       "            background-color:  yellow;\n",
       "        }    #T_d89fb1b2_4f37_11eb_9b0b_a1c59707b4b4row4_col1 {\n",
       "            background-color:  yellow;\n",
       "        }    #T_d89fb1b2_4f37_11eb_9b0b_a1c59707b4b4row4_col2 {\n",
       "            background-color:  yellow;\n",
       "        }    #T_d89fb1b2_4f37_11eb_9b0b_a1c59707b4b4row5_col0 {\n",
       "            background-color:  yellow;\n",
       "        }    #T_d89fb1b2_4f37_11eb_9b0b_a1c59707b4b4row5_col1 {\n",
       "            background-color:  yellow;\n",
       "        }    #T_d89fb1b2_4f37_11eb_9b0b_a1c59707b4b4row5_col2 {\n",
       "            background-color:  yellow;\n",
       "        }    #T_d89fb1b2_4f37_11eb_9b0b_a1c59707b4b4row6_col0 {\n",
       "            background-color:  white;\n",
       "        }    #T_d89fb1b2_4f37_11eb_9b0b_a1c59707b4b4row6_col1 {\n",
       "            background-color:  white;\n",
       "        }    #T_d89fb1b2_4f37_11eb_9b0b_a1c59707b4b4row6_col2 {\n",
       "            background-color:  white;\n",
       "        }    #T_d89fb1b2_4f37_11eb_9b0b_a1c59707b4b4row7_col0 {\n",
       "            background-color:  white;\n",
       "        }    #T_d89fb1b2_4f37_11eb_9b0b_a1c59707b4b4row7_col1 {\n",
       "            background-color:  white;\n",
       "        }    #T_d89fb1b2_4f37_11eb_9b0b_a1c59707b4b4row7_col2 {\n",
       "            background-color:  white;\n",
       "        }    #T_d89fb1b2_4f37_11eb_9b0b_a1c59707b4b4row8_col0 {\n",
       "            background-color:  white;\n",
       "        }    #T_d89fb1b2_4f37_11eb_9b0b_a1c59707b4b4row8_col1 {\n",
       "            background-color:  white;\n",
       "        }    #T_d89fb1b2_4f37_11eb_9b0b_a1c59707b4b4row8_col2 {\n",
       "            background-color:  white;\n",
       "        }    #T_d89fb1b2_4f37_11eb_9b0b_a1c59707b4b4row9_col0 {\n",
       "            background-color:  white;\n",
       "        }    #T_d89fb1b2_4f37_11eb_9b0b_a1c59707b4b4row9_col1 {\n",
       "            background-color:  white;\n",
       "        }    #T_d89fb1b2_4f37_11eb_9b0b_a1c59707b4b4row9_col2 {\n",
       "            background-color:  white;\n",
       "        }</style><table id=\"T_d89fb1b2_4f37_11eb_9b0b_a1c59707b4b4\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >X</th>        <th class=\"col_heading level0 col1\" >X_PN</th>        <th class=\"col_heading level0 col2\" >(X_PN - X)</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_d89fb1b2_4f37_11eb_9b0b_a1c59707b4b4level0_row0\" class=\"row_heading level0 row0\" >Pregnancies</th>\n",
       "                        <td id=\"T_d89fb1b2_4f37_11eb_9b0b_a1c59707b4b4row0_col0\" class=\"data row0 col0\" >0.000000</td>\n",
       "                        <td id=\"T_d89fb1b2_4f37_11eb_9b0b_a1c59707b4b4row0_col1\" class=\"data row0 col1\" >0.000000</td>\n",
       "                        <td id=\"T_d89fb1b2_4f37_11eb_9b0b_a1c59707b4b4row0_col2\" class=\"data row0 col2\" >0.000000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_d89fb1b2_4f37_11eb_9b0b_a1c59707b4b4level0_row1\" class=\"row_heading level0 row1\" >Glucose</th>\n",
       "                        <td id=\"T_d89fb1b2_4f37_11eb_9b0b_a1c59707b4b4row1_col0\" class=\"data row1 col0\" >137.000000</td>\n",
       "                        <td id=\"T_d89fb1b2_4f37_11eb_9b0b_a1c59707b4b4row1_col1\" class=\"data row1 col1\" >44.000000</td>\n",
       "                        <td id=\"T_d89fb1b2_4f37_11eb_9b0b_a1c59707b4b4row1_col2\" class=\"data row1 col2\" >-93.000000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_d89fb1b2_4f37_11eb_9b0b_a1c59707b4b4level0_row2\" class=\"row_heading level0 row2\" >BloodPressure</th>\n",
       "                        <td id=\"T_d89fb1b2_4f37_11eb_9b0b_a1c59707b4b4row2_col0\" class=\"data row2 col0\" >84.000000</td>\n",
       "                        <td id=\"T_d89fb1b2_4f37_11eb_9b0b_a1c59707b4b4row2_col1\" class=\"data row2 col1\" >24.000000</td>\n",
       "                        <td id=\"T_d89fb1b2_4f37_11eb_9b0b_a1c59707b4b4row2_col2\" class=\"data row2 col2\" >-60.000000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_d89fb1b2_4f37_11eb_9b0b_a1c59707b4b4level0_row3\" class=\"row_heading level0 row3\" >SkinThickness</th>\n",
       "                        <td id=\"T_d89fb1b2_4f37_11eb_9b0b_a1c59707b4b4row3_col0\" class=\"data row3 col0\" >27.000000</td>\n",
       "                        <td id=\"T_d89fb1b2_4f37_11eb_9b0b_a1c59707b4b4row3_col1\" class=\"data row3 col1\" >7.000000</td>\n",
       "                        <td id=\"T_d89fb1b2_4f37_11eb_9b0b_a1c59707b4b4row3_col2\" class=\"data row3 col2\" >-20.000000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_d89fb1b2_4f37_11eb_9b0b_a1c59707b4b4level0_row4\" class=\"row_heading level0 row4\" >Insulin</th>\n",
       "                        <td id=\"T_d89fb1b2_4f37_11eb_9b0b_a1c59707b4b4row4_col0\" class=\"data row4 col0\" >30.500000</td>\n",
       "                        <td id=\"T_d89fb1b2_4f37_11eb_9b0b_a1c59707b4b4row4_col1\" class=\"data row4 col1\" >14.000000</td>\n",
       "                        <td id=\"T_d89fb1b2_4f37_11eb_9b0b_a1c59707b4b4row4_col2\" class=\"data row4 col2\" >-16.500000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_d89fb1b2_4f37_11eb_9b0b_a1c59707b4b4level0_row5\" class=\"row_heading level0 row5\" >BMI</th>\n",
       "                        <td id=\"T_d89fb1b2_4f37_11eb_9b0b_a1c59707b4b4row5_col0\" class=\"data row5 col0\" >27.300000</td>\n",
       "                        <td id=\"T_d89fb1b2_4f37_11eb_9b0b_a1c59707b4b4row5_col1\" class=\"data row5 col1\" >18.200000</td>\n",
       "                        <td id=\"T_d89fb1b2_4f37_11eb_9b0b_a1c59707b4b4row5_col2\" class=\"data row5 col2\" >-9.100000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_d89fb1b2_4f37_11eb_9b0b_a1c59707b4b4level0_row6\" class=\"row_heading level0 row6\" >DiabetesPedigreeFunction</th>\n",
       "                        <td id=\"T_d89fb1b2_4f37_11eb_9b0b_a1c59707b4b4row6_col0\" class=\"data row6 col0\" >0.231000</td>\n",
       "                        <td id=\"T_d89fb1b2_4f37_11eb_9b0b_a1c59707b4b4row6_col1\" class=\"data row6 col1\" >0.080000</td>\n",
       "                        <td id=\"T_d89fb1b2_4f37_11eb_9b0b_a1c59707b4b4row6_col2\" class=\"data row6 col2\" >-0.150000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_d89fb1b2_4f37_11eb_9b0b_a1c59707b4b4level0_row7\" class=\"row_heading level0 row7\" >Age_is_Old</th>\n",
       "                        <td id=\"T_d89fb1b2_4f37_11eb_9b0b_a1c59707b4b4row7_col0\" class=\"data row7 col0\" >1.000000</td>\n",
       "                        <td id=\"T_d89fb1b2_4f37_11eb_9b0b_a1c59707b4b4row7_col1\" class=\"data row7 col1\" >0.000000</td>\n",
       "                        <td id=\"T_d89fb1b2_4f37_11eb_9b0b_a1c59707b4b4row7_col2\" class=\"data row7 col2\" >-1.000000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_d89fb1b2_4f37_11eb_9b0b_a1c59707b4b4level0_row8\" class=\"row_heading level0 row8\" >Age_is_Young</th>\n",
       "                        <td id=\"T_d89fb1b2_4f37_11eb_9b0b_a1c59707b4b4row8_col0\" class=\"data row8 col0\" >0.000000</td>\n",
       "                        <td id=\"T_d89fb1b2_4f37_11eb_9b0b_a1c59707b4b4row8_col1\" class=\"data row8 col1\" >0.000000</td>\n",
       "                        <td id=\"T_d89fb1b2_4f37_11eb_9b0b_a1c59707b4b4row8_col2\" class=\"data row8 col2\" >0.000000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_d89fb1b2_4f37_11eb_9b0b_a1c59707b4b4level0_row9\" class=\"row_heading level0 row9\" >Outcome</th>\n",
       "                        <td id=\"T_d89fb1b2_4f37_11eb_9b0b_a1c59707b4b4row9_col0\" class=\"data row9 col0\" >Diabetes-risk</td>\n",
       "                        <td id=\"T_d89fb1b2_4f37_11eb_9b0b_a1c59707b4b4row9_col1\" class=\"data row9 col1\" >no-Diabetes-risk</td>\n",
       "                        <td id=\"T_d89fb1b2_4f37_11eb_9b0b_a1c59707b4b4row9_col2\" class=\"data row9 col2\" >NIL</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f4bffdf6b90>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xpn = adv_pn\n",
    "classes = [ class_names[np.argmax(nn.predict_proba(X))], class_names[np.argmax(nn.predict_proba(Xpn))], 'NIL' ]\n",
    "\n",
    "print(\"Sample:\", idx)\n",
    "print(\"prediction(X)\", nn.predict_proba(X), class_names[np.argmax(nn.predict_proba(X))])\n",
    "print(\"prediction(Xpn)\", nn.predict_proba(Xpn), class_names[np.argmax(nn.predict_proba(Xpn))] )\n",
    "\n",
    "\n",
    "X_re = rescale(X) # Convert values back to original scale from normalized\n",
    "Xpn_re = rescale(Xpn)\n",
    "Xpn_re = np.around(Xpn_re.astype(np.double), 2)\n",
    "\n",
    "delta_re = Xpn_re - X_re\n",
    "delta_re = np.around(delta_re.astype(np.double), 2)\n",
    "delta_re[np.absolute(delta_re) < 1e-4] = 0\n",
    "\n",
    "X3 = np.vstack((X_re, Xpn_re, delta_re))\n",
    "\n",
    "dfre = pd.DataFrame.from_records(X3) # Create dataframe to display original point, PN and difference (delta)\n",
    "dfre[23] = classes\n",
    "\n",
    "dfre.columns = df_final.columns\n",
    "dfre.rename(index={0:'X',1:'X_PN', 2:'(X_PN - X)'}, inplace=True)\n",
    "dfret = dfre.transpose()\n",
    "\n",
    "\n",
    "def highlight_ce(s, col, ncols):\n",
    "    if (type(s[col]) != str):\n",
    "        if (abs(s[col]) > 1):\n",
    "            return(['background-color: yellow']*ncols)    \n",
    "    return(['background-color: white']*ncols)\n",
    "\n",
    "dfret.style.apply(highlight_ce, col='X_PN', ncols=3, axis=1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The above results show that the patient should have 'less Glucose, Blood Pressure', 'Skin Thickness', Insulin, BMI for it to classified as `No-Diabetes-risk`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
